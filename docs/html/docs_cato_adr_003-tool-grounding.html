<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>003 tool grounding - RADIANT Documentation</title>
  
<style>
@media print {
  body { font-size: 11pt !important; }
  pre { page-break-inside: avoid; }
  h1, h2, h3 { page-break-after: avoid; }
  .no-print { display: none !important; }
}

* { box-sizing: border-box; }

body {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
  line-height: 1.7;
  color: #1d1d1f;
  max-width: 900px;
  margin: 0 auto;
  padding: 40px 30px;
  background: white;
}

h1 {
  color: #1d1d1f;
  border-bottom: 3px solid #0071e3;
  padding-bottom: 12px;
  font-size: 28px;
  margin-top: 0;
}

h2 {
  color: #1d1d1f;
  border-bottom: 1px solid #d2d2d7;
  padding-bottom: 8px;
  font-size: 22px;
  margin-top: 40px;
}

h3 { color: #1d1d1f; font-size: 18px; margin-top: 30px; }
h4 { color: #1d1d1f; font-size: 16px; margin-top: 25px; }

a { color: #0071e3; text-decoration: none; }
a:hover { text-decoration: underline; }

code {
  background: #f5f5f7;
  padding: 2px 6px;
  border-radius: 4px;
  font-family: 'SF Mono', Monaco, 'Cascadia Code', monospace;
  font-size: 0.9em;
  color: #1d1d1f;
}

pre {
  background: #1d1d1f;
  color: #f5f5f7;
  padding: 20px;
  border-radius: 10px;
  overflow-x: auto;
  font-size: 13px;
  line-height: 1.5;
}

pre code {
  background: transparent;
  padding: 0;
  color: inherit;
}

table {
  width: 100%;
  border-collapse: collapse;
  margin: 20px 0;
  font-size: 14px;
}

th, td {
  border: 1px solid #d2d2d7;
  padding: 12px 15px;
  text-align: left;
}

th {
  background: #0071e3;
  color: white;
  font-weight: 600;
}

tr:nth-child(even) { background: #f5f5f7; }

blockquote {
  border-left: 4px solid #0071e3;
  margin: 20px 0;
  padding: 15px 25px;
  background: #f5f5f7;
  border-radius: 0 8px 8px 0;
}

blockquote p { margin: 0; }

img { max-width: 100%; height: auto; border-radius: 8px; }

hr {
  border: none;
  border-top: 1px solid #d2d2d7;
  margin: 40px 0;
}

ul, ol { padding-left: 25px; }
li { margin: 8px 0; }

.header-bar {
  background: linear-gradient(135deg, #0071e3 0%, #00c6ff 100%);
  color: white;
  padding: 20px 30px;
  margin: -40px -30px 30px -30px;
  border-radius: 0 0 16px 16px;
}

.header-bar h1 {
  color: white;
  border: none;
  margin: 0;
  padding: 0;
}

.header-bar .meta {
  font-size: 13px;
  opacity: 0.9;
  margin-top: 8px;
}

.print-btn {
  position: fixed;
  top: 20px;
  right: 20px;
  background: #0071e3;
  color: white;
  border: none;
  padding: 12px 24px;
  border-radius: 8px;
  cursor: pointer;
  font-size: 14px;
  font-weight: 500;
  box-shadow: 0 4px 12px rgba(0,113,227,0.3);
}

.print-btn:hover { background: #0077ed; }

.mermaid {
  background: #f5f5f7;
  padding: 20px;
  border-radius: 10px;
  text-align: center;
  margin: 20px 0;
}

.footer {
  margin-top: 60px;
  padding-top: 20px;
  border-top: 1px solid #d2d2d7;
  color: #86868b;
  font-size: 12px;
  text-align: center;
}
</style>

</head>
<body>
  <button class="print-btn no-print" onclick="window.print()">ğŸ–¨ï¸ Print / Save as PDF</button>
  
  <div class="header-bar">
    <h1>003 tool grounding</h1>
    <div class="meta">RADIANT v5.52.29 | docs/cato/adr/003-tool-grounding.md</div>
  </div>
  
  <h1 id="adr-003-tool-grounding-with-20-external-verification">ADR-003: Tool Grounding with 20%+ External Verification</h1>
<h2 id="status">Status</h2>
<p>Accepted</p>
<h2 id="context">Context</h2>
<p>LLM vs.Â LLM comparison (having one model verify another) measures <strong>consistency</strong>, not <strong>truth</strong>. This creates a dangerous failure mode:</p>
<ol type="1">
<li>Model A generates a plausible-sounding hallucination</li>
<li>Model B (or A again) confirms it sounds reasonable</li>
<li>The hallucination gets reinforced in memory</li>
<li>Future queries retrieve and build upon the hallucination</li>
<li><strong>Hallucination cementing</strong>: False beliefs become entrenched</li>
</ol>
<p>Without external grounding, Catoâ€™s curiosity becomes a <strong>hallucination amplifier</strong> rather than a learning mechanism.</p>
<h3 id="evidence">Evidence</h3>
<ul>
<li>GPT-4 self-consistency: ~85% (agrees with itself on hallucinations)</li>
<li>Claude self-consistency: ~82%</li>
<li>Cross-model agreement on hallucinations: ~70%</li>
</ul>
<p>These numbers mean <strong>most hallucinations pass LLM-only verification</strong>.</p>
<h2 id="decision">Decision</h2>
<p>Mandate that <strong>at least 20% of curiosity loops must verify against external reality</strong> through tool use:</p>
<h3 id="grounding-tools">Grounding Tools</h3>
<table>
<colgroup>
<col style="width: 24%" />
<col style="width: 36%" />
<col style="width: 40%" />
</colgroup>
<thead>
<tr>
<th>Tool</th>
<th>Purpose</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Web Search</strong></td>
<td>Factual verification</td>
<td>â€œIs X true?â€ queries</td>
</tr>
<tr>
<td><strong>Code Execution</strong></td>
<td>Computational verification</td>
<td>Math, algorithms, data analysis</td>
</tr>
<tr>
<td><strong>API Calls</strong></td>
<td>Real-time data</td>
<td>Weather, stocks, current events</td>
</tr>
<tr>
<td><strong>Database Queries</strong></td>
<td>Structured data</td>
<td>Historical records, statistics</td>
</tr>
<tr>
<td><strong>Document Retrieval</strong></td>
<td>Source verification</td>
<td>Citations, quotes, references</td>
</tr>
</tbody>
</table>
<h3 id="grounding-policy">Grounding Policy</h3>
<pre class="python"><code>class GroundingPolicy:
    &quot;&quot;&quot;Determines when to use external grounding.&quot;&quot;&quot;
    
    ALWAYS_GROUND = [
        &quot;factual_claim&quot;,      # &quot;The population of X is Y&quot;
        &quot;numerical_claim&quot;,    # &quot;X costs $Y&quot;
        &quot;temporal_claim&quot;,     # &quot;X happened in Y&quot;
        &quot;attribution&quot;,        # &quot;X said Y&quot;
        &quot;scientific_claim&quot;,   # &quot;Studies show X&quot;
    ]
    
    SAMPLE_GROUND = [
        &quot;general_knowledge&quot;,  # 20% sampling
        &quot;reasoning_chain&quot;,    # 10% sampling
        &quot;creative_content&quot;,   # 5% sampling
    ]
    
    NEVER_GROUND = [
        &quot;opinion&quot;,            # &quot;I think X&quot;
        &quot;hypothetical&quot;,       # &quot;If X then Y&quot;
        &quot;meta_statement&quot;,     # &quot;I&#39;m uncertain about X&quot;
    ]</code></pre>
<h2 id="architecture">Architecture</h2>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Curiosity Question                            â”‚
â”‚  &quot;What is the GDP of France in 2024?&quot;                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Claim Classifier                              â”‚
â”‚  Type: factual_claim, numerical_claim                           â”‚
â”‚  Decision: MUST_GROUND                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LLM Prediction                                â”‚
â”‚  &quot;France&#39;s GDP in 2024 is approximately $3.1 trillion&quot;          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Tool Grounding                                â”‚
â”‚  Tool: Web Search (IMF, World Bank, Statista)                   â”‚
â”‚  Result: &quot;$2.78 trillion (IMF 2024 estimate)&quot;                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    NLI Comparison                                â”‚
â”‚  Prediction vs. Ground Truth                                    â”‚
â”‚  Result: PARTIAL_MATCH (order of magnitude correct)             â”‚
â”‚  Surprise Score: 0.4                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Memory Update                                 â”‚
â”‚  Store corrected fact with source attribution                   â”‚
â”‚  Mark original prediction as &quot;needs_update&quot;                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</code></pre>
<h2 id="implementation">Implementation</h2>
<h3 id="tool-executor-service">Tool Executor Service</h3>
<pre class="typescript"><code>interface GroundingResult {
  tool: string;
  query: string;
  result: string;
  sources: string[];
  confidence: number;
  timestamp: Date;
}

class ToolGroundingService {
  private readonly webSearch: WebSearchClient;
  private readonly codeExecutor: CodeExecutionClient;
  private readonly apiClient: ExternalAPIClient;
  
  async ground(
    claim: string,
    claimType: string
  ): Promise&lt;GroundingResult&gt; {
    // Select appropriate tool
    const tool = this.selectTool(claimType);
    
    // Execute grounding
    switch (tool) {
      case &#39;web_search&#39;:
        return this.groundWithWebSearch(claim);
      case &#39;code_execution&#39;:
        return this.groundWithCode(claim);
      case &#39;api_call&#39;:
        return this.groundWithAPI(claim);
      default:
        throw new Error(`Unknown tool: ${tool}`);
    }
  }
  
  private async groundWithWebSearch(
    claim: string
  ): Promise&lt;GroundingResult&gt; {
    // Generate search query from claim
    const query = await this.generateSearchQuery(claim);
    
    // Execute search
    const results = await this.webSearch.search(query, { limit: 5 });
    
    // Extract relevant facts
    const facts = await this.extractFacts(results, claim);
    
    return {
      tool: &#39;web_search&#39;,
      query,
      result: facts.summary,
      sources: facts.sources,
      confidence: facts.confidence,
      timestamp: new Date()
    };
  }
}</code></pre>
<h3 id="grounding-budget">Grounding Budget</h3>
<p>To prevent excessive API costs, grounding has its own budget:</p>
<table>
<thead>
<tr>
<th>Tool</th>
<th>Cost per Call</th>
<th>Daily Limit</th>
<th>Monthly Budget</th>
</tr>
</thead>
<tbody>
<tr>
<td>Web Search</td>
<td>$0.01</td>
<td>1,000</td>
<td>~$300</td>
</tr>
<tr>
<td>Code Execution</td>
<td>$0.001</td>
<td>5,000</td>
<td>~$150</td>
</tr>
<tr>
<td>API Calls</td>
<td>Varies</td>
<td>500</td>
<td>~$100</td>
</tr>
<tr>
<td><strong>Total</strong></td>
<td></td>
<td></td>
<td><strong>~$550/month</strong></td>
</tr>
</tbody>
</table>
<h2 id="consequences">Consequences</h2>
<h3 id="positive">Positive</h3>
<ul>
<li><strong>Hallucination prevention</strong>: External reality check breaks confirmation loops</li>
<li><strong>Source attribution</strong>: All facts traceable to external sources</li>
<li><strong>Confidence calibration</strong>: Grounding provides ground truth for calibration</li>
<li><strong>User trust</strong>: Can cite sources when asked</li>
</ul>
<h3 id="negative">Negative</h3>
<ul>
<li><strong>Higher latency</strong>: Tool calls add 500ms-2s per grounding</li>
<li><strong>Additional cost</strong>: ~$550/month for grounding tools</li>
<li><strong>Complexity</strong>: Tool integration and error handling</li>
<li><strong>Rate limits</strong>: External APIs have usage limits</li>
</ul>
<h2 id="metrics">Metrics</h2>
<p>Track grounding effectiveness:</p>
<table>
<colgroup>
<col style="width: 27%" />
<col style="width: 27%" />
<col style="width: 44%" />
</colgroup>
<thead>
<tr>
<th>Metric</th>
<th>Target</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Grounding Ratio</td>
<td>â‰¥ 20%</td>
<td>% of curiosity loops with tool grounding</td>
</tr>
<tr>
<td>Correction Rate</td>
<td>â‰¤ 30%</td>
<td>% of LLM predictions corrected by grounding</td>
</tr>
<tr>
<td>Source Coverage</td>
<td>â‰¥ 80%</td>
<td>% of facts with external source attribution</td>
</tr>
<tr>
<td>Hallucination Rate</td>
<td>â‰¤ 10%</td>
<td>% of responses containing unverified claims</td>
</tr>
</tbody>
</table>
<h2 id="references">References</h2>
<ul>
<li><a href="https://arxiv.org/abs/2109.07958">TruthfulQA: Measuring How Models Mimic Human Falsehoods</a></li>
<li><a href="https://arxiv.org/abs/2302.04761">Tool-Augmented Language Models</a></li>
<li><a href="https://arxiv.org/abs/2005.11401">Retrieval-Augmented Generation</a></li>
</ul>

  
  <div class="footer">
    RADIANT Documentation | Version 5.52.29 | Generated January 25, 2026
  </div>
</body>
</html>