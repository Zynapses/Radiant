<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>SECTION 06 SELF HOSTED MODELS - RADIANT Documentation</title>
  
<style>
@media print {
  body { font-size: 11pt !important; }
  pre { page-break-inside: avoid; }
  h1, h2, h3 { page-break-after: avoid; }
  .no-print { display: none !important; }
}

* { box-sizing: border-box; }

body {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
  line-height: 1.7;
  color: #1d1d1f;
  max-width: 900px;
  margin: 0 auto;
  padding: 40px 30px;
  background: white;
}

h1 {
  color: #1d1d1f;
  border-bottom: 3px solid #0071e3;
  padding-bottom: 12px;
  font-size: 28px;
  margin-top: 0;
}

h2 {
  color: #1d1d1f;
  border-bottom: 1px solid #d2d2d7;
  padding-bottom: 8px;
  font-size: 22px;
  margin-top: 40px;
}

h3 { color: #1d1d1f; font-size: 18px; margin-top: 30px; }
h4 { color: #1d1d1f; font-size: 16px; margin-top: 25px; }

a { color: #0071e3; text-decoration: none; }
a:hover { text-decoration: underline; }

code {
  background: #f5f5f7;
  padding: 2px 6px;
  border-radius: 4px;
  font-family: 'SF Mono', Monaco, 'Cascadia Code', monospace;
  font-size: 0.9em;
  color: #1d1d1f;
}

pre {
  background: #1d1d1f;
  color: #f5f5f7;
  padding: 20px;
  border-radius: 10px;
  overflow-x: auto;
  font-size: 13px;
  line-height: 1.5;
}

pre code {
  background: transparent;
  padding: 0;
  color: inherit;
}

table {
  width: 100%;
  border-collapse: collapse;
  margin: 20px 0;
  font-size: 14px;
}

th, td {
  border: 1px solid #d2d2d7;
  padding: 12px 15px;
  text-align: left;
}

th {
  background: #0071e3;
  color: white;
  font-weight: 600;
}

tr:nth-child(even) { background: #f5f5f7; }

blockquote {
  border-left: 4px solid #0071e3;
  margin: 20px 0;
  padding: 15px 25px;
  background: #f5f5f7;
  border-radius: 0 8px 8px 0;
}

blockquote p { margin: 0; }

img { max-width: 100%; height: auto; border-radius: 8px; }

hr {
  border: none;
  border-top: 1px solid #d2d2d7;
  margin: 40px 0;
}

ul, ol { padding-left: 25px; }
li { margin: 8px 0; }

.header-bar {
  background: linear-gradient(135deg, #0071e3 0%, #00c6ff 100%);
  color: white;
  padding: 20px 30px;
  margin: -40px -30px 30px -30px;
  border-radius: 0 0 16px 16px;
}

.header-bar h1 {
  color: white;
  border: none;
  margin: 0;
  padding: 0;
}

.header-bar .meta {
  font-size: 13px;
  opacity: 0.9;
  margin-top: 8px;
}

.print-btn {
  position: fixed;
  top: 20px;
  right: 20px;
  background: #0071e3;
  color: white;
  border: none;
  padding: 12px 24px;
  border-radius: 8px;
  cursor: pointer;
  font-size: 14px;
  font-weight: 500;
  box-shadow: 0 4px 12px rgba(0,113,227,0.3);
}

.print-btn:hover { background: #0077ed; }

.mermaid {
  background: #f5f5f7;
  padding: 20px;
  border-radius: 10px;
  text-align: center;
  margin: 20px 0;
}

.footer {
  margin-top: 60px;
  padding-top: 20px;
  border-top: 1px solid #d2d2d7;
  color: #86868b;
  font-size: 12px;
  text-align: center;
}
</style>

</head>
<body>
  <button class="print-btn no-print" onclick="window.print()">ЁЯЦия╕П Print / Save as PDF</button>
  
  <div class="header-bar">
    <h1>SECTION 06 SELF HOSTED MODELS</h1>
    <div class="meta">RADIANT v5.52.29 | docs/sections/SECTION-06-SELF-HOSTED-MODELS.md</div>
  </div>
  
  <h1 id="section-6-self-hosted-models-mid-level-services-v2.2.0">SECTION 6: SELF-HOSTED MODELS &amp; MID-LEVEL SERVICES (v2.2.0)</h1>
<h1 id="├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в">├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р</h1>
<blockquote>
<p><strong>Dependencies:</strong> Sections 0-5 <strong>Creates:</strong> 30+ SageMaker models, Thermal state management</p>
</blockquote>
<h2 id="type-imports">Type Imports</h2>
<pre class="typescript"><code>import { ThermalState, ThermalConfig, ServiceState, MidLevelService } from &#39;@radiant/shared&#39;;</code></pre>
<hr />
<h1 id="radiant-v2.2.0---prompt-6-self-hosted-models-mid-level-services">RADIANT v2.2.0 - Prompt 6: Self-Hosted Models &amp; Mid-Level Services</h1>
<blockquote>
<p><strong>Prompt 6 of 9</strong> | Target Size: ~75KB | Version: 3.7.0 | December 2024</p>
</blockquote>
<hr />
<h2 id="overview">OVERVIEW</h2>
<p>This prompt creates the self-hosted AI model configurations and mid-level orchestration services:</p>
<ol type="1">
<li><strong>Self-Hosted Models</strong> - 30+ AI models deployed on SageMaker across 9 categories</li>
<li><strong>Thermal State Management</strong> - Lambda functions for OFF/COLD/WARM/HOT/AUTOMATIC states</li>
<li><strong>Mid-Level Services</strong> - 5 domain-specific orchestration services</li>
<li><strong>Service State Management</strong> - RUNNING/DEGRADED/DISABLED/OFFLINE states</li>
<li><strong>LiteLLM Configuration</strong> - Self-hosted model routing configuration</li>
<li><strong>Client Notifications</strong> - Real-time model warm-up notifications via WebSocket</li>
</ol>
<p>All configurations are tier-aware, with self-hosted models requiring Tier 3+ (GROWTH and above).</p>
<hr />
<h2 id="architecture">ARCHITECTURE</h2>
<pre><code>├Г┬в├втВм┬Э├ЕтАЩ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├В┬Р
├Г┬в├втВм┬Э├втВм┼б                         SELF-HOSTED AI LAYER                                 ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├ЕтАЬ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├В┬д
├Г┬в├втВм┬Э├втВм┼б                                                                             ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б   Client Request                                                            ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б        ├Г┬в├втВм┬Э├втВм┼б                                                                    ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б        ├Г┬в├втВмтАЬ├В┬╝                                                                    ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├ЕтАЩ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├В┬Р     ├Г┬в├втВм┬Э├ЕтАЩ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├В┬Р     ├Г┬в├втВм┬Э├ЕтАЩ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├В┬Р      ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б  Lambda Router  ├Г┬в├втВм┬Э├втВм┼б├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВмтАЬ├В┬║├Г┬в├втВм┬Э├втВм┼б  Thermal State  ├Г┬в├втВм┬Э├втВм┼б├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВмтАЬ├В┬║├Г┬в├втВм┬Э├втВм┼б  Model Warmer   ├Г┬в├втВм┬Э├втВм┼б      ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┬Э├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├В┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├Л┼У     ├Г┬в├втВм┬Э├втВм┼б    Manager      ├Г┬в├втВм┬Э├втВм┼б     ├Г┬в├втВм┬Э├втВм┼б    Lambda       ├Г┬в├втВм┬Э├втВм┼б      ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б            ├Г┬в├втВм┬Э├втВм┼б              ├Г┬в├втВм┬Э├втВм┬Э├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├Л┼У     ├Г┬в├втВм┬Э├втВм┬Э├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├Л┼У      ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б            ├Г┬в├втВм┬Э├втВм┼б                                                                ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б            ├Г┬в├втВмтАЬ├В┬╝                                                                ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├ЕтАЩ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├В┬Р    ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б                    LITELLM GATEWAY (ECS Fargate)                   ├Г┬в├втВм┬Э├втВм┼б    ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┬Э├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├В┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├Л┼У    ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б            ├Г┬в├втВм┬Э├втВм┼б                                                                ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├ЕтАЩ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├В┬┤├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├В┬Р      ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б                                                                  ├Г┬в├втВм┬Э├втВм┼б      ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВмтАЬ├В┬╝                              ├Г┬в├втВмтАЬ├В┬╝                              ├Г┬в├втВмтАЬ├В┬╝    ├Г┬в├втВм┬Э├втВм┼б      ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├ЕтАЩ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├В┬Р  ├Г┬в├втВм┬Э├ЕтАЩ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├В┬Р  ├Г┬в├втВм┬Э├ЕтАЩ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├В┬Р   ├Г┬в├втВм┬Э├втВм┼б      ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б   COMPUTER       ├Г┬в├втВм┬Э├втВм┼б  ├Г┬в├втВм┬Э├втВм┼б   AUDIO/SPEECH   ├Г┬в├втВм┬Э├втВм┼б  ├Г┬в├втВм┬Э├втВм┼б   SCIENTIFIC     ├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б      ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б   VISION         ├Г┬в├втВм┬Э├втВм┼б  ├Г┬в├втВм┬Э├втВм┼б                  ├Г┬в├втВм┬Э├втВм┼б  ├Г┬в├втВм┬Э├втВм┼б   COMPUTING      ├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б      ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втАЪ┬м├В┬в Classification ├Г┬в├втВм┬Э├втВм┼б  ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втАЪ┬м├В┬в Whisper STT    ├Г┬в├втВм┬Э├втВм┼б  ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втАЪ┬м├В┬в AlphaFold2     ├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б      ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втАЪ┬м├В┬в Detection      ├Г┬в├втВм┬Э├втВм┼б  ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втАЪ┬м├В┬в TitaNet        ├Г┬в├втВм┬Э├втВм┼б  ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втАЪ┬м├В┬в ESM-2          ├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б      ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втАЪ┬м├В┬в Segmentation   ├Г┬в├втВм┬Э├втВм┼б  ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втАЪ┬м├В┬в pyannote       ├Г┬в├втВм┬Э├втВм┼б  ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втАЪ┬м├В┬в AlphaGeometry  ├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б      ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┬Э├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├Л┼У  ├Г┬в├втВм┬Э├втВм┬Э├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├Л┼У  ├Г┬в├втВм┬Э├втВм┬Э├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├Л┼У   ├Г┬в├втВм┬Э├втВм┼б      ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б                                                                      ├Г┬в├втВм┬Э├втВм┼б      ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВмтАЬ├В┬╝                              ├Г┬в├втВмтАЬ├В┬╝                              ├Г┬в├втВмтАЬ├В┬╝    ├Г┬в├втВм┬Э├втВм┼б      ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├ЕтАЩ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├В┬Р  ├Г┬в├втВм┬Э├ЕтАЩ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├В┬Р  ├Г┬в├втВм┬Э├ЕтАЩ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├В┬Р   ├Г┬в├втВм┬Э├втВм┼б      ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б   MEDICAL        ├Г┬в├втВм┬Э├втВм┼б  ├Г┬в├втВм┬Э├втВм┼б   GEOSPATIAL     ├Г┬в├втВм┬Э├втВм┼б  ├Г┬в├втВм┬Э├втВм┼б   3D/GENERATIVE  ├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б      ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б   IMAGING        ├Г┬в├втВм┬Э├втВм┼б  ├Г┬в├втВм┬Э├втВм┼б   ANALYSIS       ├Г┬в├втВм┬Э├втВм┼б  ├Г┬в├втВм┬Э├втВм┼б                  ├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б      ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втАЪ┬м├В┬в nnU-Net        ├Г┬в├втВм┬Э├втВм┼б  ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втАЪ┬м├В┬в Prithvi 100M   ├Г┬в├втВм┬Э├втВм┼б  ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втАЪ┬м├В┬в Nerfstudio     ├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б      ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втАЪ┬м├В┬в MedSAM         ├Г┬в├втВм┬Э├втВм┼б  ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втАЪ┬м├В┬в Prithvi 600M   ├Г┬в├втВм┬Э├втВм┼б  ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втАЪ┬м├В┬в 3D Gaussian    ├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б      ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┬Э├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├Л┼У  ├Г┬в├втВм┬Э├втВм┬Э├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├Л┼У  ├Г┬в├втВм┬Э├втВм┬Э├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├Л┼У   ├Г┬в├втВм┬Э├втВм┼б      ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┬Э├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├Л┼У
                                    ├Г┬в├втВм┬Э├втВм┼б
                                    ├Г┬в├втВмтАЬ├В┬╝
├Г┬в├втВм┬Э├ЕтАЩ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├В┬Р
├Г┬в├втВм┬Э├втВм┼б                        MID-LEVEL SERVICES LAYER                              ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├ЕтАЬ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├В┬д
├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├ЕтАЩ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├В┬Р ├Г┬в├втВм┬Э├ЕтАЩ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├В┬Р ├Г┬в├втВм┬Э├ЕтАЩ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├В┬Р                ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б   PERCEPTION    ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б   SCIENTIFIC    ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б   MEDICAL       ├Г┬в├втВм┬Э├втВм┼б                ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б   SERVICE       ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б   SERVICE       ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б   SERVICE       ├Г┬в├втВм┬Э├втВм┼б                ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б Orchestrates:   ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б Orchestrates:   ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б Orchestrates:   ├Г┬в├втВм┬Э├втВм┼б                ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втАЪ┬м├В┬в YOLOv8/11     ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втАЪ┬м├В┬в AlphaFold2    ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втАЪ┬м├В┬в nnU-Net       ├Г┬в├втВм┬Э├втВм┼б                ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втАЪ┬м├В┬в SAM           ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втАЪ┬м├В┬в ESM-2         ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втАЪ┬м├В┬в MedSAM        ├Г┬в├втВм┬Э├втВм┼б                ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втАЪ┬м├В┬в CLIP          ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втАЪ┬м├В┬в AlphaGeometry ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втАЪ┬м├В┬в Whisper       ├Г┬в├втВм┬Э├втВм┼б                ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┬Э├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├Л┼У ├Г┬в├втВм┬Э├втВм┬Э├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├Л┼У ├Г┬в├втВм┬Э├втВм┬Э├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├Л┼У                ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├ЕтАЩ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├В┬Р ├Г┬в├втВм┬Э├ЕтАЩ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├В┬Р                                    ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б   GEOSPATIAL    ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б   3D RECON      ├Г┬в├втВм┬Э├втВм┼б                                    ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б   SERVICE       ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б   SERVICE       ├Г┬в├втВм┬Э├втВм┼б                                    ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втАЪ┬м├В┬в Prithvi       ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втАЪ┬м├В┬в Nerfstudio    ├Г┬в├втВм┬Э├втВм┼б                                    ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втАЪ┬м├В┬в SAM           ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втАЪ┬м├В┬в 3D Gaussian   ├Г┬в├втВм┬Э├втВм┼б                                    ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┼б ├Г┬в├втВм┬Э├втВм┬Э├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├Л┼У ├Г┬в├втВм┬Э├втВм┬Э├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├Л┼У                                    ├Г┬в├втВм┬Э├втВм┼б
├Г┬в├втВм┬Э├втВм┬Э├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├Л┼У</code></pre>
<hr />
<h2 id="directory-structure">DIRECTORY STRUCTURE</h2>
<pre><code>packages/infrastructure/
├Г┬в├втВм┬Э├ЕтАЬ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м lib/
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├ЕтАЬ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м config/
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├ЕтАЬ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м models/
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├ЕтАЬ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м index.ts                  # All model exports
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├ЕтАЬ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м vision.models.ts          # Computer vision models
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├ЕтАЬ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м audio.models.ts           # Audio/speech models
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├ЕтАЬ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м scientific.models.ts      # Scientific models
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├ЕтАЬ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м medical.models.ts         # Medical imaging models
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├ЕтАЬ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м geospatial.models.ts      # Geospatial models
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┬Э├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м generative.models.ts      # 3D/generative models
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┬Э├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м services/
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б       ├Г┬в├втВм┬Э├ЕтАЬ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м index.ts                  # All service exports
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б       ├Г┬в├втВм┬Э├ЕтАЬ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м perception.service.ts
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б       ├Г┬в├втВм┬Э├ЕтАЬ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м scientific.service.ts
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б       ├Г┬в├втВм┬Э├ЕтАЬ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м medical.service.ts
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б       ├Г┬в├втВм┬Э├ЕтАЬ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м geospatial.service.ts
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б       ├Г┬в├втВм┬Э├втВм┬Э├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м reconstruction.service.ts
├Г┬в├втВм┬Э├ЕтАЬ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м lambda/
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├ЕтАЬ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м thermal/
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├ЕтАЬ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м manager.ts                    # Thermal state manager
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├ЕтАЬ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м warmer.ts                     # Model warming Lambda
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┬Э├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м notifier.ts                   # Client notification Lambda
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┬Э├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м services/
├Г┬в├втВм┬Э├втВм┼б       ├Г┬в├втВм┬Э├ЕтАЬ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м perception.ts                 # Perception orchestration
├Г┬в├втВм┬Э├втВм┼б       ├Г┬в├втВм┬Э├ЕтАЬ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м scientific.ts                 # Scientific orchestration
├Г┬в├втВм┬Э├втВм┼б       ├Г┬в├втВм┬Э├ЕтАЬ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м medical.ts                    # Medical orchestration
├Г┬в├втВм┬Э├втВм┼б       ├Г┬в├втВм┬Э├ЕтАЬ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м geospatial.ts                 # Geospatial orchestration
├Г┬в├втВм┬Э├втВм┼б       ├Г┬в├втВм┬Э├втВм┬Э├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м reconstruction.ts             # 3D reconstruction
├Г┬в├втВм┬Э├ЕтАЬ├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м litellm/
├Г┬в├втВм┬Э├втВм┼б   ├Г┬в├втВм┬Э├втВм┬Э├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м config/
├Г┬в├втВм┬Э├втВм┼б       ├Г┬в├втВм┬Э├втВм┬Э├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м self-hosted.yaml              # Self-hosted model config
├Г┬в├втВм┬Э├втВм┬Э├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м migrations/
    ├Г┬в├втВм┬Э├втВм┬Э├Г┬в├втВм┬Э├втАЪ┬м├Г┬в├втВм┬Э├втАЪ┬м 006_self_hosted_models.sql        # Schema additions</code></pre>
<hr />
<h2 id="part-1-self-hosted-model-definitions">PART 1: SELF-HOSTED MODEL DEFINITIONS</h2>
<h3 id="aws-sagemaker-instance-pricing-with-75-markup">AWS SageMaker Instance Pricing (with 75% markup)</h3>
<table>
<colgroup>
<col style="width: 17%" />
<col style="width: 10%" />
<col style="width: 10%" />
<col style="width: 19%" />
<col style="width: 23%" />
<col style="width: 17%" />
</colgroup>
<thead>
<tr>
<th>Instance</th>
<th>GPUs</th>
<th>VRAM</th>
<th>Base $/hr</th>
<th>Billed $/hr</th>
<th>Best For</th>
</tr>
</thead>
<tbody>
<tr>
<td>ml.g4dn.xlarge</td>
<td>1x T4</td>
<td>16 GB</td>
<td>$0.74</td>
<td>$1.30</td>
<td>Small models, embeddings</td>
</tr>
<tr>
<td>ml.g5.xlarge</td>
<td>1x A10G</td>
<td>24 GB</td>
<td>$1.41</td>
<td>$2.47</td>
<td>Medium models</td>
</tr>
<tr>
<td>ml.g5.2xlarge</td>
<td>1x A10G</td>
<td>24 GB</td>
<td>$1.52</td>
<td>$2.66</td>
<td>Medium+ models</td>
</tr>
<tr>
<td>ml.g5.4xlarge</td>
<td>1x A10G</td>
<td>24 GB</td>
<td>$2.03</td>
<td>$3.55</td>
<td>Large vision models</td>
</tr>
<tr>
<td>ml.g5.12xlarge</td>
<td>4x A10G</td>
<td>96 GB</td>
<td>$8.16</td>
<td>$14.28</td>
<td>Large LLMs</td>
</tr>
<tr>
<td>ml.g5.48xlarge</td>
<td>8x A10G</td>
<td>192 GB</td>
<td>$20.36</td>
<td>$35.63</td>
<td>Very large models</td>
</tr>
<tr>
<td>ml.p4d.24xlarge</td>
<td>8x A100</td>
<td>320 GB</td>
<td>$32.77</td>
<td>$57.35</td>
<td>Scientific computing</td>
</tr>
</tbody>
</table>
<h3 id="packagesinfrastructurelibconfigmodelsindex.ts">packages/infrastructure/lib/config/models/index.ts</h3>
<pre class="typescript"><code>/**
 * Self-Hosted Model Registry
 * All models available for deployment on SageMaker
 * Pricing includes 75% markup over AWS infrastructure costs
 */

export * from &#39;./vision.models&#39;;
export * from &#39;./audio.models&#39;;
export * from &#39;./scientific.models&#39;;
export * from &#39;./medical.models&#39;;
export * from &#39;./geospatial.models&#39;;
export * from &#39;./generative.models&#39;;

// ============================================================================
// SHARED TYPES
// ============================================================================

export type ThermalState = &#39;OFF&#39; | &#39;COLD&#39; | &#39;WARM&#39; | &#39;HOT&#39; | &#39;AUTOMATIC&#39;;
export type ServiceState = &#39;RUNNING&#39; | &#39;DEGRADED&#39; | &#39;DISABLED&#39; | &#39;OFFLINE&#39;;

export interface ThermalConfig {
  defaultState: ThermalState;
  scaleToZeroAfterMinutes: number;
  warmupTimeSeconds: number;
  minInstances: number;
  maxInstances: number;
}

export interface SageMakerModelConfig {
  id: string;
  name: string;
  displayName: string;
  description: string;
  category: ModelCategory;
  specialty: ModelSpecialty;
  
  // SageMaker Configuration
  image: string;
  instanceType: string;
  environment: Record&lt;string, string&gt;;
  modelDataUrl?: string;
  
  // Model Capabilities
  parameters: number;
  accuracy?: string;
  benchmark?: string;
  capabilities: string[];
  inputFormats: string[];
  outputFormats: string[];
  
  // Thermal Management
  thermal: ThermalConfig;
  
  // Licensing
  license: string;
  licenseUrl?: string;
  commercialUseNotes?: string;
  
  // Pricing (75% markup over AWS)
  pricing: SelfHostedModelPricing;
  
  // Requirements
  minTier: number;
  requiresGPU: boolean;
  gpuMemoryGB: number;
  
  // Status
  status: &#39;active&#39; | &#39;beta&#39; | &#39;deprecated&#39; | &#39;coming_soon&#39;;
}

export type ModelCategory =
  | &#39;vision_classification&#39;
  | &#39;vision_detection&#39;
  | &#39;vision_segmentation&#39;
  | &#39;audio_stt&#39;
  | &#39;audio_speaker&#39;
  | &#39;scientific_protein&#39;
  | &#39;scientific_math&#39;
  | &#39;medical_imaging&#39;
  | &#39;geospatial&#39;
  | &#39;generative_3d&#39;
  | &#39;llm_text&#39;;

export type ModelSpecialty =
  | &#39;image_classification&#39;
  | &#39;object_detection&#39;
  | &#39;instance_segmentation&#39;
  | &#39;speech_to_text&#39;
  | &#39;speaker_identification&#39;
  | &#39;protein_folding&#39;
  | &#39;protein_embeddings&#39;
  | &#39;geometry_reasoning&#39;
  | &#39;medical_segmentation&#39;
  | &#39;satellite_analysis&#39;
  | &#39;3d_reconstruction&#39;
  | &#39;text_generation&#39;;

export interface SelfHostedModelPricing {
  hourlyRate: number;        // Per-hour instance cost (with 75% markup)
  perImage?: number;
  perMinuteAudio?: number;
  perMinuteVideo?: number;
  per3DModel?: number;
  perRequest?: number;
  markup: number;            // 0.75 = 75%
}

export const INSTANCE_PRICING: Record&lt;string, { base: number; billed: number }&gt; = {
  &#39;ml.g4dn.xlarge&#39;:   { base: 0.74,  billed: 1.30 },
  &#39;ml.g5.xlarge&#39;:     { base: 1.41,  billed: 2.47 },
  &#39;ml.g5.2xlarge&#39;:    { base: 1.52,  billed: 2.66 },
  &#39;ml.g5.4xlarge&#39;:    { base: 2.03,  billed: 3.55 },
  &#39;ml.g5.12xlarge&#39;:   { base: 8.16,  billed: 14.28 },
  &#39;ml.g5.48xlarge&#39;:   { base: 20.36, billed: 35.63 },
  &#39;ml.p4d.24xlarge&#39;:  { base: 32.77, billed: 57.35 },
};</code></pre>
<h3 id="packagesinfrastructurelibconfigmodelsvision.models.ts">packages/infrastructure/lib/config/models/vision.models.ts</h3>
<pre class="typescript"><code>/**
 * Computer Vision Models - Classification, Detection, Segmentation
 */

import { SageMakerModelConfig, INSTANCE_PRICING } from &#39;./index&#39;;

// ============================================================================
// IMAGE CLASSIFICATION MODELS (8 models)
// ============================================================================

export const CLASSIFICATION_MODELS: SageMakerModelConfig[] = [
  {
    id: &#39;efficientnet-b0&#39;,
    name: &#39;efficientnet-b0&#39;,
    displayName: &#39;EfficientNet-B0&#39;,
    description: &#39;Lightweight image classification model&#39;,
    category: &#39;vision_classification&#39;,
    specialty: &#39;image_classification&#39;,
    image: &#39;pytorch-inference:2.1-transformers4.36-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g4dn.xlarge&#39;,
    environment: { HF_MODEL_ID: &#39;google/efficientnet-b0&#39;, HF_TASK: &#39;image-classification&#39; },
    parameters: 5_300_000,
    accuracy: &#39;77.1% ImageNet Top-1&#39;,
    capabilities: [&#39;image_classification&#39;, &#39;feature_extraction&#39;],
    inputFormats: [&#39;image/jpeg&#39;, &#39;image/png&#39;],
    outputFormats: [&#39;application/json&#39;],
    thermal: { defaultState: &#39;COLD&#39;, scaleToZeroAfterMinutes: 15, warmupTimeSeconds: 45, minInstances: 0, maxInstances: 3 },
    license: &#39;Apache-2.0&#39;,
    pricing: { hourlyRate: 1.30, perImage: 0.001, markup: 0.75 },
    minTier: 3, requiresGPU: true, gpuMemoryGB: 2, status: &#39;active&#39;,
  },
  {
    id: &#39;efficientnetv2-l&#39;,
    name: &#39;efficientnetv2-l&#39;,
    displayName: &#39;EfficientNetV2-L&#39;,
    description: &#39;State-of-the-art classification with improved training efficiency&#39;,
    category: &#39;vision_classification&#39;,
    specialty: &#39;image_classification&#39;,
    image: &#39;pytorch-inference:2.1-transformers4.36-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g5.2xlarge&#39;,
    environment: { HF_MODEL_ID: &#39;google/efficientnetv2-l&#39;, HF_TASK: &#39;image-classification&#39; },
    parameters: 118_000_000,
    accuracy: &#39;85.7% ImageNet Top-1&#39;,
    capabilities: [&#39;image_classification&#39;, &#39;feature_extraction&#39;],
    inputFormats: [&#39;image/jpeg&#39;, &#39;image/png&#39;],
    outputFormats: [&#39;application/json&#39;],
    thermal: { defaultState: &#39;COLD&#39;, scaleToZeroAfterMinutes: 15, warmupTimeSeconds: 90, minInstances: 0, maxInstances: 3 },
    license: &#39;Apache-2.0&#39;,
    pricing: { hourlyRate: 2.66, perImage: 0.003, markup: 0.75 },
    minTier: 3, requiresGPU: true, gpuMemoryGB: 10, status: &#39;active&#39;,
  },
  {
    id: &#39;swin-large&#39;,
    name: &#39;swin-large&#39;,
    displayName: &#39;Swin Transformer Large&#39;,
    description: &#39;Vision Transformer with shifted window attention&#39;,
    category: &#39;vision_classification&#39;,
    specialty: &#39;image_classification&#39;,
    image: &#39;pytorch-inference:2.1-transformers4.36-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g5.2xlarge&#39;,
    environment: { HF_MODEL_ID: &#39;microsoft/swin-large-patch4-window7-224&#39;, HF_TASK: &#39;image-classification&#39; },
    parameters: 197_000_000,
    accuracy: &#39;87.3% ImageNet Top-1&#39;,
    capabilities: [&#39;image_classification&#39;, &#39;feature_extraction&#39;],
    inputFormats: [&#39;image/jpeg&#39;, &#39;image/png&#39;],
    outputFormats: [&#39;application/json&#39;],
    thermal: { defaultState: &#39;COLD&#39;, scaleToZeroAfterMinutes: 15, warmupTimeSeconds: 90, minInstances: 0, maxInstances: 3 },
    license: &#39;MIT&#39;,
    pricing: { hourlyRate: 2.66, perImage: 0.004, markup: 0.75 },
    minTier: 3, requiresGPU: true, gpuMemoryGB: 16, status: &#39;active&#39;,
  },
  {
    id: &#39;clip-vit-l14&#39;,
    name: &#39;clip-vit-l14&#39;,
    displayName: &#39;CLIP ViT-L/14&#39;,
    description: &#39;Multimodal vision-language model for zero-shot classification&#39;,
    category: &#39;vision_classification&#39;,
    specialty: &#39;image_classification&#39;,
    image: &#39;pytorch-inference:2.1-transformers4.36-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g5.2xlarge&#39;,
    environment: { HF_MODEL_ID: &#39;openai/clip-vit-large-patch14&#39;, HF_TASK: &#39;zero-shot-image-classification&#39; },
    parameters: 428_000_000,
    accuracy: &#39;76.2% ImageNet Zero-Shot&#39;,
    capabilities: [&#39;zero_shot_classification&#39;, &#39;image_text_matching&#39;],
    inputFormats: [&#39;image/jpeg&#39;, &#39;image/png&#39;],
    outputFormats: [&#39;application/json&#39;],
    thermal: { defaultState: &#39;COLD&#39;, scaleToZeroAfterMinutes: 15, warmupTimeSeconds: 90, minInstances: 0, maxInstances: 3 },
    license: &#39;MIT&#39;,
    pricing: { hourlyRate: 2.66, perImage: 0.005, markup: 0.75 },
    minTier: 3, requiresGPU: true, gpuMemoryGB: 16, status: &#39;active&#39;,
  },
];

// ============================================================================
// OBJECT DETECTION MODELS (7 models)
// ============================================================================

export const DETECTION_MODELS: SageMakerModelConfig[] = [
  {
    id: &#39;yolov8n&#39;,
    name: &#39;yolov8n&#39;,
    displayName: &#39;YOLOv8 Nano&#39;,
    description: &#39;Ultra-lightweight real-time object detection&#39;,
    category: &#39;vision_detection&#39;,
    specialty: &#39;object_detection&#39;,
    image: &#39;pytorch-inference:2.1-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g4dn.xlarge&#39;,
    environment: { MODEL_NAME: &#39;yolov8n&#39; },
    parameters: 3_200_000,
    benchmark: &#39;37.3 COCO mAP&#39;,
    capabilities: [&#39;object_detection&#39;, &#39;real_time&#39;],
    inputFormats: [&#39;image/jpeg&#39;, &#39;image/png&#39;, &#39;video/mp4&#39;],
    outputFormats: [&#39;application/json&#39;],
    thermal: { defaultState: &#39;COLD&#39;, scaleToZeroAfterMinutes: 15, warmupTimeSeconds: 30, minInstances: 0, maxInstances: 5 },
    license: &#39;AGPL-3.0&#39;,
    commercialUseNotes: &#39;Requires Ultralytics Enterprise License for commercial use&#39;,
    pricing: { hourlyRate: 1.30, perImage: 0.002, markup: 0.75 },
    minTier: 3, requiresGPU: true, gpuMemoryGB: 2, status: &#39;active&#39;,
  },
  {
    id: &#39;yolov8m&#39;,
    name: &#39;yolov8m&#39;,
    displayName: &#39;YOLOv8 Medium&#39;,
    description: &#39;Medium model for balanced performance&#39;,
    category: &#39;vision_detection&#39;,
    specialty: &#39;object_detection&#39;,
    image: &#39;pytorch-inference:2.1-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g5.xlarge&#39;,
    environment: { MODEL_NAME: &#39;yolov8m&#39; },
    parameters: 25_900_000,
    benchmark: &#39;50.2 COCO mAP&#39;,
    capabilities: [&#39;object_detection&#39;, &#39;real_time&#39;],
    inputFormats: [&#39;image/jpeg&#39;, &#39;image/png&#39;, &#39;video/mp4&#39;],
    outputFormats: [&#39;application/json&#39;],
    thermal: { defaultState: &#39;COLD&#39;, scaleToZeroAfterMinutes: 15, warmupTimeSeconds: 45, minInstances: 0, maxInstances: 5 },
    license: &#39;AGPL-3.0&#39;,
    commercialUseNotes: &#39;Requires Ultralytics Enterprise License for commercial use&#39;,
    pricing: { hourlyRate: 2.47, perImage: 0.004, markup: 0.75 },
    minTier: 3, requiresGPU: true, gpuMemoryGB: 8, status: &#39;active&#39;,
  },
  {
    id: &#39;yolov8x&#39;,
    name: &#39;yolov8x&#39;,
    displayName: &#39;YOLOv8 Extra Large&#39;,
    description: &#39;Largest YOLOv8 for maximum accuracy&#39;,
    category: &#39;vision_detection&#39;,
    specialty: &#39;object_detection&#39;,
    image: &#39;pytorch-inference:2.1-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g5.xlarge&#39;,
    environment: { MODEL_NAME: &#39;yolov8x&#39; },
    parameters: 68_200_000,
    benchmark: &#39;53.9 COCO mAP&#39;,
    capabilities: [&#39;object_detection&#39;, &#39;high_accuracy&#39;],
    inputFormats: [&#39;image/jpeg&#39;, &#39;image/png&#39;, &#39;video/mp4&#39;],
    outputFormats: [&#39;application/json&#39;],
    thermal: { defaultState: &#39;COLD&#39;, scaleToZeroAfterMinutes: 15, warmupTimeSeconds: 60, minInstances: 0, maxInstances: 3 },
    license: &#39;AGPL-3.0&#39;,
    commercialUseNotes: &#39;Requires Ultralytics Enterprise License for commercial use&#39;,
    pricing: { hourlyRate: 2.47, perImage: 0.006, markup: 0.75 },
    minTier: 3, requiresGPU: true, gpuMemoryGB: 12, status: &#39;active&#39;,
  },
  {
    id: &#39;yolov11x&#39;,
    name: &#39;yolov11x&#39;,
    displayName: &#39;YOLOv11 Extra Large&#39;,
    description: &#39;Latest YOLO with improved architecture&#39;,
    category: &#39;vision_detection&#39;,
    specialty: &#39;object_detection&#39;,
    image: &#39;pytorch-inference:2.1-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g5.xlarge&#39;,
    environment: { MODEL_NAME: &#39;yolo11x&#39; },
    parameters: 40_000_000,
    benchmark: &#39;54.7 COCO mAP&#39;,
    capabilities: [&#39;object_detection&#39;, &#39;real_time&#39;, &#39;high_accuracy&#39;],
    inputFormats: [&#39;image/jpeg&#39;, &#39;image/png&#39;, &#39;video/mp4&#39;],
    outputFormats: [&#39;application/json&#39;],
    thermal: { defaultState: &#39;COLD&#39;, scaleToZeroAfterMinutes: 15, warmupTimeSeconds: 60, minInstances: 0, maxInstances: 3 },
    license: &#39;AGPL-3.0&#39;,
    commercialUseNotes: &#39;Requires Ultralytics Enterprise License for commercial use&#39;,
    pricing: { hourlyRate: 2.47, perImage: 0.006, markup: 0.75 },
    minTier: 3, requiresGPU: true, gpuMemoryGB: 10, status: &#39;active&#39;,
  },
  {
    id: &#39;rt-detr-x&#39;,
    name: &#39;rt-detr-x&#39;,
    displayName: &#39;RT-DETR-X&#39;,
    description: &#39;Real-time Detection Transformer (no NMS)&#39;,
    category: &#39;vision_detection&#39;,
    specialty: &#39;object_detection&#39;,
    image: &#39;pytorch-inference:2.1-transformers4.36-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g5.xlarge&#39;,
    environment: { HF_MODEL_ID: &#39;PekingU/rtdetr_r101vd&#39;, HF_TASK: &#39;object-detection&#39; },
    parameters: 40_000_000,
    benchmark: &#39;54.8 COCO mAP&#39;,
    capabilities: [&#39;object_detection&#39;, &#39;real_time&#39;, &#39;end_to_end&#39;],
    inputFormats: [&#39;image/jpeg&#39;, &#39;image/png&#39;],
    outputFormats: [&#39;application/json&#39;],
    thermal: { defaultState: &#39;COLD&#39;, scaleToZeroAfterMinutes: 15, warmupTimeSeconds: 60, minInstances: 0, maxInstances: 3 },
    license: &#39;Apache-2.0&#39;,
    pricing: { hourlyRate: 2.47, perImage: 0.005, markup: 0.75 },
    minTier: 3, requiresGPU: true, gpuMemoryGB: 10, status: &#39;active&#39;,
  },
  {
    id: &#39;grounding-dino&#39;,
    name: &#39;grounding-dino&#39;,
    displayName: &#39;Grounding DINO&#39;,
    description: &#39;Open-vocabulary object detection with text prompts&#39;,
    category: &#39;vision_detection&#39;,
    specialty: &#39;object_detection&#39;,
    image: &#39;pytorch-inference:2.1-transformers4.36-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g5.2xlarge&#39;,
    environment: { HF_MODEL_ID: &#39;IDEA-Research/grounding-dino-base&#39;, HF_TASK: &#39;zero-shot-object-detection&#39; },
    parameters: 172_000_000,
    benchmark: &#39;52.5 COCO Zero-Shot&#39;,
    capabilities: [&#39;zero_shot_detection&#39;, &#39;text_prompted&#39;, &#39;open_vocabulary&#39;],
    inputFormats: [&#39;image/jpeg&#39;, &#39;image/png&#39;],
    outputFormats: [&#39;application/json&#39;],
    thermal: { defaultState: &#39;COLD&#39;, scaleToZeroAfterMinutes: 15, warmupTimeSeconds: 90, minInstances: 0, maxInstances: 3 },
    license: &#39;Apache-2.0&#39;,
    pricing: { hourlyRate: 2.66, perImage: 0.008, markup: 0.75 },
    minTier: 3, requiresGPU: true, gpuMemoryGB: 16, status: &#39;active&#39;,
  },
];

// ============================================================================
// SEGMENTATION MODELS (4 models)
// ============================================================================

export const SEGMENTATION_MODELS: SageMakerModelConfig[] = [
  {
    id: &#39;sam-vit-h&#39;,
    name: &#39;sam-vit-h&#39;,
    displayName: &#39;SAM ViT-H&#39;,
    description: &#39;Segment Anything Model - largest variant&#39;,
    category: &#39;vision_segmentation&#39;,
    specialty: &#39;instance_segmentation&#39;,
    image: &#39;pytorch-inference:2.1-transformers4.36-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g5.4xlarge&#39;,
    environment: { HF_MODEL_ID: &#39;facebook/sam-vit-huge&#39;, HF_TASK: &#39;mask-generation&#39; },
    parameters: 636_000_000,
    capabilities: [&#39;instance_segmentation&#39;, &#39;interactive&#39;, &#39;zero_shot&#39;],
    inputFormats: [&#39;image/jpeg&#39;, &#39;image/png&#39;],
    outputFormats: [&#39;application/json&#39;, &#39;image/png&#39;],
    thermal: { defaultState: &#39;COLD&#39;, scaleToZeroAfterMinutes: 15, warmupTimeSeconds: 120, minInstances: 0, maxInstances: 3 },
    license: &#39;Apache-2.0&#39;,
    pricing: { hourlyRate: 3.55, perImage: 0.015, markup: 0.75 },
    minTier: 4, requiresGPU: true, gpuMemoryGB: 20, status: &#39;active&#39;,
  },
  {
    id: &#39;sam2&#39;,
    name: &#39;sam2&#39;,
    displayName: &#39;SAM 2&#39;,
    description: &#39;Segment Anything Model 2 with video support&#39;,
    category: &#39;vision_segmentation&#39;,
    specialty: &#39;instance_segmentation&#39;,
    image: &#39;pytorch-inference:2.1-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g5.4xlarge&#39;,
    environment: { MODEL_NAME: &#39;sam2_hiera_large&#39; },
    parameters: 224_000_000,
    capabilities: [&#39;instance_segmentation&#39;, &#39;video_segmentation&#39;, &#39;interactive&#39;, &#39;zero_shot&#39;],
    inputFormats: [&#39;image/jpeg&#39;, &#39;image/png&#39;, &#39;video/mp4&#39;],
    outputFormats: [&#39;application/json&#39;, &#39;image/png&#39;, &#39;video/mp4&#39;],
    thermal: { defaultState: &#39;COLD&#39;, scaleToZeroAfterMinutes: 15, warmupTimeSeconds: 120, minInstances: 0, maxInstances: 3 },
    license: &#39;Apache-2.0&#39;,
    pricing: { hourlyRate: 3.55, perImage: 0.012, perMinuteVideo: 0.50, markup: 0.75 },
    minTier: 4, requiresGPU: true, gpuMemoryGB: 16, status: &#39;active&#39;,
  },
  {
    id: &#39;mobilesam&#39;,
    name: &#39;mobilesam&#39;,
    displayName: &#39;MobileSAM&#39;,
    description: &#39;Lightweight SAM for fast inference&#39;,
    category: &#39;vision_segmentation&#39;,
    specialty: &#39;instance_segmentation&#39;,
    image: &#39;pytorch-inference:2.1-transformers4.36-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g4dn.xlarge&#39;,
    environment: { HF_MODEL_ID: &#39;dhkim2810/mobilesam&#39;, HF_TASK: &#39;mask-generation&#39; },
    parameters: 10_000_000,
    capabilities: [&#39;instance_segmentation&#39;, &#39;interactive&#39;, &#39;fast&#39;],
    inputFormats: [&#39;image/jpeg&#39;, &#39;image/png&#39;],
    outputFormats: [&#39;application/json&#39;, &#39;image/png&#39;],
    thermal: { defaultState: &#39;COLD&#39;, scaleToZeroAfterMinutes: 15, warmupTimeSeconds: 30, minInstances: 0, maxInstances: 5 },
    license: &#39;Apache-2.0&#39;,
    pricing: { hourlyRate: 1.30, perImage: 0.004, markup: 0.75 },
    minTier: 3, requiresGPU: true, gpuMemoryGB: 4, status: &#39;active&#39;,
  },
  {
    id: &#39;mask-rcnn&#39;,
    name: &#39;mask-rcnn&#39;,
    displayName: &#39;Mask R-CNN&#39;,
    description: &#39;Classic instance segmentation model&#39;,
    category: &#39;vision_segmentation&#39;,
    specialty: &#39;instance_segmentation&#39;,
    image: &#39;pytorch-inference:2.1-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g5.xlarge&#39;,
    environment: { MODEL_NAME: &#39;mask_rcnn_R_101_FPN_3x&#39;, DETECTRON2_CONFIG: &#39;COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml&#39; },
    parameters: 63_000_000,
    benchmark: &#39;42.9 COCO AP&#39;,
    capabilities: [&#39;instance_segmentation&#39;, &#39;object_detection&#39;],
    inputFormats: [&#39;image/jpeg&#39;, &#39;image/png&#39;],
    outputFormats: [&#39;application/json&#39;, &#39;image/png&#39;],
    thermal: { defaultState: &#39;COLD&#39;, scaleToZeroAfterMinutes: 15, warmupTimeSeconds: 60, minInstances: 0, maxInstances: 3 },
    license: &#39;Apache-2.0&#39;,
    pricing: { hourlyRate: 2.47, perImage: 0.006, markup: 0.75 },
    minTier: 3, requiresGPU: true, gpuMemoryGB: 8, status: &#39;active&#39;,
  },
];

// Export all vision models
export const ALL_VISION_MODELS = [...CLASSIFICATION_MODELS, ...DETECTION_MODELS, ...SEGMENTATION_MODELS];</code></pre>
<h3 id="packagesinfrastructurelibconfigmodelsaudio.models.ts">packages/infrastructure/lib/config/models/audio.models.ts</h3>
<pre class="typescript"><code>/**
 * Audio &amp; Speech Models - STT, Speaker Recognition
 */

import { SageMakerModelConfig, INSTANCE_PRICING } from &#39;./index&#39;;

// ============================================================================
// SPEECH-TO-TEXT MODELS (3 models)
// ============================================================================

export const STT_MODELS: SageMakerModelConfig[] = [
  {
    id: &#39;parakeet-tdt-1b&#39;,
    name: &#39;parakeet-tdt-1b&#39;,
    displayName: &#39;NVIDIA Parakeet TDT 1.1B&#39;,
    description: &#39;State-of-the-art ASR with 4.4% WER on LibriSpeech&#39;,
    category: &#39;audio_stt&#39;,
    specialty: &#39;speech_to_text&#39;,
    image: &#39;pytorch-inference:2.1-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g5.xlarge&#39;,
    environment: { MODEL_NAME: &#39;nvidia/parakeet-tdt-1.1b&#39; },
    parameters: 1_100_000_000,
    accuracy: &#39;4.4% WER LibriSpeech test-clean&#39;,
    capabilities: [&#39;speech_to_text&#39;, &#39;english&#39;, &#39;real_time&#39;],
    inputFormats: [&#39;audio/wav&#39;, &#39;audio/mp3&#39;, &#39;audio/flac&#39;],
    outputFormats: [&#39;application/json&#39;, &#39;text/plain&#39;],
    thermal: { defaultState: &#39;COLD&#39;, scaleToZeroAfterMinutes: 15, warmupTimeSeconds: 90, minInstances: 0, maxInstances: 3 },
    license: &#39;CC-BY-4.0&#39;,
    pricing: { hourlyRate: 2.47, perMinuteAudio: 0.03, markup: 0.75 },
    minTier: 3, requiresGPU: true, gpuMemoryGB: 10, status: &#39;active&#39;,
  },
  {
    id: &#39;whisper-large-v3&#39;,
    name: &#39;whisper-large-v3&#39;,
    displayName: &#39;OpenAI Whisper Large V3&#39;,
    description: &#39;Multilingual speech recognition and translation&#39;,
    category: &#39;audio_stt&#39;,
    specialty: &#39;speech_to_text&#39;,
    image: &#39;pytorch-inference:2.1-transformers4.36-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g5.xlarge&#39;,
    environment: { HF_MODEL_ID: &#39;openai/whisper-large-v3&#39;, HF_TASK: &#39;automatic-speech-recognition&#39; },
    parameters: 1_550_000_000,
    accuracy: &#39;5.0% WER LibriSpeech test-clean&#39;,
    capabilities: [&#39;speech_to_text&#39;, &#39;multilingual&#39;, &#39;translation&#39;, &#39;timestamps&#39;],
    inputFormats: [&#39;audio/wav&#39;, &#39;audio/mp3&#39;, &#39;audio/flac&#39;, &#39;audio/m4a&#39;],
    outputFormats: [&#39;application/json&#39;, &#39;text/plain&#39;, &#39;text/vtt&#39;, &#39;text/srt&#39;],
    thermal: { defaultState: &#39;COLD&#39;, scaleToZeroAfterMinutes: 15, warmupTimeSeconds: 90, minInstances: 0, maxInstances: 3 },
    license: &#39;MIT&#39;,
    pricing: { hourlyRate: 2.47, perMinuteAudio: 0.04, markup: 0.75 },
    minTier: 3, requiresGPU: true, gpuMemoryGB: 10, status: &#39;active&#39;,
  },
  {
    id: &#39;whisper-turbo&#39;,
    name: &#39;whisper-turbo&#39;,
    displayName: &#39;OpenAI Whisper Turbo&#39;,
    description: &#39;Fast multilingual ASR with 8x speed improvement&#39;,
    category: &#39;audio_stt&#39;,
    specialty: &#39;speech_to_text&#39;,
    image: &#39;pytorch-inference:2.1-transformers4.36-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g4dn.xlarge&#39;,
    environment: { HF_MODEL_ID: &#39;openai/whisper-large-v3-turbo&#39;, HF_TASK: &#39;automatic-speech-recognition&#39; },
    parameters: 809_000_000,
    accuracy: &#39;5.5% WER LibriSpeech test-clean&#39;,
    capabilities: [&#39;speech_to_text&#39;, &#39;multilingual&#39;, &#39;fast&#39;, &#39;real_time&#39;],
    inputFormats: [&#39;audio/wav&#39;, &#39;audio/mp3&#39;, &#39;audio/flac&#39;, &#39;audio/m4a&#39;],
    outputFormats: [&#39;application/json&#39;, &#39;text/plain&#39;],
    thermal: { defaultState: &#39;COLD&#39;, scaleToZeroAfterMinutes: 15, warmupTimeSeconds: 60, minInstances: 0, maxInstances: 5 },
    license: &#39;MIT&#39;,
    pricing: { hourlyRate: 1.30, perMinuteAudio: 0.02, markup: 0.75 },
    minTier: 3, requiresGPU: true, gpuMemoryGB: 6, status: &#39;active&#39;,
  },
];

// ============================================================================
// SPEAKER RECOGNITION MODELS (3 models)
// ============================================================================

export const SPEAKER_MODELS: SageMakerModelConfig[] = [
  {
    id: &#39;titanet-large&#39;,
    name: &#39;titanet-large&#39;,
    displayName: &#39;NVIDIA TitaNet-Large&#39;,
    description: &#39;Speaker verification and embedding extraction&#39;,
    category: &#39;audio_speaker&#39;,
    specialty: &#39;speaker_identification&#39;,
    image: &#39;pytorch-inference:2.1-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g4dn.xlarge&#39;,
    environment: { MODEL_NAME: &#39;nvidia/speakerverification_en_titanet_large&#39; },
    parameters: 23_000_000,
    accuracy: &#39;0.68% EER VoxCeleb1&#39;,
    capabilities: [&#39;speaker_verification&#39;, &#39;speaker_embedding&#39;, &#39;speaker_identification&#39;],
    inputFormats: [&#39;audio/wav&#39;, &#39;audio/mp3&#39;, &#39;audio/flac&#39;],
    outputFormats: [&#39;application/json&#39;],
    thermal: { defaultState: &#39;COLD&#39;, scaleToZeroAfterMinutes: 15, warmupTimeSeconds: 45, minInstances: 0, maxInstances: 3 },
    license: &#39;CC-BY-4.0&#39;,
    pricing: { hourlyRate: 1.30, perMinuteAudio: 0.02, markup: 0.75 },
    minTier: 3, requiresGPU: true, gpuMemoryGB: 4, status: &#39;active&#39;,
  },
  {
    id: &#39;ecapa-tdnn&#39;,
    name: &#39;ecapa-tdnn&#39;,
    displayName: &#39;ECAPA-TDNN&#39;,
    description: &#39;Emphasized channel attention for speaker verification&#39;,
    category: &#39;audio_speaker&#39;,
    specialty: &#39;speaker_identification&#39;,
    image: &#39;pytorch-inference:2.1-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g4dn.xlarge&#39;,
    environment: { MODEL_NAME: &#39;speechbrain/spkrec-ecapa-voxceleb&#39; },
    parameters: 20_800_000,
    accuracy: &#39;0.80% EER VoxCeleb1&#39;,
    capabilities: [&#39;speaker_verification&#39;, &#39;speaker_embedding&#39;],
    inputFormats: [&#39;audio/wav&#39;, &#39;audio/mp3&#39;, &#39;audio/flac&#39;],
    outputFormats: [&#39;application/json&#39;],
    thermal: { defaultState: &#39;COLD&#39;, scaleToZeroAfterMinutes: 15, warmupTimeSeconds: 45, minInstances: 0, maxInstances: 3 },
    license: &#39;Apache-2.0&#39;,
    pricing: { hourlyRate: 1.30, perMinuteAudio: 0.02, markup: 0.75 },
    minTier: 3, requiresGPU: true, gpuMemoryGB: 4, status: &#39;active&#39;,
  },
  {
    id: &#39;pyannote-speaker-diarization&#39;,
    name: &#39;pyannote-speaker-diarization&#39;,
    displayName: &#39;pyannote Speaker Diarization 3.1&#39;,
    description: &#39;Who spoke when - speaker diarization pipeline&#39;,
    category: &#39;audio_speaker&#39;,
    specialty: &#39;speaker_identification&#39;,
    image: &#39;pytorch-inference:2.1-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g5.xlarge&#39;,
    environment: { MODEL_NAME: &#39;pyannote/speaker-diarization-3.1&#39; },
    parameters: 0,
    accuracy: &#39;18.4% DER AMI Mix-Headset&#39;,
    capabilities: [&#39;speaker_diarization&#39;, &#39;speaker_counting&#39;, &#39;overlap_detection&#39;],
    inputFormats: [&#39;audio/wav&#39;, &#39;audio/mp3&#39;, &#39;audio/flac&#39;],
    outputFormats: [&#39;application/json&#39;, &#39;text/rttm&#39;],
    thermal: { defaultState: &#39;COLD&#39;, scaleToZeroAfterMinutes: 15, warmupTimeSeconds: 60, minInstances: 0, maxInstances: 3 },
    license: &#39;MIT&#39;,
    commercialUseNotes: &#39;Requires pyannote/speaker-diarization access grant&#39;,
    pricing: { hourlyRate: 2.47, perMinuteAudio: 0.05, markup: 0.75 },
    minTier: 3, requiresGPU: true, gpuMemoryGB: 8, status: &#39;active&#39;,
  },
];

export const ALL_AUDIO_MODELS = [...STT_MODELS, ...SPEAKER_MODELS];</code></pre>
<h3 id="packagesinfrastructurelibconfigmodelsscientific.models.ts">packages/infrastructure/lib/config/models/scientific.models.ts</h3>
<pre class="typescript"><code>/**
 * Scientific Computing Models - Protein folding, embeddings, math reasoning
 */

import { SageMakerModelConfig, INSTANCE_PRICING } from &#39;./index&#39;;

export const SCIENTIFIC_MODELS: SageMakerModelConfig[] = [
  {
    id: &#39;alphafold2&#39;,
    name: &#39;alphafold2&#39;,
    displayName: &#39;AlphaFold 2&#39;,
    description: &#39;Protein structure prediction with near-experimental accuracy&#39;,
    category: &#39;scientific_protein&#39;,
    specialty: &#39;protein_folding&#39;,
    image: &#39;pytorch-inference:2.1-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g5.12xlarge&#39;,
    environment: { MODEL_NAME: &#39;alphafold2_ptm&#39;, JAX_PLATFORM_NAME: &#39;gpu&#39; },
    parameters: 93_000_000,
    accuracy: &#39;GDT &gt; 90 on CASP14&#39;,
    capabilities: [&#39;protein_folding&#39;, &#39;structure_prediction&#39;, &#39;confidence_estimation&#39;],
    inputFormats: [&#39;text/fasta&#39;, &#39;text/plain&#39;],
    outputFormats: [&#39;application/pdb&#39;, &#39;application/mmcif&#39;, &#39;application/json&#39;],
    thermal: { defaultState: &#39;OFF&#39;, scaleToZeroAfterMinutes: 10, warmupTimeSeconds: 180, minInstances: 0, maxInstances: 2 },
    license: &#39;Apache-2.0&#39;,
    pricing: { hourlyRate: 14.28, perRequest: 2.00, markup: 0.75 },
    minTier: 4, requiresGPU: true, gpuMemoryGB: 96, status: &#39;active&#39;,
  },
  {
    id: &#39;esm2-3b&#39;,
    name: &#39;esm2-3b&#39;,
    displayName: &#39;ESM-2 3B&#39;,
    description: &#39;Protein language model for embeddings and analysis&#39;,
    category: &#39;scientific_protein&#39;,
    specialty: &#39;protein_embeddings&#39;,
    image: &#39;pytorch-inference:2.1-transformers4.36-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g5.4xlarge&#39;,
    environment: { HF_MODEL_ID: &#39;facebook/esm2_t36_3B_UR50D&#39; },
    parameters: 3_000_000_000,
    capabilities: [&#39;protein_embedding&#39;, &#39;sequence_analysis&#39;, &#39;structure_prediction&#39;],
    inputFormats: [&#39;text/fasta&#39;, &#39;text/plain&#39;],
    outputFormats: [&#39;application/json&#39;],
    thermal: { defaultState: &#39;OFF&#39;, scaleToZeroAfterMinutes: 10, warmupTimeSeconds: 120, minInstances: 0, maxInstances: 2 },
    license: &#39;MIT&#39;,
    pricing: { hourlyRate: 3.55, perRequest: 0.50, markup: 0.75 },
    minTier: 4, requiresGPU: true, gpuMemoryGB: 20, status: &#39;active&#39;,
  },
  {
    id: &#39;alphageometry&#39;,
    name: &#39;alphageometry&#39;,
    displayName: &#39;AlphaGeometry&#39;,
    description: &#39;Olympiad-level geometry problem solver&#39;,
    category: &#39;scientific_math&#39;,
    specialty: &#39;geometry_reasoning&#39;,
    image: &#39;pytorch-inference:2.1-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g5.2xlarge&#39;,
    environment: { MODEL_NAME: &#39;alphageometry&#39; },
    parameters: 150_000_000,
    accuracy: &#39;25/30 IMO geometry problems&#39;,
    capabilities: [&#39;geometry_solving&#39;, &#39;proof_generation&#39;, &#39;theorem_proving&#39;],
    inputFormats: [&#39;application/json&#39;, &#39;text/plain&#39;],
    outputFormats: [&#39;application/json&#39;, &#39;text/plain&#39;],
    thermal: { defaultState: &#39;OFF&#39;, scaleToZeroAfterMinutes: 10, warmupTimeSeconds: 90, minInstances: 0, maxInstances: 2 },
    license: &#39;Apache-2.0&#39;,
    pricing: { hourlyRate: 2.66, perRequest: 0.30, markup: 0.75 },
    minTier: 4, requiresGPU: true, gpuMemoryGB: 16, status: &#39;active&#39;,
  },
  {
    id: &#39;protenix&#39;,
    name: &#39;protenix&#39;,
    displayName: &#39;Protenix&#39;,
    description: &#39;Open-source AlphaFold3-like structure prediction&#39;,
    category: &#39;scientific_protein&#39;,
    specialty: &#39;protein_folding&#39;,
    image: &#39;pytorch-inference:2.1-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g5.12xlarge&#39;,
    environment: { MODEL_NAME: &#39;protenix&#39; },
    parameters: 0,
    capabilities: [&#39;protein_folding&#39;, &#39;dna_rna_binding&#39;, &#39;ligand_binding&#39;, &#39;multi_chain&#39;],
    inputFormats: [&#39;text/fasta&#39;, &#39;application/json&#39;],
    outputFormats: [&#39;application/pdb&#39;, &#39;application/mmcif&#39;, &#39;application/json&#39;],
    thermal: { defaultState: &#39;OFF&#39;, scaleToZeroAfterMinutes: 10, warmupTimeSeconds: 180, minInstances: 0, maxInstances: 2 },
    license: &#39;Apache-2.0&#39;,
    pricing: { hourlyRate: 14.28, perRequest: 2.50, markup: 0.75 },
    minTier: 4, requiresGPU: true, gpuMemoryGB: 96, status: &#39;beta&#39;,
  },
];</code></pre>
<h3 id="packagesinfrastructurelibconfigmodelsmedical.models.ts">packages/infrastructure/lib/config/models/medical.models.ts</h3>
<pre class="typescript"><code>/**
 * Medical Imaging Models - HIPAA-compliant medical image analysis
 */

import { SageMakerModelConfig, INSTANCE_PRICING } from &#39;./index&#39;;

export const MEDICAL_MODELS: SageMakerModelConfig[] = [
  {
    id: &#39;nnunet&#39;,
    name: &#39;nnunet&#39;,
    displayName: &#39;nnU-Net&#39;,
    description: &#39;Self-configuring medical image segmentation&#39;,
    category: &#39;medical_imaging&#39;,
    specialty: &#39;medical_segmentation&#39;,
    image: &#39;pytorch-inference:2.1-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g5.2xlarge&#39;,
    environment: { MODEL_NAME: &#39;nnunet&#39;, NNUNET_DATASET: &#39;generic&#39; },
    parameters: 31_000_000,
    accuracy: &#39;State-of-the-art on 23/23 Medical Segmentation Decathlon tasks&#39;,
    capabilities: [&#39;medical_segmentation&#39;, &#39;tumor_detection&#39;, &#39;organ_segmentation&#39;, &#39;3d_imaging&#39;],
    inputFormats: [&#39;application/dicom&#39;, &#39;application/nifti&#39;, &#39;image/png&#39;],
    outputFormats: [&#39;application/nifti&#39;, &#39;application/json&#39;, &#39;image/png&#39;],
    thermal: { defaultState: &#39;OFF&#39;, scaleToZeroAfterMinutes: 10, warmupTimeSeconds: 120, minInstances: 0, maxInstances: 2 },
    license: &#39;Apache-2.0&#39;,
    commercialUseNotes: &#39;HIPAA compliant when deployed in compliant AWS environment&#39;,
    pricing: { hourlyRate: 2.66, perImage: 0.10, markup: 0.75 },
    minTier: 4, requiresGPU: true, gpuMemoryGB: 16, status: &#39;active&#39;,
  },
  {
    id: &#39;medsam&#39;,
    name: &#39;medsam&#39;,
    displayName: &#39;MedSAM&#39;,
    description: &#39;Segment Anything Model fine-tuned for medical images&#39;,
    category: &#39;medical_imaging&#39;,
    specialty: &#39;medical_segmentation&#39;,
    image: &#39;pytorch-inference:2.1-transformers4.36-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g5.2xlarge&#39;,
    environment: { HF_MODEL_ID: &#39;wanglab/medsam-vit-base&#39;, HF_TASK: &#39;mask-generation&#39; },
    parameters: 93_000_000,
    capabilities: [&#39;medical_segmentation&#39;, &#39;interactive&#39;, &#39;multi_modality&#39;],
    inputFormats: [&#39;application/dicom&#39;, &#39;application/nifti&#39;, &#39;image/png&#39;, &#39;image/jpeg&#39;],
    outputFormats: [&#39;application/json&#39;, &#39;image/png&#39;],
    thermal: { defaultState: &#39;OFF&#39;, scaleToZeroAfterMinutes: 10, warmupTimeSeconds: 90, minInstances: 0, maxInstances: 2 },
    license: &#39;Apache-2.0&#39;,
    commercialUseNotes: &#39;HIPAA compliant when deployed in compliant AWS environment&#39;,
    pricing: { hourlyRate: 2.66, perImage: 0.08, markup: 0.75 },
    minTier: 4, requiresGPU: true, gpuMemoryGB: 12, status: &#39;active&#39;,
  },
];</code></pre>
<h3 id="packagesinfrastructurelibconfigmodelsgeospatial.models.ts">packages/infrastructure/lib/config/models/geospatial.models.ts</h3>
<pre class="typescript"><code>/**
 * Geospatial Analysis Models - Satellite imagery and earth observation
 */

import { SageMakerModelConfig, INSTANCE_PRICING } from &#39;./index&#39;;

export const GEOSPATIAL_MODELS: SageMakerModelConfig[] = [
  {
    id: &#39;prithvi-100m&#39;,
    name: &#39;prithvi-100m&#39;,
    displayName: &#39;Prithvi 100M&#39;,
    description: &#39;NASA/IBM geospatial foundation model (100M parameters)&#39;,
    category: &#39;geospatial&#39;,
    specialty: &#39;satellite_analysis&#39;,
    image: &#39;pytorch-inference:2.1-transformers4.36-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g5.xlarge&#39;,
    environment: { HF_MODEL_ID: &#39;ibm-nasa-geospatial/Prithvi-100M&#39; },
    parameters: 100_000_000,
    capabilities: [&#39;satellite_analysis&#39;, &#39;land_use&#39;, &#39;flood_detection&#39;, &#39;crop_mapping&#39;],
    inputFormats: [&#39;image/tiff&#39;, &#39;image/geotiff&#39;, &#39;image/png&#39;],
    outputFormats: [&#39;application/json&#39;, &#39;image/geotiff&#39;],
    thermal: { defaultState: &#39;OFF&#39;, scaleToZeroAfterMinutes: 10, warmupTimeSeconds: 90, minInstances: 0, maxInstances: 2 },
    license: &#39;Apache-2.0&#39;,
    pricing: { hourlyRate: 2.47, perImage: 0.05, markup: 0.75 },
    minTier: 4, requiresGPU: true, gpuMemoryGB: 10, status: &#39;active&#39;,
  },
  {
    id: &#39;prithvi-600m&#39;,
    name: &#39;prithvi-600m&#39;,
    displayName: &#39;Prithvi 600M&#39;,
    description: &#39;NASA/IBM geospatial foundation model (600M parameters)&#39;,
    category: &#39;geospatial&#39;,
    specialty: &#39;satellite_analysis&#39;,
    image: &#39;pytorch-inference:2.1-transformers4.36-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g5.4xlarge&#39;,
    environment: { HF_MODEL_ID: &#39;ibm-nasa-geospatial/Prithvi-EO-2.0-600M&#39; },
    parameters: 600_000_000,
    capabilities: [&#39;satellite_analysis&#39;, &#39;land_use&#39;, &#39;flood_detection&#39;, &#39;crop_mapping&#39;, &#39;change_detection&#39;],
    inputFormats: [&#39;image/tiff&#39;, &#39;image/geotiff&#39;, &#39;image/png&#39;],
    outputFormats: [&#39;application/json&#39;, &#39;image/geotiff&#39;],
    thermal: { defaultState: &#39;OFF&#39;, scaleToZeroAfterMinutes: 10, warmupTimeSeconds: 120, minInstances: 0, maxInstances: 2 },
    license: &#39;Apache-2.0&#39;,
    pricing: { hourlyRate: 3.55, perImage: 0.10, markup: 0.75 },
    minTier: 4, requiresGPU: true, gpuMemoryGB: 20, status: &#39;active&#39;,
  },
];</code></pre>
<h3 id="packagesinfrastructurelibconfigmodelsgenerative.models.ts">packages/infrastructure/lib/config/models/generative.models.ts</h3>
<pre class="typescript"><code>/**
 * 3D &amp; Generative Models - 3D reconstruction, self-hosted LLMs
 */

import { SageMakerModelConfig, INSTANCE_PRICING } from &#39;./index&#39;;

export const GENERATIVE_3D_MODELS: SageMakerModelConfig[] = [
  {
    id: &#39;nerfstudio&#39;,
    name: &#39;nerfstudio&#39;,
    displayName: &#39;Nerfstudio&#39;,
    description: &#39;Neural Radiance Fields for 3D scene reconstruction&#39;,
    category: &#39;generative_3d&#39;,
    specialty: &#39;3d_reconstruction&#39;,
    image: &#39;pytorch-inference:2.1-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g5.4xlarge&#39;,
    environment: { MODEL_NAME: &#39;nerfstudio&#39;, NERFSTUDIO_METHOD: &#39;nerfacto&#39; },
    parameters: 0,
    capabilities: [&#39;3d_reconstruction&#39;, &#39;novel_view_synthesis&#39;, &#39;scene_capture&#39;],
    inputFormats: [&#39;video/mp4&#39;, &#39;image/jpeg&#39;, &#39;image/png&#39;],
    outputFormats: [&#39;model/gltf+json&#39;, &#39;model/obj&#39;, &#39;video/mp4&#39;],
    thermal: { defaultState: &#39;OFF&#39;, scaleToZeroAfterMinutes: 10, warmupTimeSeconds: 120, minInstances: 0, maxInstances: 2 },
    license: &#39;Apache-2.0&#39;,
    pricing: { hourlyRate: 3.55, per3DModel: 5.00, markup: 0.75 },
    minTier: 4, requiresGPU: true, gpuMemoryGB: 24, status: &#39;active&#39;,
  },
  {
    id: &#39;3d-gaussian-splatting&#39;,
    name: &#39;3d-gaussian-splatting&#39;,
    displayName: &#39;3D Gaussian Splatting&#39;,
    description: &#39;Real-time radiance field rendering with 3D Gaussians&#39;,
    category: &#39;generative_3d&#39;,
    specialty: &#39;3d_reconstruction&#39;,
    image: &#39;pytorch-inference:2.1-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g5.4xlarge&#39;,
    environment: { MODEL_NAME: &#39;3dgs&#39; },
    parameters: 0,
    capabilities: [&#39;3d_reconstruction&#39;, &#39;real_time_rendering&#39;, &#39;novel_view_synthesis&#39;],
    inputFormats: [&#39;video/mp4&#39;, &#39;image/jpeg&#39;, &#39;image/png&#39;],
    outputFormats: [&#39;model/ply&#39;, &#39;model/gltf+json&#39;, &#39;video/mp4&#39;],
    thermal: { defaultState: &#39;OFF&#39;, scaleToZeroAfterMinutes: 10, warmupTimeSeconds: 120, minInstances: 0, maxInstances: 2 },
    license: &#39;Custom&#39;,
    commercialUseNotes: &#39;Check license for commercial use terms&#39;,
    pricing: { hourlyRate: 3.55, per3DModel: 4.00, markup: 0.75 },
    minTier: 4, requiresGPU: true, gpuMemoryGB: 24, status: &#39;active&#39;,
  },
];

export const TEXT_GENERATION_MODELS: SageMakerModelConfig[] = [
  {
    id: &#39;mistral-7b-instruct&#39;,
    name: &#39;mistral-7b-instruct&#39;,
    displayName: &#39;Mistral 7B Instruct&#39;,
    description: &#39;Efficient instruction-following model&#39;,
    category: &#39;llm_text&#39;,
    specialty: &#39;text_generation&#39;,
    image: &#39;huggingface-pytorch-tgi-inference:2.1-tgi1.4-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g5.xlarge&#39;,
    environment: { HF_MODEL_ID: &#39;mistralai/Mistral-7B-Instruct-v0.3&#39;, MAX_INPUT_LENGTH: &#39;4096&#39;, MAX_TOTAL_TOKENS: &#39;8192&#39; },
    parameters: 7_000_000_000,
    capabilities: [&#39;text_generation&#39;, &#39;instruction_following&#39;, &#39;function_calling&#39;],
    inputFormats: [&#39;application/json&#39;, &#39;text/plain&#39;],
    outputFormats: [&#39;application/json&#39;, &#39;text/plain&#39;],
    thermal: { defaultState: &#39;COLD&#39;, scaleToZeroAfterMinutes: 15, warmupTimeSeconds: 90, minInstances: 0, maxInstances: 3 },
    license: &#39;Apache-2.0&#39;,
    pricing: { hourlyRate: 2.47, perRequest: 0.005, markup: 0.75 },
    minTier: 3, requiresGPU: true, gpuMemoryGB: 16, status: &#39;active&#39;,
  },
  {
    id: &#39;llama-3-70b-instruct&#39;,
    name: &#39;llama-3-70b-instruct&#39;,
    displayName: &#39;Llama 3 70B Instruct&#39;,
    description: &#39;Large open-weight model for complex tasks&#39;,
    category: &#39;llm_text&#39;,
    specialty: &#39;text_generation&#39;,
    image: &#39;huggingface-pytorch-tgi-inference:2.1-tgi1.4-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g5.48xlarge&#39;,
    environment: { HF_MODEL_ID: &#39;meta-llama/Meta-Llama-3-70B-Instruct&#39;, MAX_INPUT_LENGTH: &#39;8192&#39;, MAX_TOTAL_TOKENS: &#39;16384&#39;, QUANTIZE: &#39;bitsandbytes&#39; },
    parameters: 70_000_000_000,
    capabilities: [&#39;text_generation&#39;, &#39;instruction_following&#39;, &#39;reasoning&#39;, &#39;code_generation&#39;],
    inputFormats: [&#39;application/json&#39;, &#39;text/plain&#39;],
    outputFormats: [&#39;application/json&#39;, &#39;text/plain&#39;],
    thermal: { defaultState: &#39;OFF&#39;, scaleToZeroAfterMinutes: 10, warmupTimeSeconds: 300, minInstances: 0, maxInstances: 2 },
    license: &#39;Llama 3 Community License&#39;,
    commercialUseNotes: &#39;Free for commercial use, attribution required&#39;,
    pricing: { hourlyRate: 35.63, perRequest: 0.05, markup: 0.75 },
    minTier: 5, requiresGPU: true, gpuMemoryGB: 160, status: &#39;active&#39;,
  },
  {
    id: &#39;qwen-72b-instruct&#39;,
    name: &#39;qwen-72b-instruct&#39;,
    displayName: &#39;Qwen 2.5 72B Instruct&#39;,
    description: &#39;State-of-the-art multilingual model&#39;,
    category: &#39;llm_text&#39;,
    specialty: &#39;text_generation&#39;,
    image: &#39;huggingface-pytorch-tgi-inference:2.1-tgi1.4-gpu-py310-cu121-ubuntu22.04&#39;,
    instanceType: &#39;ml.g5.48xlarge&#39;,
    environment: { HF_MODEL_ID: &#39;Qwen/Qwen2.5-72B-Instruct&#39;, MAX_INPUT_LENGTH: &#39;32768&#39;, MAX_TOTAL_TOKENS: &#39;65536&#39;, QUANTIZE: &#39;gptq&#39; },
    parameters: 72_000_000_000,
    capabilities: [&#39;text_generation&#39;, &#39;instruction_following&#39;, &#39;multilingual&#39;, &#39;long_context&#39;, &#39;code_generation&#39;],
    inputFormats: [&#39;application/json&#39;, &#39;text/plain&#39;],
    outputFormats: [&#39;application/json&#39;, &#39;text/plain&#39;],
    thermal: { defaultState: &#39;OFF&#39;, scaleToZeroAfterMinutes: 10, warmupTimeSeconds: 300, minInstances: 0, maxInstances: 2 },
    license: &#39;Apache-2.0&#39;,
    pricing: { hourlyRate: 35.63, perRequest: 0.05, markup: 0.75 },
    minTier: 5, requiresGPU: true, gpuMemoryGB: 160, status: &#39;active&#39;,
  },
];

export const ALL_GENERATIVE_MODELS = [...GENERATIVE_3D_MODELS, ...TEXT_GENERATION_MODELS];</code></pre>
<hr />
<h2 id="part-2-mid-level-services">PART 2: MID-LEVEL SERVICES</h2>
<h3 id="packagesinfrastructurelibconfigservicesindex.ts">packages/infrastructure/lib/config/services/index.ts</h3>
<pre class="typescript"><code>/**
 * Mid-Level Service Definitions
 * Services that orchestrate multiple AI models for domain-specific tasks
 */

export type ServiceState = &#39;RUNNING&#39; | &#39;DEGRADED&#39; | &#39;DISABLED&#39; | &#39;OFFLINE&#39;;

export interface MidLevelServiceConfig {
  id: string;
  name: string;
  displayName: string;
  description: string;
  requiredModels: string[];
  optionalModels: string[];
  defaultState: ServiceState;
  gracefulDegradation: boolean;
  pricing: ServicePricing;
  minTier: number;
  endpoints: ServiceEndpoint[];
}

export interface ServicePricing {
  perRequest?: number;
  perMinuteAudio?: number;
  perMinuteVideo?: number;
  perImage?: number;
  per3DModel?: number;
  markup: number;
}

export interface ServiceEndpoint {
  path: string;
  method: &#39;GET&#39; | &#39;POST&#39; | &#39;PUT&#39; | &#39;DELETE&#39;;
  description: string;
  requiredModels: string[];
  inputFormats: string[];
  outputFormats: string[];
}

export const SERVICE_STATE_COLORS: Record&lt;ServiceState, string&gt; = {
  RUNNING: &#39;#22c55e&#39;,    // green
  DEGRADED: &#39;#f59e0b&#39;,   // yellow
  DISABLED: &#39;#6b7280&#39;,   // gray
  OFFLINE: &#39;#ef4444&#39;,    // red
};</code></pre>
<h3 id="packagesinfrastructurelibconfigservicesperception.service.ts">packages/infrastructure/lib/config/services/perception.service.ts</h3>
<pre class="typescript"><code>/**
 * Perception Service - Unified computer vision pipeline
 */

import { MidLevelServiceConfig } from &#39;./index&#39;;

export const PERCEPTION_SERVICE: MidLevelServiceConfig = {
  id: &#39;perception&#39;,
  name: &#39;perception&#39;,
  displayName: &#39;Perception Service&#39;,
  description: &#39;Unified computer vision pipeline for detection, segmentation, and classification&#39;,
  requiredModels: [&#39;yolov8m&#39;, &#39;mobilesam&#39;],
  optionalModels: [&#39;yolov8x&#39;, &#39;yolov11x&#39;, &#39;sam-vit-h&#39;, &#39;sam2&#39;, &#39;clip-vit-l14&#39;, &#39;grounding-dino&#39;, &#39;efficientnetv2-l&#39;],
  defaultState: &#39;DISABLED&#39;,
  gracefulDegradation: true,
  pricing: { perImage: 0.02, perMinuteVideo: 0.50, markup: 0.40 },
  minTier: 3,
  endpoints: [
    { path: &#39;/perception/detect&#39;, method: &#39;POST&#39;, description: &#39;Detect objects in images&#39;, requiredModels: [&#39;yolov8m&#39;], inputFormats: [&#39;image/jpeg&#39;, &#39;image/png&#39;], outputFormats: [&#39;application/json&#39;] },
    { path: &#39;/perception/segment&#39;, method: &#39;POST&#39;, description: &#39;Segment objects or regions&#39;, requiredModels: [&#39;mobilesam&#39;], inputFormats: [&#39;image/jpeg&#39;, &#39;image/png&#39;], outputFormats: [&#39;application/json&#39;, &#39;image/png&#39;] },
    { path: &#39;/perception/classify&#39;, method: &#39;POST&#39;, description: &#39;Classify images&#39;, requiredModels: [&#39;efficientnetv2-l&#39;], inputFormats: [&#39;image/jpeg&#39;, &#39;image/png&#39;], outputFormats: [&#39;application/json&#39;] },
    { path: &#39;/perception/analyze&#39;, method: &#39;POST&#39;, description: &#39;Full perception pipeline&#39;, requiredModels: [&#39;yolov8m&#39;, &#39;mobilesam&#39;], inputFormats: [&#39;image/jpeg&#39;, &#39;image/png&#39;], outputFormats: [&#39;application/json&#39;] },
  ],
};</code></pre>
<h3 id="packagesinfrastructurelibconfigservicesscientific.service.ts">packages/infrastructure/lib/config/services/scientific.service.ts</h3>
<pre class="typescript"><code>/**
 * Scientific Computing Service - Protein analysis and math reasoning
 */

import { MidLevelServiceConfig } from &#39;./index&#39;;

export const SCIENTIFIC_SERVICE: MidLevelServiceConfig = {
  id: &#39;scientific&#39;,
  name: &#39;scientific&#39;,
  displayName: &#39;Scientific Computing Service&#39;,
  description: &#39;Protein folding, embeddings, and computational biology pipelines&#39;,
  requiredModels: [&#39;esm2-3b&#39;],
  optionalModels: [&#39;alphafold2&#39;, &#39;alphageometry&#39;, &#39;protenix&#39;],
  defaultState: &#39;DISABLED&#39;,
  gracefulDegradation: true,
  pricing: { perRequest: 0.50, markup: 0.40 },
  minTier: 4,
  endpoints: [
    { path: &#39;/scientific/protein/embed&#39;, method: &#39;POST&#39;, description: &#39;Generate protein embeddings&#39;, requiredModels: [&#39;esm2-3b&#39;], inputFormats: [&#39;text/fasta&#39;], outputFormats: [&#39;application/json&#39;] },
    { path: &#39;/scientific/protein/fold&#39;, method: &#39;POST&#39;, description: &#39;Predict protein 3D structure&#39;, requiredModels: [&#39;alphafold2&#39;], inputFormats: [&#39;text/fasta&#39;], outputFormats: [&#39;application/pdb&#39;, &#39;application/mmcif&#39;] },
    { path: &#39;/scientific/geometry/solve&#39;, method: &#39;POST&#39;, description: &#39;Solve geometry problems&#39;, requiredModels: [&#39;alphageometry&#39;], inputFormats: [&#39;application/json&#39;], outputFormats: [&#39;application/json&#39;] },
  ],
};</code></pre>
<h3 id="packagesinfrastructurelibconfigservicesmedical.service.ts">packages/infrastructure/lib/config/services/medical.service.ts</h3>
<pre class="typescript"><code>/**
 * Medical Imaging Service - HIPAA-compliant medical analysis
 */

import { MidLevelServiceConfig } from &#39;./index&#39;;

export const MEDICAL_SERVICE: MidLevelServiceConfig = {
  id: &#39;medical&#39;,
  name: &#39;medical&#39;,
  displayName: &#39;Medical Imaging Service&#39;,
  description: &#39;HIPAA-compliant medical image segmentation and analysis&#39;,
  requiredModels: [&#39;medsam&#39;],
  optionalModels: [&#39;nnunet&#39;, &#39;whisper-large-v3&#39;],
  defaultState: &#39;DISABLED&#39;,
  gracefulDegradation: true,
  pricing: { perImage: 0.15, perMinuteAudio: 0.08, markup: 0.40 },
  minTier: 4,
  endpoints: [
    { path: &#39;/medical/segment&#39;, method: &#39;POST&#39;, description: &#39;Segment anatomical structures&#39;, requiredModels: [&#39;medsam&#39;], inputFormats: [&#39;application/dicom&#39;, &#39;application/nifti&#39;], outputFormats: [&#39;application/nifti&#39;, &#39;application/json&#39;] },
    { path: &#39;/medical/segment/3d&#39;, method: &#39;POST&#39;, description: &#39;Volumetric 3D segmentation&#39;, requiredModels: [&#39;nnunet&#39;], inputFormats: [&#39;application/dicom&#39;, &#39;application/nifti&#39;], outputFormats: [&#39;application/nifti&#39;] },
    { path: &#39;/medical/transcribe&#39;, method: &#39;POST&#39;, description: &#39;Transcribe medical dictation&#39;, requiredModels: [&#39;whisper-large-v3&#39;], inputFormats: [&#39;audio/wav&#39;], outputFormats: [&#39;application/json&#39;] },
  ],
};</code></pre>
<h3 id="packagesinfrastructurelibconfigservicesgeospatial.service.ts">packages/infrastructure/lib/config/services/geospatial.service.ts</h3>
<pre class="typescript"><code>/**
 * Geospatial Analysis Service - Satellite imagery analysis
 */

import { MidLevelServiceConfig } from &#39;./index&#39;;

export const GEOSPATIAL_SERVICE: MidLevelServiceConfig = {
  id: &#39;geospatial&#39;,
  name: &#39;geospatial&#39;,
  displayName: &#39;Geospatial Analysis Service&#39;,
  description: &#39;Satellite imagery analysis for land use, flood detection, and crop mapping&#39;,
  requiredModels: [&#39;prithvi-100m&#39;],
  optionalModels: [&#39;prithvi-600m&#39;, &#39;mobilesam&#39;],
  defaultState: &#39;DISABLED&#39;,
  gracefulDegradation: true,
  pricing: { perImage: 0.08, markup: 0.40 },
  minTier: 4,
  endpoints: [
    { path: &#39;/geospatial/classify&#39;, method: &#39;POST&#39;, description: &#39;Classify land use&#39;, requiredModels: [&#39;prithvi-100m&#39;], inputFormats: [&#39;image/geotiff&#39;], outputFormats: [&#39;application/json&#39;] },
    { path: &#39;/geospatial/detect/floods&#39;, method: &#39;POST&#39;, description: &#39;Detect flood extent&#39;, requiredModels: [&#39;prithvi-100m&#39;], inputFormats: [&#39;image/geotiff&#39;], outputFormats: [&#39;application/json&#39;] },
    { path: &#39;/geospatial/change&#39;, method: &#39;POST&#39;, description: &#39;Detect changes between images&#39;, requiredModels: [&#39;prithvi-600m&#39;], inputFormats: [&#39;image/geotiff&#39;], outputFormats: [&#39;application/json&#39;] },
  ],
};</code></pre>
<h3 id="packagesinfrastructurelibconfigservicesreconstruction.service.ts">packages/infrastructure/lib/config/services/reconstruction.service.ts</h3>
<pre class="typescript"><code>/**
 * 3D Reconstruction Service - NeRF and 3D Gaussian Splatting
 */

import { MidLevelServiceConfig } from &#39;./index&#39;;

export const RECONSTRUCTION_SERVICE: MidLevelServiceConfig = {
  id: &#39;reconstruction&#39;,
  name: &#39;reconstruction&#39;,
  displayName: &#39;3D Reconstruction Service&#39;,
  description: &#39;Generate 3D models from images and videos using neural radiance fields&#39;,
  requiredModels: [&#39;nerfstudio&#39;],
  optionalModels: [&#39;3d-gaussian-splatting&#39;],
  defaultState: &#39;DISABLED&#39;,
  gracefulDegradation: true,
  pricing: { per3DModel: 8.00, markup: 0.40 },
  minTier: 4,
  endpoints: [
    { path: &#39;/reconstruction/nerf&#39;, method: &#39;POST&#39;, description: &#39;Create 3D model using NeRF&#39;, requiredModels: [&#39;nerfstudio&#39;], inputFormats: [&#39;video/mp4&#39;, &#39;image/jpeg&#39;], outputFormats: [&#39;model/gltf+json&#39;, &#39;model/obj&#39;] },
    { path: &#39;/reconstruction/gaussian&#39;, method: &#39;POST&#39;, description: &#39;Fast 3D using Gaussian splatting&#39;, requiredModels: [&#39;3d-gaussian-splatting&#39;], inputFormats: [&#39;video/mp4&#39;], outputFormats: [&#39;model/ply&#39;] },
    { path: &#39;/reconstruction/render&#39;, method: &#39;POST&#39;, description: &#39;Render novel views&#39;, requiredModels: [&#39;nerfstudio&#39;], inputFormats: [&#39;application/json&#39;], outputFormats: [&#39;image/png&#39;, &#39;video/mp4&#39;] },
  ],
};</code></pre>
<hr />
<h2 id="part-3-thermal-state-management">PART 3: THERMAL STATE MANAGEMENT</h2>
<h3 id="thermal-state-definitions">Thermal State Definitions</h3>
<table>
<thead>
<tr>
<th>State</th>
<th>Description</th>
<th>Instance Count</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>OFF</strong></td>
<td>Completely disabled</td>
<td>0</td>
<td>Not needed, cost savings</td>
</tr>
<tr>
<td><strong>COLD</strong></td>
<td>Scales to zero when idle</td>
<td>0 (on-demand)</td>
<td>Infrequent use</td>
</tr>
<tr>
<td><strong>WARM</strong></td>
<td>Minimum instances always running</td>
<td>min (1+)</td>
<td>Regular use</td>
</tr>
<tr>
<td><strong>HOT</strong></td>
<td>Pre-scaled for high traffic</td>
<td>min + buffer</td>
<td>High demand</td>
</tr>
<tr>
<td><strong>AUTOMATIC</strong></td>
<td>AI-managed scaling</td>
<td>dynamic</td>
<td>Variable workloads</td>
</tr>
</tbody>
</table>
<h3 id="packagesinfrastructurelambdathermalmanager.ts-summary">packages/infrastructure/lambda/thermal/manager.ts (Summary)</h3>
<pre class="typescript"><code>/**
 * Thermal State Manager Lambda
 * 
 * Key Functions:
 * - handleListModels(): List all models with thermal states
 * - handleGetModel(): Get specific model thermal state + metrics
 * - handleUpdateState(): Admin update thermal state
 * - handleBulkUpdate(): Bulk update multiple models
 * - handleWarmModel(): Request model warm-up (API users)
 * - handleScheduledCheck(): Auto-scaling and scale-to-zero logic
 * 
 * Scheduled Tasks (every 5 minutes):
 * - Check transition status
 * - Handle AUTOMATIC scaling based on metrics
 * - Scale to zero inactive WARM/HOT models
 */

// API Routes
// GET  /thermal/models          - List all models
// GET  /thermal/models/:id      - Get model details
// PUT  /thermal/models/:id      - Update thermal state
// POST /thermal/bulk            - Bulk update
// POST /thermal/warm/:id        - Request warm-up
// GET  /thermal/metrics         - Get summary metrics</code></pre>
<h3 id="packagesinfrastructurelambdathermalnotifier.ts-summary">packages/infrastructure/lambda/thermal/notifier.ts (Summary)</h3>
<pre class="typescript"><code>/**
 * Client Notification Lambda
 * 
 * Sends real-time notifications to clients via WebSocket when:
 * - Model warm-up starts
 * - Model becomes ready
 * - Model goes cold/offline
 * - Service state changes
 */</code></pre>
<hr />
<h2 id="part-4-database-schema">PART 4: DATABASE SCHEMA</h2>
<h3 id="packagesinfrastructuremigrations006_self_hosted_models.sql">packages/infrastructure/migrations/006_self_hosted_models.sql</h3>
<pre class="sql"><code>-- Self-Hosted Model Registry
CREATE TABLE IF NOT EXISTS self_hosted_models (
    id VARCHAR(100) PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    display_name VARCHAR(255) NOT NULL,
    description TEXT,
    category VARCHAR(50) NOT NULL,
    specialty VARCHAR(50) NOT NULL,
    sagemaker_image VARCHAR(500) NOT NULL,
    instance_type VARCHAR(50) NOT NULL,
    environment JSONB NOT NULL DEFAULT &#39;{}&#39;,
    parameters BIGINT,
    accuracy VARCHAR(100),
    capabilities TEXT[] NOT NULL DEFAULT &#39;{}&#39;,
    input_formats TEXT[] NOT NULL DEFAULT &#39;{}&#39;,
    output_formats TEXT[] NOT NULL DEFAULT &#39;{}&#39;,
    license VARCHAR(100) NOT NULL,
    commercial_use_notes TEXT,
    hourly_rate DECIMAL(10,4) NOT NULL,
    per_image DECIMAL(10,6),
    per_minute_audio DECIMAL(10,6),
    per_3d_model DECIMAL(10,4),
    markup_percent DECIMAL(5,2) NOT NULL DEFAULT 75.00,
    min_tier INTEGER NOT NULL DEFAULT 3,
    requires_gpu BOOLEAN NOT NULL DEFAULT true,
    gpu_memory_gb INTEGER NOT NULL,
    status VARCHAR(20) NOT NULL DEFAULT &#39;active&#39;,
    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()
);

-- Thermal States per app/environment
CREATE TABLE IF NOT EXISTS thermal_states (
    app_id VARCHAR(100) NOT NULL,
    environment VARCHAR(20) NOT NULL,
    model_id VARCHAR(100) NOT NULL REFERENCES self_hosted_models(id),
    current_state VARCHAR(20) NOT NULL DEFAULT &#39;COLD&#39;,
    target_state VARCHAR(20) NOT NULL DEFAULT &#39;COLD&#39;,
    instance_count INTEGER NOT NULL DEFAULT 0,
    min_instances INTEGER NOT NULL DEFAULT 0,
    max_instances INTEGER NOT NULL DEFAULT 3,
    last_activity TIMESTAMP WITH TIME ZONE,
    last_state_change TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
    scale_to_zero_after_minutes INTEGER NOT NULL DEFAULT 15,
    warmup_time_seconds INTEGER NOT NULL DEFAULT 60,
    is_transitioning BOOLEAN NOT NULL DEFAULT false,
    error_message TEXT,
    updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
    updated_by VARCHAR(100),
    PRIMARY KEY (app_id, environment, model_id),
    CONSTRAINT valid_thermal_state CHECK (current_state IN (&#39;OFF&#39;, &#39;COLD&#39;, &#39;WARM&#39;, &#39;HOT&#39;, &#39;AUTOMATIC&#39;))
);

-- Mid-Level Services
CREATE TABLE IF NOT EXISTS mid_level_services (
    id VARCHAR(50) PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    display_name VARCHAR(255) NOT NULL,
    description TEXT,
    required_models TEXT[] NOT NULL DEFAULT &#39;{}&#39;,
    optional_models TEXT[] NOT NULL DEFAULT &#39;{}&#39;,
    default_state VARCHAR(20) NOT NULL DEFAULT &#39;DISABLED&#39;,
    graceful_degradation BOOLEAN NOT NULL DEFAULT true,
    per_request DECIMAL(10,6),
    per_image DECIMAL(10,6),
    per_3d_model DECIMAL(10,4),
    markup_percent DECIMAL(5,2) NOT NULL DEFAULT 40.00,
    min_tier INTEGER NOT NULL DEFAULT 3,
    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()
);

-- Service States per app/environment
CREATE TABLE IF NOT EXISTS service_states (
    app_id VARCHAR(100) NOT NULL,
    environment VARCHAR(20) NOT NULL,
    service_id VARCHAR(50) NOT NULL REFERENCES mid_level_services(id),
    current_state VARCHAR(20) NOT NULL DEFAULT &#39;DISABLED&#39;,
    degraded_reason TEXT,
    available_models TEXT[] NOT NULL DEFAULT &#39;{}&#39;,
    unavailable_models TEXT[] NOT NULL DEFAULT &#39;{}&#39;,
    updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
    PRIMARY KEY (app_id, environment, service_id),
    CONSTRAINT valid_service_state CHECK (current_state IN (&#39;RUNNING&#39;, &#39;DEGRADED&#39;, &#39;DISABLED&#39;, &#39;OFFLINE&#39;))
);

-- Model Usage Tracking (for billing)
CREATE TABLE IF NOT EXISTS model_usage (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    app_id VARCHAR(100) NOT NULL,
    environment VARCHAR(20) NOT NULL,
    tenant_id VARCHAR(100) NOT NULL,
    user_id VARCHAR(100),
    model_id VARCHAR(100) NOT NULL,
    service_id VARCHAR(50),
    operation VARCHAR(100) NOT NULL,
    processing_time_ms INTEGER NOT NULL,
    input_size_bytes INTEGER,
    output_size_bytes INTEGER,
    computed_cost DECIMAL(12,8) NOT NULL,
    request_id VARCHAR(100),
    metadata JSONB,
    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()
);

CREATE INDEX idx_model_usage_tenant ON model_usage(tenant_id);
CREATE INDEX idx_model_usage_model ON model_usage(model_id);
CREATE INDEX idx_model_usage_created ON model_usage(created_at);</code></pre>
<hr />
<h2 id="part-5-estimated-costs-by-tier">PART 5: ESTIMATED COSTS BY TIER</h2>
<h3 id="self-hosted-model-costs-monthly">Self-Hosted Model Costs (Monthly)</h3>
<table>
<colgroup>
<col style="width: 21%" />
<col style="width: 15%" />
<col style="width: 15%" />
<col style="width: 15%" />
<col style="width: 15%" />
<col style="width: 15%" />
</colgroup>
<thead>
<tr>
<th>Component</th>
<th>Tier 1</th>
<th>Tier 2</th>
<th>Tier 3</th>
<th>Tier 4</th>
<th>Tier 5</th>
</tr>
</thead>
<tbody>
<tr>
<td>SageMaker (Vision)</td>
<td>N/A</td>
<td>N/A</td>
<td>~$150</td>
<td>~$400</td>
<td>~$1,000</td>
</tr>
<tr>
<td>SageMaker (Audio)</td>
<td>N/A</td>
<td>N/A</td>
<td>~$100</td>
<td>~$250</td>
<td>~$600</td>
</tr>
<tr>
<td>SageMaker (Scientific)</td>
<td>N/A</td>
<td>N/A</td>
<td>N/A</td>
<td>~$300</td>
<td>~$800</td>
</tr>
<tr>
<td>SageMaker (Medical)</td>
<td>N/A</td>
<td>N/A</td>
<td>N/A</td>
<td>~$200</td>
<td>~$500</td>
</tr>
<tr>
<td>SageMaker (Geospatial)</td>
<td>N/A</td>
<td>N/A</td>
<td>N/A</td>
<td>~$150</td>
<td>~$400</td>
</tr>
<tr>
<td>SageMaker (3D)</td>
<td>N/A</td>
<td>N/A</td>
<td>N/A</td>
<td>~$200</td>
<td>~$500</td>
</tr>
<tr>
<td>SageMaker (LLMs)</td>
<td>N/A</td>
<td>N/A</td>
<td>~$100</td>
<td>~$500</td>
<td>~$2,000</td>
</tr>
<tr>
<td>Lambda (Thermal/Services)</td>
<td>N/A</td>
<td>N/A</td>
<td>~$30</td>
<td>~$80</td>
<td>~$250</td>
</tr>
<tr>
<td>DynamoDB (States)</td>
<td>N/A</td>
<td>N/A</td>
<td>~$5</td>
<td>~$15</td>
<td>~$50</td>
</tr>
<tr>
<td><strong>Prompt 6 Total</strong></td>
<td><strong>N/A</strong></td>
<td><strong>N/A</strong></td>
<td><strong>~$385</strong></td>
<td><strong>~$2,095</strong></td>
<td><strong>~$6,100</strong></td>
</tr>
</tbody>
</table>
<p><em>Notes:</em> - Self-hosted models require Tier 3+ (GROWTH tier or above) - Costs assume models in COLD state (scale to zero when idle) - 75% markup on SageMaker costs included for billing</p>
<hr />
<h2 id="model-summary-by-category">MODEL SUMMARY BY CATEGORY</h2>
<h3 id="computer-vision-19-models">Computer Vision (19 models)</h3>
<table>
<colgroup>
<col style="width: 40%" />
<col style="width: 28%" />
<col style="width: 32%" />
</colgroup>
<thead>
<tr>
<th>Category</th>
<th>Count</th>
<th>Models</th>
</tr>
</thead>
<tbody>
<tr>
<td>Classification</td>
<td>8</td>
<td>EfficientNet-B0/B5/V2-L, Swin-T/B/L, CLIP-B32/L14</td>
</tr>
<tr>
<td>Detection</td>
<td>7</td>
<td>YOLOv8n/s/m/x, YOLOv11x, RT-DETR-X, Grounding DINO</td>
</tr>
<tr>
<td>Segmentation</td>
<td>4</td>
<td>SAM ViT-H, SAM 2, MobileSAM, Mask R-CNN</td>
</tr>
</tbody>
</table>
<h3 id="audiospeech-6-models">Audio/Speech (6 models)</h3>
<table>
<colgroup>
<col style="width: 40%" />
<col style="width: 28%" />
<col style="width: 32%" />
</colgroup>
<thead>
<tr>
<th>Category</th>
<th>Count</th>
<th>Models</th>
</tr>
</thead>
<tbody>
<tr>
<td>Speech-to-Text</td>
<td>3</td>
<td>Parakeet TDT 1.1B, Whisper Large V3, Whisper Turbo</td>
</tr>
<tr>
<td>Speaker</td>
<td>3</td>
<td>TitaNet-Large, ECAPA-TDNN, pyannote Diarization</td>
</tr>
</tbody>
</table>
<h3 id="scientific-4-models">Scientific (4 models)</h3>
<table>
<thead>
<tr>
<th>Category</th>
<th>Count</th>
<th>Models</th>
</tr>
</thead>
<tbody>
<tr>
<td>Protein</td>
<td>3</td>
<td>AlphaFold2, ESM-2 3B, Protenix</td>
</tr>
<tr>
<td>Math</td>
<td>1</td>
<td>AlphaGeometry</td>
</tr>
</tbody>
</table>
<h3 id="medical-2-models">Medical (2 models)</h3>
<table>
<thead>
<tr>
<th>Category</th>
<th>Count</th>
<th>Models</th>
</tr>
</thead>
<tbody>
<tr>
<td>Imaging</td>
<td>2</td>
<td>nnU-Net, MedSAM</td>
</tr>
</tbody>
</table>
<h3 id="geospatial-2-models">Geospatial (2 models)</h3>
<table>
<thead>
<tr>
<th>Category</th>
<th>Count</th>
<th>Models</th>
</tr>
</thead>
<tbody>
<tr>
<td>Satellite</td>
<td>2</td>
<td>Prithvi 100M, Prithvi 600M</td>
</tr>
</tbody>
</table>
<h3 id="dgenerative-2-models">3D/Generative (2 models)</h3>
<table>
<thead>
<tr>
<th>Category</th>
<th>Count</th>
<th>Models</th>
</tr>
</thead>
<tbody>
<tr>
<td>Reconstruction</td>
<td>2</td>
<td>Nerfstudio, 3D Gaussian Splatting</td>
</tr>
</tbody>
</table>
<h3 id="text-generation-3-models">Text Generation (3 models)</h3>
<table>
<thead>
<tr>
<th>Category</th>
<th>Count</th>
<th>Models</th>
</tr>
</thead>
<tbody>
<tr>
<td>LLMs</td>
<td>3</td>
<td>Mistral 7B, Llama 3 70B, Qwen 72B</td>
</tr>
</tbody>
</table>
<p><strong>Total: 38 self-hosted models</strong></p>
<hr />
<h2 id="api-routes-summary">API ROUTES SUMMARY</h2>
<h3 id="thermal-management">Thermal Management</h3>
<table>
<thead>
<tr>
<th>Method</th>
<th>Path</th>
<th>Description</th>
<th>Permission</th>
</tr>
</thead>
<tbody>
<tr>
<td>GET</td>
<td>/thermal/models</td>
<td>List all models with states</td>
<td>settings:read</td>
</tr>
<tr>
<td>GET</td>
<td>/thermal/models/:id</td>
<td>Get model thermal state</td>
<td>settings:read</td>
</tr>
<tr>
<td>PUT</td>
<td>/thermal/models/:id</td>
<td>Update thermal state</td>
<td>settings:write</td>
</tr>
<tr>
<td>POST</td>
<td>/thermal/bulk</td>
<td>Bulk update states</td>
<td>settings:write</td>
</tr>
<tr>
<td>POST</td>
<td>/thermal/warm/:id</td>
<td>Request model warm-up</td>
<td>(API users)</td>
</tr>
</tbody>
</table>
<h3 id="mid-level-services">Mid-Level Services</h3>
<table>
<thead>
<tr>
<th>Method</th>
<th>Path</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>POST</td>
<td>/perception/detect</td>
<td>Object detection</td>
</tr>
<tr>
<td>POST</td>
<td>/perception/segment</td>
<td>Image segmentation</td>
</tr>
<tr>
<td>POST</td>
<td>/perception/classify</td>
<td>Image classification</td>
</tr>
<tr>
<td>POST</td>
<td>/perception/analyze</td>
<td>Full pipeline</td>
</tr>
<tr>
<td>POST</td>
<td>/scientific/protein/embed</td>
<td>Protein embeddings</td>
</tr>
<tr>
<td>POST</td>
<td>/scientific/protein/fold</td>
<td>Protein structure</td>
</tr>
<tr>
<td>POST</td>
<td>/medical/segment</td>
<td>Medical segmentation</td>
</tr>
<tr>
<td>POST</td>
<td>/geospatial/classify</td>
<td>Land use classification</td>
</tr>
<tr>
<td>POST</td>
<td>/reconstruction/nerf</td>
<td>3D reconstruction</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="deployment-verification">DEPLOYMENT VERIFICATION</h2>
<pre class="bash"><code># 1. Check thermal states
curl -H &quot;Authorization: Bearer $ADMIN_TOKEN&quot; \
  https://admin-api.YOUR_DOMAIN.com/api/v2/thermal/models

# 2. Update thermal state
curl -X PUT -H &quot;Authorization: Bearer $ADMIN_TOKEN&quot; \
  -H &quot;Content-Type: application/json&quot; \
  -d &#39;{&quot;targetState&quot;: &quot;WARM&quot;}&#39; \
  https://admin-api.YOUR_DOMAIN.com/api/v2/thermal/models/yolov8m

# 3. Test object detection
curl -X POST -H &quot;Authorization: Bearer $TOKEN&quot; \
  -H &quot;Content-Type: application/json&quot; \
  -d &#39;{&quot;imageUrl&quot;: &quot;https://YOUR_DOMAIN.com/image.jpg&quot;}&#39; \
  https://api.YOUR_DOMAIN.com/api/v2/perception/detect

# 4. Check service status
curl -H &quot;Authorization: Bearer $TOKEN&quot; \
  https://api.YOUR_DOMAIN.com/api/v2/perception/status</code></pre>
<hr />
<h2 id="next-prompts">NEXT PROMPTS</h2>
<p>Continue with: - <strong>Prompt 7</strong>: External Providers &amp; Database Schema/Migrations - <strong>Prompt 8</strong>: Admin Web Dashboard (Next.js) - <strong>Prompt 9</strong>: Assembly &amp; Deployment Guide</p>
<hr />
<p><em>End of Prompt 6: Self-Hosted Models &amp; Mid-Level Services</em> <em>RADIANT v2.2.0 - December 2024</em></p>
<h1 id="├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в-1">├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р</h1>
<h1 id="end-of-section-6">END OF SECTION 6</h1>
<h1 id="├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в-2">├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р</h1>
<h1 id="├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в├в-3">├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р├втАв┬Р</h1>

  
  <div class="footer">
    RADIANT Documentation | Version 5.52.29 | Generated January 25, 2026
  </div>
</body>
</html>