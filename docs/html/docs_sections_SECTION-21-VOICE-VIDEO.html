<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>SECTION 21 VOICE VIDEO - RADIANT Documentation</title>
  
<style>
@media print {
  body { font-size: 11pt !important; }
  pre { page-break-inside: avoid; }
  h1, h2, h3 { page-break-after: avoid; }
  .no-print { display: none !important; }
}

* { box-sizing: border-box; }

body {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
  line-height: 1.7;
  color: #1d1d1f;
  max-width: 900px;
  margin: 0 auto;
  padding: 40px 30px;
  background: white;
}

h1 {
  color: #1d1d1f;
  border-bottom: 3px solid #0071e3;
  padding-bottom: 12px;
  font-size: 28px;
  margin-top: 0;
}

h2 {
  color: #1d1d1f;
  border-bottom: 1px solid #d2d2d7;
  padding-bottom: 8px;
  font-size: 22px;
  margin-top: 40px;
}

h3 { color: #1d1d1f; font-size: 18px; margin-top: 30px; }
h4 { color: #1d1d1f; font-size: 16px; margin-top: 25px; }

a { color: #0071e3; text-decoration: none; }
a:hover { text-decoration: underline; }

code {
  background: #f5f5f7;
  padding: 2px 6px;
  border-radius: 4px;
  font-family: 'SF Mono', Monaco, 'Cascadia Code', monospace;
  font-size: 0.9em;
  color: #1d1d1f;
}

pre {
  background: #1d1d1f;
  color: #f5f5f7;
  padding: 20px;
  border-radius: 10px;
  overflow-x: auto;
  font-size: 13px;
  line-height: 1.5;
}

pre code {
  background: transparent;
  padding: 0;
  color: inherit;
}

table {
  width: 100%;
  border-collapse: collapse;
  margin: 20px 0;
  font-size: 14px;
}

th, td {
  border: 1px solid #d2d2d7;
  padding: 12px 15px;
  text-align: left;
}

th {
  background: #0071e3;
  color: white;
  font-weight: 600;
}

tr:nth-child(even) { background: #f5f5f7; }

blockquote {
  border-left: 4px solid #0071e3;
  margin: 20px 0;
  padding: 15px 25px;
  background: #f5f5f7;
  border-radius: 0 8px 8px 0;
}

blockquote p { margin: 0; }

img { max-width: 100%; height: auto; border-radius: 8px; }

hr {
  border: none;
  border-top: 1px solid #d2d2d7;
  margin: 40px 0;
}

ul, ol { padding-left: 25px; }
li { margin: 8px 0; }

.header-bar {
  background: linear-gradient(135deg, #0071e3 0%, #00c6ff 100%);
  color: white;
  padding: 20px 30px;
  margin: -40px -30px 30px -30px;
  border-radius: 0 0 16px 16px;
}

.header-bar h1 {
  color: white;
  border: none;
  margin: 0;
  padding: 0;
}

.header-bar .meta {
  font-size: 13px;
  opacity: 0.9;
  margin-top: 8px;
}

.print-btn {
  position: fixed;
  top: 20px;
  right: 20px;
  background: #0071e3;
  color: white;
  border: none;
  padding: 12px 24px;
  border-radius: 8px;
  cursor: pointer;
  font-size: 14px;
  font-weight: 500;
  box-shadow: 0 4px 12px rgba(0,113,227,0.3);
}

.print-btn:hover { background: #0077ed; }

.mermaid {
  background: #f5f5f7;
  padding: 20px;
  border-radius: 10px;
  text-align: center;
  margin: 20px 0;
}

.footer {
  margin-top: 60px;
  padding-top: 20px;
  border-top: 1px solid #d2d2d7;
  color: #86868b;
  font-size: 12px;
  text-align: center;
}
</style>

</head>
<body>
  <button class="print-btn no-print" onclick="window.print()">üñ®Ô∏è Print / Save as PDF</button>
  
  <div class="header-bar">
    <h1>SECTION 21 VOICE VIDEO</h1>
    <div class="meta">RADIANT v5.52.29 | docs/sections/SECTION-21-VOICE-VIDEO.md</div>
  </div>
  
  <h1 id="section-21-voice-video-input-v3.6.0">SECTION 21: VOICE &amp; VIDEO INPUT (v3.6.0)</h1>
<h1 id="section">‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê</h1>
<h2 id="voicevideo-overview">21.1 Voice/Video Overview</h2>
<p>Integration with Deepgram for speech-to-text and ElevenLabs for text-to-speech.</p>
<h2 id="voice-database-schema">21.2 Voice Database Schema</h2>
<pre class="sql"><code>-- migrations/030_voice_video.sql

CREATE TABLE voice_sessions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    tenant_id UUID NOT NULL REFERENCES tenants(id),
    user_id UUID NOT NULL REFERENCES users(id),
    session_type VARCHAR(20) NOT NULL,
    input_format VARCHAR(20),
    output_format VARCHAR(20),
    language VARCHAR(10) DEFAULT &#39;en&#39;,
    voice_id VARCHAR(100),
    total_duration_ms INTEGER DEFAULT 0,
    total_cost DECIMAL(10, 6) DEFAULT 0,
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,
    ended_at TIMESTAMPTZ
);

CREATE TABLE voice_transcriptions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    session_id UUID NOT NULL REFERENCES voice_sessions(id) ON DELETE CASCADE,
    audio_url VARCHAR(500),
    transcription TEXT,
    confidence DECIMAL(3, 2),
    duration_ms INTEGER,
    word_timestamps JSONB,
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE voice_synthesis (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    session_id UUID NOT NULL REFERENCES voice_sessions(id) ON DELETE CASCADE,
    input_text TEXT NOT NULL,
    audio_url VARCHAR(500),
    voice_id VARCHAR(100) NOT NULL,
    duration_ms INTEGER,
    character_count INTEGER,
    cost DECIMAL(10, 6),
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_voice_sessions_user ON voice_sessions(tenant_id, user_id);
CREATE INDEX idx_voice_transcriptions ON voice_transcriptions(session_id);

ALTER TABLE voice_sessions ENABLE ROW LEVEL SECURITY;
ALTER TABLE voice_transcriptions ENABLE ROW LEVEL SECURITY;
ALTER TABLE voice_synthesis ENABLE ROW LEVEL SECURITY;

CREATE POLICY voice_sessions_isolation ON voice_sessions USING (tenant_id = current_setting(&#39;app.current_tenant_id&#39;)::UUID);
CREATE POLICY voice_transcriptions_isolation ON voice_transcriptions USING (
    session_id IN (SELECT id FROM voice_sessions WHERE tenant_id = current_setting(&#39;app.current_tenant_id&#39;)::UUID)
);
CREATE POLICY voice_synthesis_isolation ON voice_synthesis USING (
    session_id IN (SELECT id FROM voice_sessions WHERE tenant_id = current_setting(&#39;app.current_tenant_id&#39;)::UUID)
);</code></pre>
<h2 id="voice-service-integration">21.3 Voice Service Integration</h2>
<pre class="typescript"><code>// packages/core/src/services/voice-service.ts

import { Pool } from &#39;pg&#39;;
import { S3Client, PutObjectCommand, GetObjectCommand } from &#39;@aws-sdk/client-s3&#39;;
import { getSignedUrl } from &#39;@aws-sdk/s3-request-presigner&#39;;

interface DeepgramResponse {
    results: {
        channels: Array&lt;{
            alternatives: Array&lt;{
                transcript: string;
                confidence: number;
                words: Array&lt;{ word: string; start: number; end: number }&gt;;
            }&gt;;
        }&gt;;
    };
    metadata: {
        duration: number;
    };
}

export class VoiceService {
    private pool: Pool;
    private s3: S3Client;
    private deepgramApiKey: string;
    private elevenLabsApiKey: string;
    
    constructor(pool: Pool) {
        this.pool = pool;
        this.s3 = new S3Client({});
        this.deepgramApiKey = process.env.DEEPGRAM_API_KEY!;
        this.elevenLabsApiKey = process.env.ELEVENLABS_API_KEY!;
    }
    
    async createSession(
        tenantId: string,
        userId: string,
        sessionType: &#39;stt&#39; | &#39;tts&#39; | &#39;realtime&#39;,
        options?: { language?: string; voiceId?: string }
    ): Promise&lt;string&gt; {
        const result = await this.pool.query(`
            INSERT INTO voice_sessions (tenant_id, user_id, session_type, language, voice_id)
            VALUES ($1, $2, $3, $4, $5)
            RETURNING id
        `, [tenantId, userId, sessionType, options?.language || &#39;en&#39;, options?.voiceId]);
        
        return result.rows[0].id;
    }
    
    async transcribe(
        sessionId: string,
        audioBuffer: Buffer,
        format: string = &#39;webm&#39;
    ): Promise&lt;{ transcription: string; confidence: number; wordTimestamps: any[] }&gt; {
        // Upload audio to S3
        const audioKey = `voice/${sessionId}/${Date.now()}.${format}`;
        await this.s3.send(new PutObjectCommand({
            Bucket: process.env.ASSETS_BUCKET!,
            Key: audioKey,
            Body: audioBuffer,
            ContentType: `audio/${format}`
        }));
        
        // Call Deepgram API
        const response = await fetch(&#39;https://api.deepgram.com/v1/listen?model=nova-2&amp;smart_format=true&#39;, {
            method: &#39;POST&#39;,
            headers: {
                &#39;Authorization&#39;: `Token ${this.deepgramApiKey}`,
                &#39;Content-Type&#39;: `audio/${format}`
            },
            body: audioBuffer
        });
        
        const data: DeepgramResponse = await response.json();
        const result = data.results.channels[0].alternatives[0];
        
        // Store transcription
        const audioUrl = await this.getSignedUrl(audioKey);
        await this.pool.query(`
            INSERT INTO voice_transcriptions (session_id, audio_url, transcription, confidence, duration_ms, word_timestamps)
            VALUES ($1, $2, $3, $4, $5, $6)
        `, [sessionId, audioUrl, result.transcript, result.confidence, data.metadata.duration * 1000, JSON.stringify(result.words)]);
        
        return {
            transcription: result.transcript,
            confidence: result.confidence,
            wordTimestamps: result.words
        };
    }
    
    async synthesize(
        sessionId: string,
        text: string,
        voiceId: string = &#39;EXAVITQu4vr4xnSDxMaL&#39;
    ): Promise&lt;{ audioUrl: string; durationMs: number }&gt; {
        // Call ElevenLabs API
        const response = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`, {
            method: &#39;POST&#39;,
            headers: {
                &#39;Accept&#39;: &#39;audio/mpeg&#39;,
                &#39;xi-api-key&#39;: this.elevenLabsApiKey,
                &#39;Content-Type&#39;: &#39;application/json&#39;
            },
            body: JSON.stringify({
                text,
                model_id: &#39;eleven_multilingual_v2&#39;,
                voice_settings: {
                    stability: 0.5,
                    similarity_boost: 0.75
                }
            })
        });
        
        const audioBuffer = Buffer.from(await response.arrayBuffer());
        
        // Upload to S3
        const audioKey = `voice/${sessionId}/${Date.now()}_synthesis.mp3`;
        await this.s3.send(new PutObjectCommand({
            Bucket: process.env.ASSETS_BUCKET!,
            Key: audioKey,
            Body: audioBuffer,
            ContentType: &#39;audio/mpeg&#39;
        }));
        
        const audioUrl = await this.getSignedUrl(audioKey);
        const durationMs = this.estimateDuration(text);
        const cost = text.length * 0.00003; // Approximate ElevenLabs cost
        
        // Store synthesis record
        await this.pool.query(`
            INSERT INTO voice_synthesis (session_id, input_text, audio_url, voice_id, duration_ms, character_count, cost)
            VALUES ($1, $2, $3, $4, $5, $6, $7)
        `, [sessionId, text, audioUrl, voiceId, durationMs, text.length, cost]);
        
        return { audioUrl, durationMs };
    }
    
    private async getSignedUrl(key: string): Promise&lt;string&gt; {
        const command = new GetObjectCommand({
            Bucket: process.env.ASSETS_BUCKET!,
            Key: key
        });
        return getSignedUrl(this.s3, command, { expiresIn: 3600 });
    }
    
    private estimateDuration(text: string): number {
        // Rough estimate: ~150 words per minute
        const wordCount = text.split(/\s+/).length;
        return Math.round((wordCount / 150) * 60 * 1000);
    }
}</code></pre>
<h1 id="section-1">‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê</h1>

  
  <div class="footer">
    RADIANT Documentation | Version 5.52.29 | Generated January 25, 2026
  </div>
</body>
</html>