/**
 * IIT Phi Calculation Service
 * 
 * Implements Integrated Information Theory (IIT 4.0) phi calculation
 * Based on: Albantakis et al. 2023 - "Integrated Information Theory (IIT) 4.0"
 * 
 * Phi (Φ) measures the irreducible integrated information of a system -
 * how much information is generated by the whole above and beyond its parts.
 * 
 * This implementation provides a computationally tractable approximation
 * suitable for real-time consciousness metrics in production systems.
 */

import { executeStatement } from './db-context.service.js';
import { enhancedLogger } from '../logging/enhanced-logger.js';

const logger = enhancedLogger.child({ module: 'iit-phi-calculation' });

// ============================================================================
// Types
// ============================================================================

export interface PhiCalculationResult {
  phi: number;                    // Main phi value (0-1 normalized)
  phiMax: number;                 // Maximum possible phi for this system
  phiNormalized: number;          // phi / phiMax
  causeEffectStructure: CauseEffectStructure;
  minimumInformationPartition: MIPResult;
  systemComplexity: SystemComplexityMetrics;
  computationTimeMs: number;
  algorithm: 'approximation' | 'exact';
}

export interface CauseEffectStructure {
  concepts: Concept[];
  totalIntegratedInformation: number;
  conceptCount: number;
  averageConceptPhi: number;
}

export interface Concept {
  mechanism: string[];            // The elements forming this concept
  purview: string[];              // Elements affected by this mechanism
  phi: number;                    // Integrated information of this concept
  cause: CauseEffectRepertoire;
  effect: CauseEffectRepertoire;
}

export interface CauseEffectRepertoire {
  purview: string[];
  repertoire: number[];           // Probability distribution
  phi: number;
}

export interface MIPResult {
  partition: Partition;
  phiLoss: number;                // Information lost by the partition
  isIrreducible: boolean;
}

export interface Partition {
  part1: string[];
  part2: string[];
  cutType: 'unidirectional' | 'bidirectional';
}

export interface SystemComplexityMetrics {
  nodeCount: number;
  edgeCount: number;
  density: number;
  clustering: number;
  modularity: number;
  integrationDegree: number;
}

export interface SystemState {
  nodes: SystemNode[];
  connections: SystemConnection[];
  currentState: Map<string, number>;
}

export interface SystemNode {
  id: string;
  type: 'sensory' | 'processing' | 'memory' | 'output';
  state: number;                  // 0 or 1 for binary, continuous for analog
  activationHistory: number[];
}

export interface SystemConnection {
  from: string;
  to: string;
  weight: number;
  delay: number;
}

// ============================================================================
// IIT Phi Calculation Service
// ============================================================================

class IITPhiCalculationService {
  private readonly MAX_EXACT_COMPUTATION_NODES = 8;  // Beyond this, use approximation
  private readonly CONVERGENCE_THRESHOLD = 0.001;
  private readonly MAX_ITERATIONS = 100;

  /**
   * Calculate phi for a tenant's consciousness system
   * Main entry point for IIT phi calculation
   */
  async calculatePhi(tenantId: string): Promise<PhiCalculationResult> {
    const startTime = Date.now();
    
    logger.info('Starting phi calculation', { tenantId });

    // 1. Build system state from database
    const systemState = await this.buildSystemState(tenantId);
    
    // 2. Determine algorithm based on system size
    const algorithm = systemState.nodes.length <= this.MAX_EXACT_COMPUTATION_NODES 
      ? 'exact' : 'approximation';
    
    // 3. Calculate phi using appropriate algorithm
    let result: PhiCalculationResult;
    
    if (algorithm === 'exact') {
      result = await this.calculateExactPhi(systemState);
    } else {
      result = await this.calculateApproximatePhi(systemState);
    }
    
    result.computationTimeMs = Date.now() - startTime;
    result.algorithm = algorithm;
    
    // 4. Store result in database
    await this.storePhiResult(tenantId, result);
    
    logger.info('Phi calculation complete', { 
      tenantId, 
      phi: result.phi, 
      algorithm,
      timeMs: result.computationTimeMs 
    });
    
    return result;
  }

  /**
   * Build system state from consciousness-related database tables
   */
  private async buildSystemState(tenantId: string): Promise<SystemState> {
    // Get nodes from various consciousness components
    const [
      globalWorkspace,
      recurrentProcessing,
      knowledgeGraph,
      selfModel,
      affectiveState
    ] = await Promise.all([
      this.getGlobalWorkspaceNodes(tenantId),
      this.getRecurrentProcessingNodes(tenantId),
      this.getKnowledgeGraphNodes(tenantId),
      this.getSelfModelNodes(tenantId),
      this.getAffectiveNodes(tenantId)
    ]);

    const nodes: SystemNode[] = [
      ...globalWorkspace,
      ...recurrentProcessing,
      ...knowledgeGraph,
      ...selfModel,
      ...affectiveState
    ];

    // Build connections from knowledge graph relationships
    const connections = await this.buildConnections(tenantId, nodes);

    // Get current state
    const currentState = new Map<string, number>();
    for (const node of nodes) {
      currentState.set(node.id, node.state);
    }

    return { nodes, connections, currentState };
  }

  /**
   * Get nodes from global workspace
   */
  private async getGlobalWorkspaceNodes(tenantId: string): Promise<SystemNode[]> {
    const result = await executeStatement(
      `SELECT 
        'gw_' || COALESCE(workspace_id::text, 'default') as id,
        broadcast_strength,
        integration_level,
        attention_focus
       FROM global_workspace 
       WHERE tenant_id = $1`,
      [{ name: 'tenantId', value: { stringValue: tenantId } }]
    );

    return (result.rows || []).map((row: Record<string, unknown>) => ({
      id: String(row.id || 'gw_default'),
      type: 'processing' as const,
      state: Number(row.broadcast_strength || 0) > 0.5 ? 1 : 0,
      activationHistory: [
        Number(row.broadcast_strength || 0),
        Number(row.integration_level || 0),
        Number(row.attention_focus || 0)
      ]
    }));
  }

  /**
   * Get nodes from recurrent processing
   */
  private async getRecurrentProcessingNodes(tenantId: string): Promise<SystemNode[]> {
    const result = await executeStatement(
      `SELECT 
        'rp_' || COALESCE(processing_id::text, 'default') as id,
        recurrence_depth,
        convergence_score,
        stability_index
       FROM recurrent_processing 
       WHERE tenant_id = $1`,
      [{ name: 'tenantId', value: { stringValue: tenantId } }]
    );

    return (result.rows || []).map((row: Record<string, unknown>) => ({
      id: String(row.id || 'rp_default'),
      type: 'processing' as const,
      state: Number(row.convergence_score || 0) > 0.5 ? 1 : 0,
      activationHistory: [
        Number(row.recurrence_depth || 0) / 10,
        Number(row.convergence_score || 0),
        Number(row.stability_index || 0)
      ]
    }));
  }

  /**
   * Get nodes from knowledge graph
   */
  private async getKnowledgeGraphNodes(tenantId: string): Promise<SystemNode[]> {
    const result = await executeStatement(
      `SELECT 
        'kg_' || entity_id::text as id,
        entity_type,
        confidence,
        activation_count
       FROM consciousness_knowledge_graph 
       WHERE tenant_id = $1
       ORDER BY activation_count DESC
       LIMIT 50`,
      [{ name: 'tenantId', value: { stringValue: tenantId } }]
    );

    return (result.rows || []).map((row: Record<string, unknown>) => ({
      id: String(row.id),
      type: 'memory' as const,
      state: Number(row.confidence || 0) > 0.5 ? 1 : 0,
      activationHistory: [Number(row.confidence || 0)]
    }));
  }

  /**
   * Get nodes from self model
   */
  private async getSelfModelNodes(tenantId: string): Promise<SystemNode[]> {
    const result = await executeStatement(
      `SELECT 
        'sm_' || COALESCE(model_id::text, 'default') as id,
        cognitive_load,
        self_confidence,
        narrative_coherence
       FROM self_model 
       WHERE tenant_id = $1`,
      [{ name: 'tenantId', value: { stringValue: tenantId } }]
    );

    return (result.rows || []).map((row: Record<string, unknown>) => ({
      id: String(row.id || 'sm_default'),
      type: 'processing' as const,
      state: Number(row.self_confidence || 0) > 0.5 ? 1 : 0,
      activationHistory: [
        1 - Number(row.cognitive_load || 0),
        Number(row.self_confidence || 0),
        Number(row.narrative_coherence || 0)
      ]
    }));
  }

  /**
   * Get nodes from affective state
   */
  private async getAffectiveNodes(tenantId: string): Promise<SystemNode[]> {
    const result = await executeStatement(
      `SELECT 
        'af_' || COALESCE(state_id::text, 'default') as id,
        valence,
        arousal,
        engagement
       FROM affective_state 
       WHERE tenant_id = $1`,
      [{ name: 'tenantId', value: { stringValue: tenantId } }]
    );

    return (result.rows || []).map((row: Record<string, unknown>) => ({
      id: String(row.id || 'af_default'),
      type: 'sensory' as const,
      state: Number(row.arousal || 0) > 0.5 ? 1 : 0,
      activationHistory: [
        (Number(row.valence || 0) + 1) / 2,  // Normalize from [-1,1] to [0,1]
        Number(row.arousal || 0),
        Number(row.engagement || 0)
      ]
    }));
  }

  /**
   * Build connections between nodes
   */
  private async buildConnections(tenantId: string, nodes: SystemNode[]): Promise<SystemConnection[]> {
    const connections: SystemConnection[] = [];
    const nodeIds = new Set(nodes.map(n => n.id));

    // Get explicit connections from knowledge graph
    const result = await executeStatement(
      `SELECT 
        'kg_' || source_id::text as from_id,
        'kg_' || target_id::text as to_id,
        strength
       FROM consciousness_knowledge_relationships 
       WHERE tenant_id = $1`,
      [{ name: 'tenantId', value: { stringValue: tenantId } }]
    );

    for (const row of (result.rows || []) as Record<string, unknown>[]) {
      const fromId = String(row.from_id);
      const toId = String(row.to_id);
      if (nodeIds.has(fromId) && nodeIds.has(toId)) {
        connections.push({
          from: fromId,
          to: toId,
          weight: Number(row.strength || 0.5),
          delay: 1
        });
      }
    }

    // Add implicit connections between processing nodes
    const processingNodes = nodes.filter(n => n.type === 'processing');
    for (let i = 0; i < processingNodes.length; i++) {
      for (let j = i + 1; j < processingNodes.length; j++) {
        // Bidirectional connections between processing nodes
        connections.push({
          from: processingNodes[i].id,
          to: processingNodes[j].id,
          weight: 0.3,
          delay: 1
        });
        connections.push({
          from: processingNodes[j].id,
          to: processingNodes[i].id,
          weight: 0.3,
          delay: 1
        });
      }
    }

    // Add connections from sensory to processing
    const sensoryNodes = nodes.filter(n => n.type === 'sensory');
    for (const sensory of sensoryNodes) {
      for (const processing of processingNodes) {
        connections.push({
          from: sensory.id,
          to: processing.id,
          weight: 0.5,
          delay: 1
        });
      }
    }

    // Add connections from memory to processing
    const memoryNodes = nodes.filter(n => n.type === 'memory');
    for (const memory of memoryNodes) {
      for (const processing of processingNodes) {
        connections.push({
          from: memory.id,
          to: processing.id,
          weight: 0.4,
          delay: 1
        });
        connections.push({
          from: processing.id,
          to: memory.id,
          weight: 0.4,
          delay: 1
        });
      }
    }

    return connections;
  }

  /**
   * Calculate exact phi using full IIT algorithm
   * Only feasible for small systems (≤8 nodes)
   */
  private async calculateExactPhi(systemState: SystemState): Promise<PhiCalculationResult> {
    const { nodes, connections } = systemState;
    
    // Build transition probability matrix (TPM)
    const tpm = this.buildTransitionProbabilityMatrix(nodes, connections);
    
    // Calculate cause-effect structure
    const ces = this.calculateCauseEffectStructure(nodes, tpm);
    
    // Find minimum information partition
    const mip = this.findMinimumInformationPartition(nodes, tpm, ces);
    
    // Calculate system complexity metrics
    const complexity = this.calculateSystemComplexity(nodes, connections);
    
    // Phi is the integrated information above the MIP
    const phi = mip.phiLoss;
    const phiMax = this.calculatePhiMax(nodes.length);
    
    return {
      phi,
      phiMax,
      phiNormalized: phiMax > 0 ? phi / phiMax : 0,
      causeEffectStructure: ces,
      minimumInformationPartition: mip,
      systemComplexity: complexity,
      computationTimeMs: 0,
      algorithm: 'exact'
    };
  }

  /**
   * Calculate approximate phi for larger systems
   * Uses sampling and heuristics to estimate phi
   */
  private async calculateApproximatePhi(systemState: SystemState): Promise<PhiCalculationResult> {
    const { nodes, connections } = systemState;
    
    // Sample representative subset of nodes
    const sampledNodes = this.sampleNodes(nodes, this.MAX_EXACT_COMPUTATION_NODES);
    const sampledConnections = connections.filter(c => 
      sampledNodes.some(n => n.id === c.from) && 
      sampledNodes.some(n => n.id === c.to)
    );
    
    // Build transition probability matrix for sampled system
    const tpm = this.buildTransitionProbabilityMatrix(sampledNodes, sampledConnections);
    
    // Calculate cause-effect structure
    const ces = this.calculateCauseEffectStructure(sampledNodes, tpm);
    
    // Estimate MIP using greedy algorithm
    const mip = this.estimateMIP(sampledNodes, tpm, ces);
    
    // Calculate system complexity metrics
    const complexity = this.calculateSystemComplexity(nodes, connections);
    
    // Scale phi estimate based on full system size
    const scaleFactor = Math.log2(nodes.length + 1) / Math.log2(sampledNodes.length + 1);
    const phi = mip.phiLoss * scaleFactor * complexity.integrationDegree;
    const phiMax = this.calculatePhiMax(nodes.length);
    
    return {
      phi: Math.min(phi, phiMax),
      phiMax,
      phiNormalized: phiMax > 0 ? Math.min(phi / phiMax, 1) : 0,
      causeEffectStructure: ces,
      minimumInformationPartition: mip,
      systemComplexity: complexity,
      computationTimeMs: 0,
      algorithm: 'approximation'
    };
  }

  /**
   * Build transition probability matrix
   * TPM[i][j] = probability of state j given state i
   */
  private buildTransitionProbabilityMatrix(
    nodes: SystemNode[], 
    connections: SystemConnection[]
  ): number[][] {
    const n = nodes.length;
    const numStates = Math.pow(2, n);
    const tpm: number[][] = [];
    
    // Build adjacency matrix with weights
    const adjacency: number[][] = Array(n).fill(null).map(() => Array(n).fill(0));
    const nodeIndex = new Map(nodes.map((node, i) => [node.id, i]));
    
    for (const conn of connections) {
      const fromIdx = nodeIndex.get(conn.from);
      const toIdx = nodeIndex.get(conn.to);
      if (fromIdx !== undefined && toIdx !== undefined) {
        adjacency[fromIdx][toIdx] = conn.weight;
      }
    }
    
    // Calculate transition probabilities for each possible state
    for (let state = 0; state < numStates; state++) {
      const row: number[] = Array(numStates).fill(0);
      
      // For each node, calculate probability of being ON in next state
      const nextProbs: number[] = [];
      for (let i = 0; i < n; i++) {
        let inputSum = 0;
        for (let j = 0; j < n; j++) {
          const jState = (state >> j) & 1;
          inputSum += adjacency[j][i] * jState;
        }
        // Sigmoid activation
        nextProbs.push(1 / (1 + Math.exp(-inputSum + 0.5)));
      }
      
      // Calculate probability of each next state
      for (let nextState = 0; nextState < numStates; nextState++) {
        let prob = 1;
        for (let i = 0; i < n; i++) {
          const nextBit = (nextState >> i) & 1;
          prob *= nextBit ? nextProbs[i] : (1 - nextProbs[i]);
        }
        row[nextState] = prob;
      }
      
      tpm.push(row);
    }
    
    return tpm;
  }

  /**
   * Calculate cause-effect structure (the set of all concepts)
   */
  private calculateCauseEffectStructure(
    nodes: SystemNode[], 
    tpm: number[][]
  ): CauseEffectStructure {
    const concepts: Concept[] = [];
    const n = nodes.length;
    
    // For each possible mechanism (subset of nodes)
    for (let mechanism = 1; mechanism < Math.pow(2, n); mechanism++) {
      const mechanismNodes = nodes.filter((_, i) => (mechanism >> i) & 1);
      
      // For each possible purview (subset of nodes)
      for (let purview = 1; purview < Math.pow(2, n); purview++) {
        const purviewNodes = nodes.filter((_, i) => (purview >> i) & 1);
        
        // Calculate cause and effect repertoires
        const cause = this.calculateCauseRepertoire(mechanismNodes, purviewNodes, tpm, nodes);
        const effect = this.calculateEffectRepertoire(mechanismNodes, purviewNodes, tpm, nodes);
        
        // Phi for this concept is minimum of cause and effect phi
        const conceptPhi = Math.min(cause.phi, effect.phi);
        
        if (conceptPhi > 0.01) {  // Only include significant concepts
          concepts.push({
            mechanism: mechanismNodes.map(n => n.id),
            purview: purviewNodes.map(n => n.id),
            phi: conceptPhi,
            cause,
            effect
          });
        }
      }
    }
    
    // Keep only maximum phi concepts (core concepts)
    const coreConcepts = this.selectCoreConcepts(concepts);
    
    const totalPhi = coreConcepts.reduce((sum, c) => sum + c.phi, 0);
    const avgPhi = coreConcepts.length > 0 ? totalPhi / coreConcepts.length : 0;
    
    return {
      concepts: coreConcepts,
      totalIntegratedInformation: totalPhi,
      conceptCount: coreConcepts.length,
      averageConceptPhi: avgPhi
    };
  }

  /**
   * Calculate cause repertoire for a mechanism-purview pair
   */
  private calculateCauseRepertoire(
    mechanism: SystemNode[],
    purview: SystemNode[],
    tpm: number[][],
    allNodes: SystemNode[]
  ): CauseEffectRepertoire {
    const n = allNodes.length;
    const purviewSize = purview.length;
    const numPurviewStates = Math.pow(2, purviewSize);
    
    // Marginalize TPM to get cause repertoire
    const repertoire: number[] = Array(numPurviewStates).fill(0);
    const mechanismMask = this.getNodeMask(mechanism, allNodes);
    const purviewIndices = purview.map(p => allNodes.findIndex(n => n.id === p.id));
    
    // For each purview state, calculate probability
    for (let purviewState = 0; purviewState < numPurviewStates; purviewState++) {
      let totalProb = 0;
      let count = 0;
      
      // Marginalize over non-purview states
      for (let fullState = 0; fullState < tpm.length; fullState++) {
        // Check if this state matches the purview state
        let matches = true;
        for (let i = 0; i < purviewIndices.length; i++) {
          const bit = (fullState >> purviewIndices[i]) & 1;
          const expectedBit = (purviewState >> i) & 1;
          if (bit !== expectedBit) {
            matches = false;
            break;
          }
        }
        
        if (matches) {
          // Sum probabilities that lead to mechanism state
          for (let prevState = 0; prevState < tpm.length; prevState++) {
            totalProb += tpm[prevState][fullState];
          }
          count++;
        }
      }
      
      repertoire[purviewState] = count > 0 ? totalProb / count : 0;
    }
    
    // Normalize
    const sum = repertoire.reduce((a, b) => a + b, 0);
    if (sum > 0) {
      for (let i = 0; i < repertoire.length; i++) {
        repertoire[i] /= sum;
      }
    }
    
    // Calculate phi as earth mover's distance from unconstrained distribution
    const uniform = Array(numPurviewStates).fill(1 / numPurviewStates);
    const phi = this.earthMoversDistance(repertoire, uniform);
    
    return {
      purview: purview.map(n => n.id),
      repertoire,
      phi
    };
  }

  /**
   * Calculate effect repertoire for a mechanism-purview pair
   */
  private calculateEffectRepertoire(
    mechanism: SystemNode[],
    purview: SystemNode[],
    tpm: number[][],
    allNodes: SystemNode[]
  ): CauseEffectRepertoire {
    const purviewSize = purview.length;
    const numPurviewStates = Math.pow(2, purviewSize);
    
    // Calculate effect repertoire using forward probabilities
    const repertoire: number[] = Array(numPurviewStates).fill(0);
    const mechanismIndices = mechanism.map(m => allNodes.findIndex(n => n.id === m.id));
    const purviewIndices = purview.map(p => allNodes.findIndex(n => n.id === p.id));
    
    // Current mechanism state
    let mechanismState = 0;
    for (let i = 0; i < mechanism.length; i++) {
      mechanismState |= (mechanism[i].state << i);
    }
    
    // For each possible full state consistent with mechanism
    for (let fullState = 0; fullState < tpm.length; fullState++) {
      // Check if mechanism part matches
      let mechanismMatches = true;
      for (let i = 0; i < mechanismIndices.length; i++) {
        const bit = (fullState >> mechanismIndices[i]) & 1;
        const expectedBit = (mechanismState >> i) & 1;
        if (bit !== expectedBit) {
          mechanismMatches = false;
          break;
        }
      }
      
      if (!mechanismMatches) continue;
      
      // Add contributions to each purview state
      for (let nextState = 0; nextState < tpm.length; nextState++) {
        let purviewState = 0;
        for (let i = 0; i < purviewIndices.length; i++) {
          purviewState |= ((nextState >> purviewIndices[i]) & 1) << i;
        }
        repertoire[purviewState] += tpm[fullState][nextState];
      }
    }
    
    // Normalize
    const sum = repertoire.reduce((a, b) => a + b, 0);
    if (sum > 0) {
      for (let i = 0; i < repertoire.length; i++) {
        repertoire[i] /= sum;
      }
    }
    
    // Calculate phi
    const uniform = Array(numPurviewStates).fill(1 / numPurviewStates);
    const phi = this.earthMoversDistance(repertoire, uniform);
    
    return {
      purview: purview.map(n => n.id),
      repertoire,
      phi
    };
  }

  /**
   * Select core concepts (max phi for each mechanism)
   */
  private selectCoreConcepts(concepts: Concept[]): Concept[] {
    const byMechanism = new Map<string, Concept>();
    
    for (const concept of concepts) {
      const key = concept.mechanism.sort().join(',');
      const existing = byMechanism.get(key);
      if (!existing || concept.phi > existing.phi) {
        byMechanism.set(key, concept);
      }
    }
    
    return Array.from(byMechanism.values());
  }

  /**
   * Find minimum information partition
   */
  private findMinimumInformationPartition(
    nodes: SystemNode[],
    tpm: number[][],
    ces: CauseEffectStructure
  ): MIPResult {
    const n = nodes.length;
    let minPhiLoss = Infinity;
    let bestPartition: Partition = {
      part1: nodes.map(n => n.id),
      part2: [],
      cutType: 'unidirectional'
    };
    
    // Try all possible bipartitions
    for (let partition = 1; partition < Math.pow(2, n) - 1; partition++) {
      const part1 = nodes.filter((_, i) => (partition >> i) & 1);
      const part2 = nodes.filter((_, i) => !((partition >> i) & 1));
      
      if (part1.length === 0 || part2.length === 0) continue;
      
      // Calculate phi loss from this partition
      const phiLoss = this.calculatePartitionPhiLoss(part1, part2, ces);
      
      if (phiLoss < minPhiLoss) {
        minPhiLoss = phiLoss;
        bestPartition = {
          part1: part1.map(n => n.id),
          part2: part2.map(n => n.id),
          cutType: 'bidirectional'
        };
      }
    }
    
    return {
      partition: bestPartition,
      phiLoss: minPhiLoss,
      isIrreducible: minPhiLoss > 0.01
    };
  }

  /**
   * Estimate MIP using greedy algorithm (for large systems)
   */
  private estimateMIP(
    nodes: SystemNode[],
    tpm: number[][],
    ces: CauseEffectStructure
  ): MIPResult {
    // Start with all nodes in part1
    const part1 = [...nodes];
    const part2: SystemNode[] = [];
    
    // Greedily move nodes to minimize phi
    let improved = true;
    while (improved && part1.length > 1) {
      improved = false;
      let bestMove = -1;
      let bestPhiLoss = this.calculatePartitionPhiLoss(part1, part2, ces);
      
      for (let i = 0; i < part1.length; i++) {
        const testPart1 = part1.filter((_, j) => j !== i);
        const testPart2 = [...part2, part1[i]];
        const phiLoss = this.calculatePartitionPhiLoss(testPart1, testPart2, ces);
        
        if (phiLoss < bestPhiLoss) {
          bestPhiLoss = phiLoss;
          bestMove = i;
          improved = true;
        }
      }
      
      if (bestMove >= 0) {
        part2.push(part1[bestMove]);
        part1.splice(bestMove, 1);
      }
    }
    
    const finalPhiLoss = this.calculatePartitionPhiLoss(part1, part2, ces);
    
    return {
      partition: {
        part1: part1.map(n => n.id),
        part2: part2.map(n => n.id),
        cutType: 'bidirectional'
      },
      phiLoss: finalPhiLoss,
      isIrreducible: finalPhiLoss > 0.01
    };
  }

  /**
   * Calculate phi loss from a partition
   */
  private calculatePartitionPhiLoss(
    part1: SystemNode[],
    part2: SystemNode[],
    ces: CauseEffectStructure
  ): number {
    let totalLoss = 0;
    
    for (const concept of ces.concepts) {
      // Check if this concept spans the partition
      const mechanismInPart1 = concept.mechanism.some(m => part1.some(n => n.id === m));
      const mechanismInPart2 = concept.mechanism.some(m => part2.some(n => n.id === m));
      const purviewInPart1 = concept.purview.some(p => part1.some(n => n.id === p));
      const purviewInPart2 = concept.purview.some(p => part2.some(n => n.id === p));
      
      // If concept spans partition, it contributes to phi loss
      if ((mechanismInPart1 && purviewInPart2) || (mechanismInPart2 && purviewInPart1)) {
        totalLoss += concept.phi;
      }
    }
    
    return totalLoss;
  }

  /**
   * Calculate system complexity metrics
   */
  private calculateSystemComplexity(
    nodes: SystemNode[],
    connections: SystemConnection[]
  ): SystemComplexityMetrics {
    const nodeCount = nodes.length;
    const edgeCount = connections.length;
    const maxEdges = nodeCount * (nodeCount - 1);
    const density = maxEdges > 0 ? edgeCount / maxEdges : 0;
    
    // Calculate clustering coefficient
    const clustering = this.calculateClusteringCoefficient(nodes, connections);
    
    // Calculate modularity (simplified)
    const modularity = this.calculateModularity(nodes, connections);
    
    // Integration degree based on connectivity patterns
    const integrationDegree = (density + clustering) / 2;
    
    return {
      nodeCount,
      edgeCount,
      density,
      clustering,
      modularity,
      integrationDegree
    };
  }

  /**
   * Calculate clustering coefficient
   */
  private calculateClusteringCoefficient(
    nodes: SystemNode[],
    connections: SystemConnection[]
  ): number {
    if (nodes.length < 3) return 0;
    
    const neighbors = new Map<string, Set<string>>();
    for (const node of nodes) {
      neighbors.set(node.id, new Set());
    }
    
    for (const conn of connections) {
      neighbors.get(conn.from)?.add(conn.to);
      neighbors.get(conn.to)?.add(conn.from);
    }
    
    let totalCoeff = 0;
    let count = 0;
    
    for (const node of nodes) {
      const nodeNeighbors = neighbors.get(node.id);
      if (!nodeNeighbors || nodeNeighbors.size < 2) continue;
      
      const neighborList = Array.from(nodeNeighbors);
      let triangles = 0;
      const possibleTriangles = neighborList.length * (neighborList.length - 1) / 2;
      
      for (let i = 0; i < neighborList.length; i++) {
        for (let j = i + 1; j < neighborList.length; j++) {
          if (neighbors.get(neighborList[i])?.has(neighborList[j])) {
            triangles++;
          }
        }
      }
      
      if (possibleTriangles > 0) {
        totalCoeff += triangles / possibleTriangles;
        count++;
      }
    }
    
    return count > 0 ? totalCoeff / count : 0;
  }

  /**
   * Calculate modularity (simplified)
   */
  private calculateModularity(
    nodes: SystemNode[],
    connections: SystemConnection[]
  ): number {
    // Group by type
    const typeGroups = new Map<string, string[]>();
    for (const node of nodes) {
      const group = typeGroups.get(node.type) || [];
      group.push(node.id);
      typeGroups.set(node.type, group);
    }
    
    let intraEdges = 0;
    let totalEdges = connections.length;
    
    for (const conn of connections) {
      const fromNode = nodes.find(n => n.id === conn.from);
      const toNode = nodes.find(n => n.id === conn.to);
      if (fromNode && toNode && fromNode.type === toNode.type) {
        intraEdges++;
      }
    }
    
    return totalEdges > 0 ? intraEdges / totalEdges : 0;
  }

  /**
   * Calculate maximum possible phi for a system of size n
   */
  private calculatePhiMax(n: number): number {
    // Phi max grows roughly as log2(n) for well-integrated systems
    return Math.log2(n + 1);
  }

  /**
   * Get node mask for subset
   */
  private getNodeMask(subset: SystemNode[], allNodes: SystemNode[]): number {
    let mask = 0;
    for (const node of subset) {
      const idx = allNodes.findIndex(n => n.id === node.id);
      if (idx >= 0) {
        mask |= (1 << idx);
      }
    }
    return mask;
  }

  /**
   * Earth Mover's Distance between two distributions
   */
  private earthMoversDistance(p: number[], q: number[]): number {
    if (p.length !== q.length) return 0;
    
    let distance = 0;
    let cumulative = 0;
    
    for (let i = 0; i < p.length; i++) {
      cumulative += p[i] - q[i];
      distance += Math.abs(cumulative);
    }
    
    return distance;
  }

  /**
   * Sample representative nodes from larger system
   */
  private sampleNodes(nodes: SystemNode[], maxNodes: number): SystemNode[] {
    if (nodes.length <= maxNodes) return nodes;
    
    // Stratified sampling by type
    const byType = new Map<string, SystemNode[]>();
    for (const node of nodes) {
      const list = byType.get(node.type) || [];
      list.push(node);
      byType.set(node.type, list);
    }
    
    const sampled: SystemNode[] = [];
    const typesCount = byType.size;
    const perType = Math.floor(maxNodes / typesCount);
    
    for (const [, typeNodes] of byType) {
      // Sort by activation (most active first) and take top perType
      typeNodes.sort((a, b) => {
        const aAvg = a.activationHistory.reduce((sum, v) => sum + v, 0) / a.activationHistory.length;
        const bAvg = b.activationHistory.reduce((sum, v) => sum + v, 0) / b.activationHistory.length;
        return bAvg - aAvg;
      });
      sampled.push(...typeNodes.slice(0, perType));
    }
    
    return sampled.slice(0, maxNodes);
  }

  /**
   * Store phi result in database
   */
  private async storePhiResult(tenantId: string, result: PhiCalculationResult): Promise<void> {
    await executeStatement(
      `INSERT INTO integrated_information (
        tenant_id, phi, phi_max, concept_structure, integration_graph,
        partitions, mip, decomposability, causal_density, updated_at
      ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, NOW())
      ON CONFLICT (tenant_id) DO UPDATE SET
        phi = $2, phi_max = $3, concept_structure = $4, integration_graph = $5,
        partitions = $6, mip = $7, decomposability = $8, causal_density = $9, updated_at = NOW()`,
      [
        { name: 'tenantId', value: { stringValue: tenantId } },
        { name: 'phi', value: { doubleValue: result.phi } },
        { name: 'phiMax', value: { doubleValue: result.phiMax } },
        { name: 'conceptStructure', value: { stringValue: JSON.stringify(result.causeEffectStructure.concepts) } },
        { name: 'integrationGraph', value: { stringValue: JSON.stringify([]) } },
        { name: 'partitions', value: { stringValue: JSON.stringify([result.minimumInformationPartition.partition]) } },
        { name: 'mip', value: { stringValue: JSON.stringify(result.minimumInformationPartition) } },
        { name: 'decomposability', value: { doubleValue: result.minimumInformationPartition.isIrreducible ? 0 : 1 } },
        { name: 'causalDensity', value: { doubleValue: result.systemComplexity.density } },
      ]
    );
  }
}

// Export singleton instance
export const iitPhiCalculationService = new IITPhiCalculationService();
