// RADIANT v4.18.0 - Self-Hosted Model Registry
// 56 self-hosted models with comprehensive metadata for AGI orchestration
// Models are deployed on AWS SageMaker with thermal management

// ============================================================================
// Types
// ============================================================================

export type ModelFamily = 
  | 'llama' | 'qwen' | 'mistral' | 'deepseek' | 'phi' | 'gemma'
  | 'falcon' | 'mpt' | 'yi' | 'internlm' | 'baichuan' | 'codellama'
  | 'starcoder' | 'wizardcoder' | 'stable_diffusion' | 'flux'
  | 'whisper' | 'bark' | 'musicgen' | 'audiogen' | 'point_e' | 'shap_e';

export type ModelModality = 'text' | 'image' | 'audio' | 'video' | '3d' | 'code' | 'embedding';

export type InstanceType = 
  | 'ml.g5.xlarge' | 'ml.g5.2xlarge' | 'ml.g5.4xlarge' | 'ml.g5.8xlarge' | 'ml.g5.12xlarge' | 'ml.g5.48xlarge'
  | 'ml.p4d.24xlarge' | 'ml.p5.48xlarge' | 'ml.inf2.xlarge' | 'ml.inf2.8xlarge' | 'ml.inf2.24xlarge';

export type DomainStrength = 'excellent' | 'good' | 'moderate' | 'basic';

export interface SelfHostedModelDefinition {
  id: string;
  family: ModelFamily;
  displayName: string;
  description: string;
  version: string;
  parameterCount: string; // e.g., "70B", "7B"
  
  // Capabilities
  inputModalities: ModelModality[];
  outputModalities: ModelModality[];
  capabilities: string[];
  
  // Context & Generation
  contextWindow: number;
  maxOutputTokens: number;
  
  // Hardware Requirements
  instanceType: InstanceType;
  minVRAM: number; // GB
  quantization?: 'fp16' | 'bf16' | 'int8' | 'int4' | 'awq' | 'gptq';
  tensorParallelism?: number;
  
  // Pricing (estimated cost per 1M tokens on SageMaker)
  pricing: { inputPer1M: number; outputPer1M: number };
  
  // Domain Strengths (for orchestration)
  domainStrengths: {
    domain: string;
    strength: DomainStrength;
    subspecialties?: string[];
  }[];
  
  // Orchestration Hints
  orchestration: {
    preferredFor: string[];      // When to prefer this model
    avoidFor: string[];          // When to avoid this model
    pairsWellWith?: string[];    // Models that complement this one
    fallbackTo?: string;         // Fallback model if this fails
    minTier: number;             // Minimum subscription tier
    latencyClass: 'fast' | 'medium' | 'slow';
    qualityTier: 'premium' | 'standard' | 'economy';
  };
  
  // Media Support (for Think Tank)
  mediaSupport?: {
    imageInput?: boolean;
    imageOutput?: boolean;
    audioInput?: boolean;
    audioOutput?: boolean;
    videoInput?: boolean;
    videoOutput?: boolean;
    documentInput?: boolean;
    maxImageSize?: number;      // pixels
    maxAudioLength?: number;    // seconds
    supportedFormats?: string[];
  };
  
  // Metadata
  license: 'apache-2.0' | 'llama' | 'mit' | 'cc-by-nc' | 'proprietary' | 'research';
  commercialUse: boolean;
  releaseDate: string;
  huggingFaceId?: string;
  paperUrl?: string;
}

// ============================================================================
// TEXT GENERATION MODELS (LLMs)
// ============================================================================

export const SELF_HOSTED_TEXT_MODELS: SelfHostedModelDefinition[] = [
  // ═══════════════════════════════════════════════════════════════════════════
  // LLAMA FAMILY
  // ═══════════════════════════════════════════════════════════════════════════
  {
    id: 'llama-3.3-70b-instruct',
    family: 'llama',
    displayName: 'Llama 3.3 70B Instruct',
    description: 'Meta\'s latest flagship open model with excellent reasoning and instruction following',
    version: '3.3',
    parameterCount: '70B',
    inputModalities: ['text'],
    outputModalities: ['text'],
    capabilities: ['chat', 'reasoning', 'code', 'function_calling', 'multilingual', 'analysis'],
    contextWindow: 131072,
    maxOutputTokens: 4096,
    instanceType: 'ml.p4d.24xlarge',
    minVRAM: 140,
    quantization: 'bf16',
    tensorParallelism: 8,
    pricing: { inputPer1M: 0.65, outputPer1M: 2.75 },
    domainStrengths: [
      { domain: 'software_engineering', strength: 'excellent', subspecialties: ['python', 'javascript', 'systems'] },
      { domain: 'business', strength: 'good', subspecialties: ['strategy', 'analysis'] },
      { domain: 'science', strength: 'good', subspecialties: ['research', 'data_analysis'] },
      { domain: 'creative', strength: 'moderate', subspecialties: ['writing', 'brainstorming'] },
    ],
    orchestration: {
      preferredFor: ['code_generation', 'technical_analysis', 'long_form_content', 'multilingual_tasks'],
      avoidFor: ['real_time_info', 'current_events', 'specialized_medical'],
      pairsWellWith: ['qwen2.5-72b-instruct', 'deepseek-coder-33b'],
      fallbackTo: 'llama-3.2-8b-instruct',
      minTier: 2,
      latencyClass: 'medium',
      qualityTier: 'premium',
    },
    license: 'llama',
    commercialUse: true,
    releaseDate: '2024-12-06',
    huggingFaceId: 'meta-llama/Llama-3.3-70B-Instruct',
  },
  {
    id: 'llama-3.2-90b-vision',
    family: 'llama',
    displayName: 'Llama 3.2 90B Vision',
    description: 'Multimodal model with vision capabilities for image understanding',
    version: '3.2',
    parameterCount: '90B',
    inputModalities: ['text', 'image'],
    outputModalities: ['text'],
    capabilities: ['chat', 'vision', 'image_analysis', 'ocr', 'diagram_understanding'],
    contextWindow: 131072,
    maxOutputTokens: 4096,
    instanceType: 'ml.p5.48xlarge',
    minVRAM: 180,
    quantization: 'bf16',
    tensorParallelism: 8,
    pricing: { inputPer1M: 1.20, outputPer1M: 4.80 },
    domainStrengths: [
      { domain: 'visual_analysis', strength: 'excellent', subspecialties: ['charts', 'diagrams', 'documents'] },
      { domain: 'software_engineering', strength: 'good', subspecialties: ['ui_review', 'architecture'] },
      { domain: 'healthcare', strength: 'moderate', subspecialties: ['medical_imaging_basic'] },
    ],
    orchestration: {
      preferredFor: ['image_understanding', 'document_analysis', 'visual_qa', 'chart_interpretation'],
      avoidFor: ['audio_tasks', 'video_generation', 'text_only_tasks'],
      pairsWellWith: ['llama-3.3-70b-instruct'],
      fallbackTo: 'llama-3.2-11b-vision',
      minTier: 3,
      latencyClass: 'slow',
      qualityTier: 'premium',
    },
    mediaSupport: {
      imageInput: true,
      maxImageSize: 4096,
      supportedFormats: ['jpg', 'png', 'webp', 'gif'],
      documentInput: true,
    },
    license: 'llama',
    commercialUse: true,
    releaseDate: '2024-09-25',
    huggingFaceId: 'meta-llama/Llama-3.2-90B-Vision-Instruct',
  },
  {
    id: 'llama-3.2-11b-vision',
    family: 'llama',
    displayName: 'Llama 3.2 11B Vision',
    description: 'Compact multimodal model balancing speed and vision capability',
    version: '3.2',
    parameterCount: '11B',
    inputModalities: ['text', 'image'],
    outputModalities: ['text'],
    capabilities: ['chat', 'vision', 'image_analysis', 'ocr'],
    contextWindow: 131072,
    maxOutputTokens: 4096,
    instanceType: 'ml.g5.4xlarge',
    minVRAM: 24,
    quantization: 'bf16',
    pricing: { inputPer1M: 0.18, outputPer1M: 0.72 },
    domainStrengths: [
      { domain: 'visual_analysis', strength: 'good', subspecialties: ['basic_ocr', 'simple_diagrams'] },
    ],
    orchestration: {
      preferredFor: ['quick_image_analysis', 'basic_ocr', 'image_captioning'],
      avoidFor: ['complex_visual_reasoning', 'detailed_chart_analysis'],
      fallbackTo: 'llama-3.2-3b-instruct',
      minTier: 1,
      latencyClass: 'fast',
      qualityTier: 'standard',
    },
    mediaSupport: {
      imageInput: true,
      maxImageSize: 2048,
      supportedFormats: ['jpg', 'png', 'webp'],
    },
    license: 'llama',
    commercialUse: true,
    releaseDate: '2024-09-25',
    huggingFaceId: 'meta-llama/Llama-3.2-11B-Vision-Instruct',
  },
  {
    id: 'llama-3.2-8b-instruct',
    family: 'llama',
    displayName: 'Llama 3.2 8B Instruct',
    description: 'Fast and efficient model for general tasks',
    version: '3.2',
    parameterCount: '8B',
    inputModalities: ['text'],
    outputModalities: ['text'],
    capabilities: ['chat', 'code', 'function_calling'],
    contextWindow: 131072,
    maxOutputTokens: 4096,
    instanceType: 'ml.g5.2xlarge',
    minVRAM: 16,
    quantization: 'bf16',
    pricing: { inputPer1M: 0.10, outputPer1M: 0.40 },
    domainStrengths: [
      { domain: 'general', strength: 'good' },
      { domain: 'software_engineering', strength: 'moderate' },
    ],
    orchestration: {
      preferredFor: ['quick_responses', 'simple_tasks', 'high_volume'],
      avoidFor: ['complex_reasoning', 'specialized_domains'],
      minTier: 1,
      latencyClass: 'fast',
      qualityTier: 'economy',
    },
    license: 'llama',
    commercialUse: true,
    releaseDate: '2024-09-25',
    huggingFaceId: 'meta-llama/Llama-3.2-8B-Instruct',
  },
  {
    id: 'llama-3.2-3b-instruct',
    family: 'llama',
    displayName: 'Llama 3.2 3B Instruct',
    description: 'Ultra-fast lightweight model for edge and high-throughput',
    version: '3.2',
    parameterCount: '3B',
    inputModalities: ['text'],
    outputModalities: ['text'],
    capabilities: ['chat', 'summarization'],
    contextWindow: 131072,
    maxOutputTokens: 2048,
    instanceType: 'ml.g5.xlarge',
    minVRAM: 8,
    quantization: 'bf16',
    pricing: { inputPer1M: 0.04, outputPer1M: 0.16 },
    domainStrengths: [
      { domain: 'general', strength: 'moderate' },
    ],
    orchestration: {
      preferredFor: ['classification', 'simple_qa', 'high_throughput'],
      avoidFor: ['complex_tasks', 'detailed_analysis'],
      minTier: 1,
      latencyClass: 'fast',
      qualityTier: 'economy',
    },
    license: 'llama',
    commercialUse: true,
    releaseDate: '2024-09-25',
    huggingFaceId: 'meta-llama/Llama-3.2-3B-Instruct',
  },

  // ═══════════════════════════════════════════════════════════════════════════
  // QWEN FAMILY
  // ═══════════════════════════════════════════════════════════════════════════
  {
    id: 'qwen2.5-72b-instruct',
    family: 'qwen',
    displayName: 'Qwen 2.5 72B Instruct',
    description: 'Alibaba\'s flagship model with excellent multilingual and reasoning',
    version: '2.5',
    parameterCount: '72B',
    inputModalities: ['text'],
    outputModalities: ['text'],
    capabilities: ['chat', 'reasoning', 'code', 'function_calling', 'multilingual', 'math'],
    contextWindow: 131072,
    maxOutputTokens: 8192,
    instanceType: 'ml.p4d.24xlarge',
    minVRAM: 144,
    quantization: 'bf16',
    tensorParallelism: 8,
    pricing: { inputPer1M: 0.40, outputPer1M: 1.20 },
    domainStrengths: [
      { domain: 'mathematics', strength: 'excellent', subspecialties: ['calculus', 'algebra', 'statistics'] },
      { domain: 'software_engineering', strength: 'excellent', subspecialties: ['python', 'algorithms'] },
      { domain: 'science', strength: 'good', subspecialties: ['physics', 'chemistry'] },
      { domain: 'multilingual', strength: 'excellent', subspecialties: ['chinese', 'english', 'japanese'] },
    ],
    orchestration: {
      preferredFor: ['math_problems', 'multilingual_tasks', 'chinese_content', 'code_generation'],
      avoidFor: ['real_time_info', 'western_cultural_context'],
      pairsWellWith: ['llama-3.3-70b-instruct', 'deepseek-v3'],
      fallbackTo: 'qwen2.5-32b-instruct',
      minTier: 2,
      latencyClass: 'medium',
      qualityTier: 'premium',
    },
    license: 'apache-2.0',
    commercialUse: true,
    releaseDate: '2024-09-19',
    huggingFaceId: 'Qwen/Qwen2.5-72B-Instruct',
  },
  {
    id: 'qwen2.5-32b-instruct',
    family: 'qwen',
    displayName: 'Qwen 2.5 32B Instruct',
    description: 'Balanced Qwen model with good quality and speed',
    version: '2.5',
    parameterCount: '32B',
    inputModalities: ['text'],
    outputModalities: ['text'],
    capabilities: ['chat', 'reasoning', 'code', 'function_calling', 'multilingual'],
    contextWindow: 131072,
    maxOutputTokens: 8192,
    instanceType: 'ml.g5.12xlarge',
    minVRAM: 64,
    quantization: 'bf16',
    tensorParallelism: 4,
    pricing: { inputPer1M: 0.20, outputPer1M: 0.60 },
    domainStrengths: [
      { domain: 'mathematics', strength: 'good' },
      { domain: 'software_engineering', strength: 'good' },
      { domain: 'multilingual', strength: 'excellent' },
    ],
    orchestration: {
      preferredFor: ['multilingual_tasks', 'balanced_workloads'],
      avoidFor: ['specialized_domains'],
      fallbackTo: 'qwen2.5-7b-instruct',
      minTier: 2,
      latencyClass: 'medium',
      qualityTier: 'standard',
    },
    license: 'apache-2.0',
    commercialUse: true,
    releaseDate: '2024-09-19',
    huggingFaceId: 'Qwen/Qwen2.5-32B-Instruct',
  },
  {
    id: 'qwen2.5-coder-32b',
    family: 'qwen',
    displayName: 'Qwen 2.5 Coder 32B',
    description: 'Specialized coding model with excellent code generation',
    version: '2.5',
    parameterCount: '32B',
    inputModalities: ['text', 'code'],
    outputModalities: ['text', 'code'],
    capabilities: ['code', 'code_generation', 'code_review', 'debugging', 'refactoring'],
    contextWindow: 131072,
    maxOutputTokens: 8192,
    instanceType: 'ml.g5.12xlarge',
    minVRAM: 64,
    quantization: 'bf16',
    tensorParallelism: 4,
    pricing: { inputPer1M: 0.25, outputPer1M: 0.75 },
    domainStrengths: [
      { domain: 'software_engineering', strength: 'excellent', subspecialties: ['python', 'javascript', 'rust', 'go'] },
    ],
    orchestration: {
      preferredFor: ['code_generation', 'code_review', 'debugging', 'refactoring'],
      avoidFor: ['non_coding_tasks', 'creative_writing'],
      pairsWellWith: ['deepseek-coder-33b', 'codellama-70b'],
      fallbackTo: 'qwen2.5-coder-7b',
      minTier: 2,
      latencyClass: 'medium',
      qualityTier: 'premium',
    },
    license: 'apache-2.0',
    commercialUse: true,
    releaseDate: '2024-11-12',
    huggingFaceId: 'Qwen/Qwen2.5-Coder-32B-Instruct',
  },
  {
    id: 'qwen2.5-7b-instruct',
    family: 'qwen',
    displayName: 'Qwen 2.5 7B Instruct',
    description: 'Fast and efficient Qwen model',
    version: '2.5',
    parameterCount: '7B',
    inputModalities: ['text'],
    outputModalities: ['text'],
    capabilities: ['chat', 'code', 'multilingual'],
    contextWindow: 131072,
    maxOutputTokens: 8192,
    instanceType: 'ml.g5.2xlarge',
    minVRAM: 16,
    quantization: 'bf16',
    pricing: { inputPer1M: 0.08, outputPer1M: 0.24 },
    domainStrengths: [
      { domain: 'general', strength: 'good' },
      { domain: 'multilingual', strength: 'good' },
    ],
    orchestration: {
      preferredFor: ['quick_tasks', 'multilingual', 'high_throughput'],
      avoidFor: ['complex_reasoning'],
      minTier: 1,
      latencyClass: 'fast',
      qualityTier: 'economy',
    },
    license: 'apache-2.0',
    commercialUse: true,
    releaseDate: '2024-09-19',
    huggingFaceId: 'Qwen/Qwen2.5-7B-Instruct',
  },
  {
    id: 'qwen2.5-coder-7b',
    family: 'qwen',
    displayName: 'Qwen 2.5 Coder 7B',
    description: 'Fast coding model for high-throughput code tasks',
    version: '2.5',
    parameterCount: '7B',
    inputModalities: ['text', 'code'],
    outputModalities: ['text', 'code'],
    capabilities: ['code', 'code_generation', 'code_completion'],
    contextWindow: 131072,
    maxOutputTokens: 8192,
    instanceType: 'ml.g5.2xlarge',
    minVRAM: 16,
    quantization: 'bf16',
    pricing: { inputPer1M: 0.10, outputPer1M: 0.30 },
    domainStrengths: [
      { domain: 'software_engineering', strength: 'good' },
    ],
    orchestration: {
      preferredFor: ['code_completion', 'simple_code_tasks', 'high_throughput'],
      avoidFor: ['complex_architecture', 'code_review'],
      minTier: 1,
      latencyClass: 'fast',
      qualityTier: 'economy',
    },
    license: 'apache-2.0',
    commercialUse: true,
    releaseDate: '2024-11-12',
    huggingFaceId: 'Qwen/Qwen2.5-Coder-7B-Instruct',
  },
  {
    id: 'qwen2-vl-72b',
    family: 'qwen',
    displayName: 'Qwen2-VL 72B',
    description: 'Qwen\'s flagship vision-language model',
    version: '2.0',
    parameterCount: '72B',
    inputModalities: ['text', 'image', 'video'],
    outputModalities: ['text'],
    capabilities: ['chat', 'vision', 'video_understanding', 'ocr', 'document_analysis'],
    contextWindow: 32768,
    maxOutputTokens: 4096,
    instanceType: 'ml.p5.48xlarge',
    minVRAM: 180,
    quantization: 'bf16',
    tensorParallelism: 8,
    pricing: { inputPer1M: 1.50, outputPer1M: 6.00 },
    domainStrengths: [
      { domain: 'visual_analysis', strength: 'excellent', subspecialties: ['documents', 'charts', 'video'] },
      { domain: 'multilingual', strength: 'excellent' },
    ],
    orchestration: {
      preferredFor: ['video_analysis', 'document_understanding', 'multilingual_vision'],
      avoidFor: ['text_only_tasks', 'real_time_video'],
      pairsWellWith: ['qwen2.5-72b-instruct'],
      fallbackTo: 'qwen2-vl-7b',
      minTier: 3,
      latencyClass: 'slow',
      qualityTier: 'premium',
    },
    mediaSupport: {
      imageInput: true,
      videoInput: true,
      maxImageSize: 4096,
      maxAudioLength: 300,
      supportedFormats: ['jpg', 'png', 'webp', 'mp4', 'avi', 'mov'],
    },
    license: 'apache-2.0',
    commercialUse: true,
    releaseDate: '2024-08-29',
    huggingFaceId: 'Qwen/Qwen2-VL-72B-Instruct',
  },
  {
    id: 'qwen2-vl-7b',
    family: 'qwen',
    displayName: 'Qwen2-VL 7B',
    description: 'Fast vision-language model for quick image tasks',
    version: '2.0',
    parameterCount: '7B',
    inputModalities: ['text', 'image'],
    outputModalities: ['text'],
    capabilities: ['chat', 'vision', 'ocr'],
    contextWindow: 32768,
    maxOutputTokens: 4096,
    instanceType: 'ml.g5.4xlarge',
    minVRAM: 24,
    quantization: 'bf16',
    pricing: { inputPer1M: 0.20, outputPer1M: 0.80 },
    domainStrengths: [
      { domain: 'visual_analysis', strength: 'good' },
    ],
    orchestration: {
      preferredFor: ['quick_image_analysis', 'basic_ocr'],
      avoidFor: ['complex_visual_reasoning', 'video'],
      minTier: 1,
      latencyClass: 'fast',
      qualityTier: 'standard',
    },
    mediaSupport: {
      imageInput: true,
      maxImageSize: 2048,
      supportedFormats: ['jpg', 'png', 'webp'],
    },
    license: 'apache-2.0',
    commercialUse: true,
    releaseDate: '2024-08-29',
    huggingFaceId: 'Qwen/Qwen2-VL-7B-Instruct',
  },
  {
    id: 'qwen2-audio-7b',
    family: 'qwen',
    displayName: 'Qwen2-Audio 7B',
    description: 'Audio-language model for speech understanding',
    version: '2.0',
    parameterCount: '7B',
    inputModalities: ['text', 'audio'],
    outputModalities: ['text'],
    capabilities: ['chat', 'audio_understanding', 'transcription', 'audio_qa'],
    contextWindow: 32768,
    maxOutputTokens: 4096,
    instanceType: 'ml.g5.4xlarge',
    minVRAM: 24,
    quantization: 'bf16',
    pricing: { inputPer1M: 0.25, outputPer1M: 1.00 },
    domainStrengths: [
      { domain: 'audio_processing', strength: 'excellent', subspecialties: ['speech', 'music', 'sound'] },
    ],
    orchestration: {
      preferredFor: ['audio_transcription', 'audio_qa', 'speech_analysis'],
      avoidFor: ['text_only_tasks', 'image_tasks'],
      pairsWellWith: ['whisper-large-v3'],
      minTier: 2,
      latencyClass: 'medium',
      qualityTier: 'premium',
    },
    mediaSupport: {
      audioInput: true,
      maxAudioLength: 600,
      supportedFormats: ['mp3', 'wav', 'flac', 'm4a', 'ogg'],
    },
    license: 'apache-2.0',
    commercialUse: true,
    releaseDate: '2024-08-09',
    huggingFaceId: 'Qwen/Qwen2-Audio-7B-Instruct',
  },

  // ═══════════════════════════════════════════════════════════════════════════
  // MISTRAL FAMILY
  // ═══════════════════════════════════════════════════════════════════════════
  {
    id: 'mistral-large-2411',
    family: 'mistral',
    displayName: 'Mistral Large 2411',
    description: 'Mistral\'s flagship model with excellent reasoning and multilingual',
    version: '24.11',
    parameterCount: '123B',
    inputModalities: ['text'],
    outputModalities: ['text'],
    capabilities: ['chat', 'reasoning', 'code', 'function_calling', 'multilingual'],
    contextWindow: 131072,
    maxOutputTokens: 8192,
    instanceType: 'ml.p5.48xlarge',
    minVRAM: 248,
    quantization: 'bf16',
    tensorParallelism: 8,
    pricing: { inputPer1M: 0.80, outputPer1M: 2.40 },
    domainStrengths: [
      { domain: 'software_engineering', strength: 'excellent', subspecialties: ['python', 'rust'] },
      { domain: 'multilingual', strength: 'excellent', subspecialties: ['french', 'german', 'spanish'] },
      { domain: 'business', strength: 'good' },
    ],
    orchestration: {
      preferredFor: ['european_languages', 'code_generation', 'business_analysis'],
      avoidFor: ['asian_languages', 'specialized_medical'],
      pairsWellWith: ['llama-3.3-70b-instruct'],
      fallbackTo: 'mistral-nemo-12b',
      minTier: 3,
      latencyClass: 'slow',
      qualityTier: 'premium',
    },
    license: 'apache-2.0',
    commercialUse: true,
    releaseDate: '2024-11-18',
    huggingFaceId: 'mistralai/Mistral-Large-Instruct-2411',
  },
  {
    id: 'mistral-nemo-12b',
    family: 'mistral',
    displayName: 'Mistral Nemo 12B',
    description: 'Efficient model jointly developed with NVIDIA',
    version: '1.0',
    parameterCount: '12B',
    inputModalities: ['text'],
    outputModalities: ['text'],
    capabilities: ['chat', 'code', 'function_calling'],
    contextWindow: 131072,
    maxOutputTokens: 4096,
    instanceType: 'ml.g5.4xlarge',
    minVRAM: 24,
    quantization: 'bf16',
    pricing: { inputPer1M: 0.15, outputPer1M: 0.45 },
    domainStrengths: [
      { domain: 'general', strength: 'good' },
      { domain: 'software_engineering', strength: 'good' },
    ],
    orchestration: {
      preferredFor: ['quick_responses', 'code_assistance', 'european_languages'],
      avoidFor: ['complex_reasoning', 'specialized_domains'],
      fallbackTo: 'mistral-7b-instruct',
      minTier: 1,
      latencyClass: 'fast',
      qualityTier: 'standard',
    },
    license: 'apache-2.0',
    commercialUse: true,
    releaseDate: '2024-07-18',
    huggingFaceId: 'mistralai/Mistral-Nemo-Instruct-2407',
  },
  {
    id: 'mistral-7b-instruct',
    family: 'mistral',
    displayName: 'Mistral 7B Instruct',
    description: 'Fast and efficient baseline Mistral model',
    version: '0.3',
    parameterCount: '7B',
    inputModalities: ['text'],
    outputModalities: ['text'],
    capabilities: ['chat', 'code'],
    contextWindow: 32768,
    maxOutputTokens: 4096,
    instanceType: 'ml.g5.2xlarge',
    minVRAM: 16,
    quantization: 'bf16',
    pricing: { inputPer1M: 0.06, outputPer1M: 0.18 },
    domainStrengths: [
      { domain: 'general', strength: 'moderate' },
    ],
    orchestration: {
      preferredFor: ['simple_tasks', 'high_throughput'],
      avoidFor: ['complex_reasoning', 'long_context'],
      minTier: 1,
      latencyClass: 'fast',
      qualityTier: 'economy',
    },
    license: 'apache-2.0',
    commercialUse: true,
    releaseDate: '2024-05-22',
    huggingFaceId: 'mistralai/Mistral-7B-Instruct-v0.3',
  },
  {
    id: 'codestral-22b',
    family: 'mistral',
    displayName: 'Codestral 22B',
    description: 'Mistral\'s specialized code model',
    version: '1.0',
    parameterCount: '22B',
    inputModalities: ['text', 'code'],
    outputModalities: ['text', 'code'],
    capabilities: ['code', 'code_generation', 'code_review', 'debugging', 'fill_in_middle'],
    contextWindow: 32768,
    maxOutputTokens: 8192,
    instanceType: 'ml.g5.8xlarge',
    minVRAM: 48,
    quantization: 'bf16',
    tensorParallelism: 2,
    pricing: { inputPer1M: 0.30, outputPer1M: 0.90 },
    domainStrengths: [
      { domain: 'software_engineering', strength: 'excellent', subspecialties: ['python', 'javascript', 'rust', 'go', 'java'] },
    ],
    orchestration: {
      preferredFor: ['code_generation', 'fill_in_middle', 'code_completion'],
      avoidFor: ['non_coding_tasks'],
      pairsWellWith: ['qwen2.5-coder-32b', 'deepseek-coder-33b'],
      fallbackTo: 'mistral-7b-instruct',
      minTier: 2,
      latencyClass: 'medium',
      qualityTier: 'premium',
    },
    license: 'cc-by-nc',
    commercialUse: false,
    releaseDate: '2024-05-29',
    huggingFaceId: 'mistralai/Codestral-22B-v0.1',
  },
  {
    id: 'pixtral-12b',
    family: 'mistral',
    displayName: 'Pixtral 12B',
    description: 'Mistral\'s vision-language model',
    version: '1.0',
    parameterCount: '12B',
    inputModalities: ['text', 'image'],
    outputModalities: ['text'],
    capabilities: ['chat', 'vision', 'image_analysis', 'ocr'],
    contextWindow: 131072,
    maxOutputTokens: 4096,
    instanceType: 'ml.g5.4xlarge',
    minVRAM: 24,
    quantization: 'bf16',
    pricing: { inputPer1M: 0.20, outputPer1M: 0.60 },
    domainStrengths: [
      { domain: 'visual_analysis', strength: 'good', subspecialties: ['documents', 'diagrams'] },
    ],
    orchestration: {
      preferredFor: ['image_understanding', 'document_ocr'],
      avoidFor: ['complex_visual_reasoning', 'video'],
      fallbackTo: 'llama-3.2-11b-vision',
      minTier: 2,
      latencyClass: 'medium',
      qualityTier: 'standard',
    },
    mediaSupport: {
      imageInput: true,
      maxImageSize: 2048,
      supportedFormats: ['jpg', 'png', 'webp'],
    },
    license: 'apache-2.0',
    commercialUse: true,
    releaseDate: '2024-09-11',
    huggingFaceId: 'mistralai/Pixtral-12B-2409',
  },

  // ═══════════════════════════════════════════════════════════════════════════
  // DEEPSEEK FAMILY
  // ═══════════════════════════════════════════════════════════════════════════
  {
    id: 'deepseek-v3',
    family: 'deepseek',
    displayName: 'DeepSeek V3',
    description: 'DeepSeek\'s flagship MoE model with 671B params (37B active)',
    version: '3.0',
    parameterCount: '671B',
    inputModalities: ['text'],
    outputModalities: ['text'],
    capabilities: ['chat', 'reasoning', 'code', 'math', 'function_calling', 'multilingual'],
    contextWindow: 131072,
    maxOutputTokens: 8192,
    instanceType: 'ml.p5.48xlarge',
    minVRAM: 320,
    quantization: 'bf16',
    tensorParallelism: 8,
    pricing: { inputPer1M: 0.27, outputPer1M: 1.10 },
    domainStrengths: [
      { domain: 'mathematics', strength: 'excellent', subspecialties: ['olympiad', 'proofs', 'calculus'] },
      { domain: 'software_engineering', strength: 'excellent', subspecialties: ['algorithms', 'systems'] },
      { domain: 'science', strength: 'excellent', subspecialties: ['physics', 'chemistry'] },
    ],
    orchestration: {
      preferredFor: ['math_problems', 'complex_reasoning', 'code_generation', 'scientific_analysis'],
      avoidFor: ['real_time_info', 'image_tasks'],
      pairsWellWith: ['qwen2.5-72b-instruct', 'llama-3.3-70b-instruct'],
      fallbackTo: 'deepseek-v2.5',
      minTier: 2,
      latencyClass: 'medium',
      qualityTier: 'premium',
    },
    license: 'mit',
    commercialUse: true,
    releaseDate: '2024-12-26',
    huggingFaceId: 'deepseek-ai/DeepSeek-V3',
    paperUrl: 'https://arxiv.org/abs/2412.19437',
  },
  {
    id: 'deepseek-v2.5',
    family: 'deepseek',
    displayName: 'DeepSeek V2.5',
    description: 'Balanced MoE model combining chat and code capabilities',
    version: '2.5',
    parameterCount: '236B',
    inputModalities: ['text'],
    outputModalities: ['text'],
    capabilities: ['chat', 'reasoning', 'code', 'math', 'function_calling'],
    contextWindow: 131072,
    maxOutputTokens: 8192,
    instanceType: 'ml.p4d.24xlarge',
    minVRAM: 160,
    quantization: 'bf16',
    tensorParallelism: 8,
    pricing: { inputPer1M: 0.14, outputPer1M: 0.28 },
    domainStrengths: [
      { domain: 'mathematics', strength: 'excellent' },
      { domain: 'software_engineering', strength: 'excellent' },
    ],
    orchestration: {
      preferredFor: ['math_problems', 'code_generation'],
      avoidFor: ['specialized_domains'],
      fallbackTo: 'deepseek-coder-33b',
      minTier: 2,
      latencyClass: 'medium',
      qualityTier: 'premium',
    },
    license: 'mit',
    commercialUse: true,
    releaseDate: '2024-09-05',
    huggingFaceId: 'deepseek-ai/DeepSeek-V2.5',
  },
  {
    id: 'deepseek-coder-33b',
    family: 'deepseek',
    displayName: 'DeepSeek Coder 33B',
    description: 'Specialized coding model with strong code generation',
    version: '1.5',
    parameterCount: '33B',
    inputModalities: ['text', 'code'],
    outputModalities: ['text', 'code'],
    capabilities: ['code', 'code_generation', 'code_review', 'debugging', 'fill_in_middle'],
    contextWindow: 16384,
    maxOutputTokens: 4096,
    instanceType: 'ml.g5.12xlarge',
    minVRAM: 64,
    quantization: 'bf16',
    tensorParallelism: 4,
    pricing: { inputPer1M: 0.20, outputPer1M: 0.60 },
    domainStrengths: [
      { domain: 'software_engineering', strength: 'excellent', subspecialties: ['python', 'java', 'c++', 'rust'] },
    ],
    orchestration: {
      preferredFor: ['code_generation', 'debugging', 'code_review'],
      avoidFor: ['non_coding_tasks'],
      pairsWellWith: ['qwen2.5-coder-32b', 'codestral-22b'],
      fallbackTo: 'deepseek-coder-7b',
      minTier: 2,
      latencyClass: 'medium',
      qualityTier: 'premium',
    },
    license: 'mit',
    commercialUse: true,
    releaseDate: '2024-01-17',
    huggingFaceId: 'deepseek-ai/deepseek-coder-33b-instruct',
  },
  {
    id: 'deepseek-coder-7b',
    family: 'deepseek',
    displayName: 'DeepSeek Coder 7B',
    description: 'Fast coding model for high-throughput tasks',
    version: '1.5',
    parameterCount: '7B',
    inputModalities: ['text', 'code'],
    outputModalities: ['text', 'code'],
    capabilities: ['code', 'code_generation', 'code_completion'],
    contextWindow: 16384,
    maxOutputTokens: 4096,
    instanceType: 'ml.g5.2xlarge',
    minVRAM: 16,
    quantization: 'bf16',
    pricing: { inputPer1M: 0.08, outputPer1M: 0.24 },
    domainStrengths: [
      { domain: 'software_engineering', strength: 'good' },
    ],
    orchestration: {
      preferredFor: ['code_completion', 'simple_code_tasks'],
      avoidFor: ['complex_architecture'],
      minTier: 1,
      latencyClass: 'fast',
      qualityTier: 'economy',
    },
    license: 'mit',
    commercialUse: true,
    releaseDate: '2024-01-17',
    huggingFaceId: 'deepseek-ai/deepseek-coder-7b-instruct-v1.5',
  },

  // ═══════════════════════════════════════════════════════════════════════════
  // PHI FAMILY (Microsoft)
  // ═══════════════════════════════════════════════════════════════════════════
  {
    id: 'phi-4',
    family: 'phi',
    displayName: 'Phi-4',
    description: 'Microsoft\'s latest small but mighty model with strong reasoning',
    version: '4.0',
    parameterCount: '14B',
    inputModalities: ['text'],
    outputModalities: ['text'],
    capabilities: ['chat', 'reasoning', 'code', 'math'],
    contextWindow: 16384,
    maxOutputTokens: 4096,
    instanceType: 'ml.g5.4xlarge',
    minVRAM: 28,
    quantization: 'bf16',
    pricing: { inputPer1M: 0.12, outputPer1M: 0.36 },
    domainStrengths: [
      { domain: 'mathematics', strength: 'excellent', subspecialties: ['algebra', 'logic'] },
      { domain: 'software_engineering', strength: 'good' },
      { domain: 'science', strength: 'good', subspecialties: ['physics'] },
    ],
    orchestration: {
      preferredFor: ['math_problems', 'logical_reasoning', 'quick_code'],
      avoidFor: ['long_context', 'creative_writing'],
      fallbackTo: 'phi-3.5-mini',
      minTier: 1,
      latencyClass: 'fast',
      qualityTier: 'standard',
    },
    license: 'mit',
    commercialUse: true,
    releaseDate: '2024-12-12',
    huggingFaceId: 'microsoft/phi-4',
  },
  {
    id: 'phi-3.5-moe',
    family: 'phi',
    displayName: 'Phi-3.5 MoE',
    description: 'Mixture of experts model with efficient routing',
    version: '3.5',
    parameterCount: '42B',
    inputModalities: ['text'],
    outputModalities: ['text'],
    capabilities: ['chat', 'reasoning', 'code', 'multilingual'],
    contextWindow: 131072,
    maxOutputTokens: 4096,
    instanceType: 'ml.g5.12xlarge',
    minVRAM: 80,
    quantization: 'bf16',
    tensorParallelism: 4,
    pricing: { inputPer1M: 0.18, outputPer1M: 0.54 },
    domainStrengths: [
      { domain: 'general', strength: 'good' },
      { domain: 'software_engineering', strength: 'good' },
    ],
    orchestration: {
      preferredFor: ['balanced_tasks', 'long_context', 'multilingual'],
      avoidFor: ['specialized_domains'],
      fallbackTo: 'phi-3.5-mini',
      minTier: 2,
      latencyClass: 'medium',
      qualityTier: 'standard',
    },
    license: 'mit',
    commercialUse: true,
    releaseDate: '2024-08-20',
    huggingFaceId: 'microsoft/Phi-3.5-MoE-instruct',
  },
  {
    id: 'phi-3.5-mini',
    family: 'phi',
    displayName: 'Phi-3.5 Mini',
    description: 'Compact but capable model for edge deployment',
    version: '3.5',
    parameterCount: '3.8B',
    inputModalities: ['text'],
    outputModalities: ['text'],
    capabilities: ['chat', 'code'],
    contextWindow: 131072,
    maxOutputTokens: 4096,
    instanceType: 'ml.g5.xlarge',
    minVRAM: 8,
    quantization: 'bf16',
    pricing: { inputPer1M: 0.04, outputPer1M: 0.12 },
    domainStrengths: [
      { domain: 'general', strength: 'moderate' },
    ],
    orchestration: {
      preferredFor: ['simple_tasks', 'high_throughput', 'edge_deployment'],
      avoidFor: ['complex_reasoning'],
      minTier: 1,
      latencyClass: 'fast',
      qualityTier: 'economy',
    },
    license: 'mit',
    commercialUse: true,
    releaseDate: '2024-08-20',
    huggingFaceId: 'microsoft/Phi-3.5-mini-instruct',
  },
  {
    id: 'phi-3.5-vision',
    family: 'phi',
    displayName: 'Phi-3.5 Vision',
    description: 'Compact multimodal model with vision capabilities',
    version: '3.5',
    parameterCount: '4.2B',
    inputModalities: ['text', 'image'],
    outputModalities: ['text'],
    capabilities: ['chat', 'vision', 'image_analysis', 'ocr'],
    contextWindow: 131072,
    maxOutputTokens: 4096,
    instanceType: 'ml.g5.2xlarge',
    minVRAM: 16,
    quantization: 'bf16',
    pricing: { inputPer1M: 0.08, outputPer1M: 0.24 },
    domainStrengths: [
      { domain: 'visual_analysis', strength: 'moderate' },
    ],
    orchestration: {
      preferredFor: ['quick_image_analysis', 'simple_ocr', 'edge_vision'],
      avoidFor: ['complex_visual_reasoning'],
      fallbackTo: 'phi-3.5-mini',
      minTier: 1,
      latencyClass: 'fast',
      qualityTier: 'economy',
    },
    mediaSupport: {
      imageInput: true,
      maxImageSize: 1024,
      supportedFormats: ['jpg', 'png', 'webp'],
    },
    license: 'mit',
    commercialUse: true,
    releaseDate: '2024-08-20',
    huggingFaceId: 'microsoft/Phi-3.5-vision-instruct',
  },

  // ═══════════════════════════════════════════════════════════════════════════
  // GEMMA FAMILY (Google)
  // ═══════════════════════════════════════════════════════════════════════════
  {
    id: 'gemma-2-27b',
    family: 'gemma',
    displayName: 'Gemma 2 27B',
    description: 'Google\'s largest open model with strong capabilities',
    version: '2.0',
    parameterCount: '27B',
    inputModalities: ['text'],
    outputModalities: ['text'],
    capabilities: ['chat', 'reasoning', 'code', 'multilingual'],
    contextWindow: 8192,
    maxOutputTokens: 4096,
    instanceType: 'ml.g5.8xlarge',
    minVRAM: 56,
    quantization: 'bf16',
    tensorParallelism: 2,
    pricing: { inputPer1M: 0.22, outputPer1M: 0.66 },
    domainStrengths: [
      { domain: 'general', strength: 'good' },
      { domain: 'software_engineering', strength: 'good' },
    ],
    orchestration: {
      preferredFor: ['general_tasks', 'code_assistance'],
      avoidFor: ['long_context', 'specialized_domains'],
      fallbackTo: 'gemma-2-9b',
      minTier: 2,
      latencyClass: 'medium',
      qualityTier: 'standard',
    },
    license: 'apache-2.0',
    commercialUse: true,
    releaseDate: '2024-06-27',
    huggingFaceId: 'google/gemma-2-27b-it',
  },
  {
    id: 'gemma-2-9b',
    family: 'gemma',
    displayName: 'Gemma 2 9B',
    description: 'Balanced Gemma model with good quality/speed tradeoff',
    version: '2.0',
    parameterCount: '9B',
    inputModalities: ['text'],
    outputModalities: ['text'],
    capabilities: ['chat', 'code'],
    contextWindow: 8192,
    maxOutputTokens: 4096,
    instanceType: 'ml.g5.2xlarge',
    minVRAM: 20,
    quantization: 'bf16',
    pricing: { inputPer1M: 0.10, outputPer1M: 0.30 },
    domainStrengths: [
      { domain: 'general', strength: 'good' },
    ],
    orchestration: {
      preferredFor: ['quick_tasks', 'code_completion'],
      avoidFor: ['long_context', 'complex_reasoning'],
      fallbackTo: 'gemma-2-2b',
      minTier: 1,
      latencyClass: 'fast',
      qualityTier: 'standard',
    },
    license: 'apache-2.0',
    commercialUse: true,
    releaseDate: '2024-06-27',
    huggingFaceId: 'google/gemma-2-9b-it',
  },
  {
    id: 'gemma-2-2b',
    family: 'gemma',
    displayName: 'Gemma 2 2B',
    description: 'Ultra-compact Gemma for edge and high-throughput',
    version: '2.0',
    parameterCount: '2B',
    inputModalities: ['text'],
    outputModalities: ['text'],
    capabilities: ['chat'],
    contextWindow: 8192,
    maxOutputTokens: 2048,
    instanceType: 'ml.g5.xlarge',
    minVRAM: 6,
    quantization: 'bf16',
    pricing: { inputPer1M: 0.03, outputPer1M: 0.09 },
    domainStrengths: [
      { domain: 'general', strength: 'moderate' },
    ],
    orchestration: {
      preferredFor: ['classification', 'simple_qa', 'high_throughput'],
      avoidFor: ['complex_tasks'],
      minTier: 1,
      latencyClass: 'fast',
      qualityTier: 'economy',
    },
    license: 'apache-2.0',
    commercialUse: true,
    releaseDate: '2024-06-27',
    huggingFaceId: 'google/gemma-2-2b-it',
  },
  {
    id: 'codegemma-7b',
    family: 'gemma',
    displayName: 'CodeGemma 7B',
    description: 'Google\'s code-specialized Gemma model',
    version: '1.0',
    parameterCount: '7B',
    inputModalities: ['text', 'code'],
    outputModalities: ['text', 'code'],
    capabilities: ['code', 'code_generation', 'code_completion', 'fill_in_middle'],
    contextWindow: 8192,
    maxOutputTokens: 4096,
    instanceType: 'ml.g5.2xlarge',
    minVRAM: 16,
    quantization: 'bf16',
    pricing: { inputPer1M: 0.10, outputPer1M: 0.30 },
    domainStrengths: [
      { domain: 'software_engineering', strength: 'good', subspecialties: ['python', 'javascript'] },
    ],
    orchestration: {
      preferredFor: ['code_completion', 'fill_in_middle', 'simple_code'],
      avoidFor: ['non_coding_tasks'],
      fallbackTo: 'gemma-2-9b',
      minTier: 1,
      latencyClass: 'fast',
      qualityTier: 'standard',
    },
    license: 'apache-2.0',
    commercialUse: true,
    releaseDate: '2024-04-09',
    huggingFaceId: 'google/codegemma-7b-it',
  },

  // ═══════════════════════════════════════════════════════════════════════════
  // YI FAMILY (01.AI)
  // ═══════════════════════════════════════════════════════════════════════════
  {
    id: 'yi-1.5-34b',
    family: 'yi',
    displayName: 'Yi 1.5 34B',
    description: '01.AI\'s flagship bilingual model',
    version: '1.5',
    parameterCount: '34B',
    inputModalities: ['text'],
    outputModalities: ['text'],
    capabilities: ['chat', 'reasoning', 'code', 'multilingual'],
    contextWindow: 32768,
    maxOutputTokens: 4096,
    instanceType: 'ml.g5.12xlarge',
    minVRAM: 68,
    quantization: 'bf16',
    tensorParallelism: 4,
    pricing: { inputPer1M: 0.25, outputPer1M: 0.75 },
    domainStrengths: [
      { domain: 'multilingual', strength: 'excellent', subspecialties: ['chinese', 'english'] },
      { domain: 'general', strength: 'good' },
    ],
    orchestration: {
      preferredFor: ['chinese_content', 'bilingual_tasks'],
      avoidFor: ['specialized_western_domains'],
      fallbackTo: 'yi-1.5-9b',
      minTier: 2,
      latencyClass: 'medium',
      qualityTier: 'standard',
    },
    license: 'apache-2.0',
    commercialUse: true,
    releaseDate: '2024-05-13',
    huggingFaceId: '01-ai/Yi-1.5-34B-Chat',
  },
  {
    id: 'yi-1.5-9b',
    family: 'yi',
    displayName: 'Yi 1.5 9B',
    description: 'Balanced bilingual model',
    version: '1.5',
    parameterCount: '9B',
    inputModalities: ['text'],
    outputModalities: ['text'],
    capabilities: ['chat', 'code', 'multilingual'],
    contextWindow: 32768,
    maxOutputTokens: 4096,
    instanceType: 'ml.g5.2xlarge',
    minVRAM: 20,
    quantization: 'bf16',
    pricing: { inputPer1M: 0.10, outputPer1M: 0.30 },
    domainStrengths: [
      { domain: 'multilingual', strength: 'good', subspecialties: ['chinese', 'english'] },
    ],
    orchestration: {
      preferredFor: ['quick_chinese_tasks', 'bilingual'],
      avoidFor: ['complex_reasoning'],
      minTier: 1,
      latencyClass: 'fast',
      qualityTier: 'economy',
    },
    license: 'apache-2.0',
    commercialUse: true,
    releaseDate: '2024-05-13',
    huggingFaceId: '01-ai/Yi-1.5-9B-Chat',
  },
  {
    id: 'yi-vl-34b',
    family: 'yi',
    displayName: 'Yi-VL 34B',
    description: 'Multimodal Yi with vision capabilities',
    version: '1.0',
    parameterCount: '34B',
    inputModalities: ['text', 'image'],
    outputModalities: ['text'],
    capabilities: ['chat', 'vision', 'image_analysis', 'ocr', 'multilingual'],
    contextWindow: 16384,
    maxOutputTokens: 4096,
    instanceType: 'ml.g5.12xlarge',
    minVRAM: 72,
    quantization: 'bf16',
    tensorParallelism: 4,
    pricing: { inputPer1M: 0.30, outputPer1M: 0.90 },
    domainStrengths: [
      { domain: 'visual_analysis', strength: 'good' },
      { domain: 'multilingual', strength: 'excellent', subspecialties: ['chinese_ocr'] },
    ],
    orchestration: {
      preferredFor: ['chinese_image_analysis', 'bilingual_vision'],
      avoidFor: ['western_specific_content'],
      fallbackTo: 'yi-1.5-34b',
      minTier: 2,
      latencyClass: 'medium',
      qualityTier: 'standard',
    },
    mediaSupport: {
      imageInput: true,
      maxImageSize: 2048,
      supportedFormats: ['jpg', 'png', 'webp'],
    },
    license: 'apache-2.0',
    commercialUse: true,
    releaseDate: '2024-01-23',
    huggingFaceId: '01-ai/Yi-VL-34B',
  },

  // ═══════════════════════════════════════════════════════════════════════════
  // CODELLAMA FAMILY (Meta)
  // ═══════════════════════════════════════════════════════════════════════════
  {
    id: 'codellama-70b',
    family: 'codellama',
    displayName: 'Code Llama 70B',
    description: 'Meta\'s largest code-specialized Llama model',
    version: '1.0',
    parameterCount: '70B',
    inputModalities: ['text', 'code'],
    outputModalities: ['text', 'code'],
    capabilities: ['code', 'code_generation', 'code_review', 'debugging', 'fill_in_middle'],
    contextWindow: 16384,
    maxOutputTokens: 4096,
    instanceType: 'ml.p4d.24xlarge',
    minVRAM: 140,
    quantization: 'bf16',
    tensorParallelism: 8,
    pricing: { inputPer1M: 0.55, outputPer1M: 1.65 },
    domainStrengths: [
      { domain: 'software_engineering', strength: 'excellent', subspecialties: ['python', 'c++', 'java', 'rust'] },
    ],
    orchestration: {
      preferredFor: ['complex_code_generation', 'code_review', 'architecture'],
      avoidFor: ['non_coding_tasks'],
      pairsWellWith: ['deepseek-coder-33b', 'qwen2.5-coder-32b'],
      fallbackTo: 'codellama-34b',
      minTier: 2,
      latencyClass: 'medium',
      qualityTier: 'premium',
    },
    license: 'llama',
    commercialUse: true,
    releaseDate: '2024-01-29',
    huggingFaceId: 'codellama/CodeLlama-70b-Instruct-hf',
  },
  {
    id: 'codellama-34b',
    family: 'codellama',
    displayName: 'Code Llama 34B',
    description: 'Balanced code model with strong capabilities',
    version: '1.0',
    parameterCount: '34B',
    inputModalities: ['text', 'code'],
    outputModalities: ['text', 'code'],
    capabilities: ['code', 'code_generation', 'fill_in_middle'],
    contextWindow: 16384,
    maxOutputTokens: 4096,
    instanceType: 'ml.g5.12xlarge',
    minVRAM: 68,
    quantization: 'bf16',
    tensorParallelism: 4,
    pricing: { inputPer1M: 0.28, outputPer1M: 0.84 },
    domainStrengths: [
      { domain: 'software_engineering', strength: 'good' },
    ],
    orchestration: {
      preferredFor: ['code_generation', 'refactoring'],
      avoidFor: ['non_coding_tasks'],
      fallbackTo: 'codellama-7b',
      minTier: 2,
      latencyClass: 'medium',
      qualityTier: 'standard',
    },
    license: 'llama',
    commercialUse: true,
    releaseDate: '2023-08-24',
    huggingFaceId: 'codellama/CodeLlama-34b-Instruct-hf',
  },
  {
    id: 'codellama-7b',
    family: 'codellama',
    displayName: 'Code Llama 7B',
    description: 'Fast code model for high-throughput tasks',
    version: '1.0',
    parameterCount: '7B',
    inputModalities: ['text', 'code'],
    outputModalities: ['text', 'code'],
    capabilities: ['code', 'code_completion'],
    contextWindow: 16384,
    maxOutputTokens: 4096,
    instanceType: 'ml.g5.2xlarge',
    minVRAM: 16,
    quantization: 'bf16',
    pricing: { inputPer1M: 0.08, outputPer1M: 0.24 },
    domainStrengths: [
      { domain: 'software_engineering', strength: 'moderate' },
    ],
    orchestration: {
      preferredFor: ['code_completion', 'simple_code'],
      avoidFor: ['complex_architecture'],
      minTier: 1,
      latencyClass: 'fast',
      qualityTier: 'economy',
    },
    license: 'llama',
    commercialUse: true,
    releaseDate: '2023-08-24',
    huggingFaceId: 'codellama/CodeLlama-7b-Instruct-hf',
  },

  // ═══════════════════════════════════════════════════════════════════════════
  // STARCODER FAMILY (BigCode)
  // ═══════════════════════════════════════════════════════════════════════════
  {
    id: 'starcoder2-15b',
    family: 'starcoder',
    displayName: 'StarCoder2 15B',
    description: 'BigCode\'s flagship open code model',
    version: '2.0',
    parameterCount: '15B',
    inputModalities: ['text', 'code'],
    outputModalities: ['text', 'code'],
    capabilities: ['code', 'code_generation', 'code_completion', 'fill_in_middle'],
    contextWindow: 16384,
    maxOutputTokens: 4096,
    instanceType: 'ml.g5.4xlarge',
    minVRAM: 32,
    quantization: 'bf16',
    pricing: { inputPer1M: 0.15, outputPer1M: 0.45 },
    domainStrengths: [
      { domain: 'software_engineering', strength: 'excellent', subspecialties: ['python', 'javascript', 'typescript', 'java'] },
    ],
    orchestration: {
      preferredFor: ['code_generation', 'code_completion', 'fill_in_middle'],
      avoidFor: ['non_coding_tasks'],
      pairsWellWith: ['codellama-34b'],
      fallbackTo: 'starcoder2-7b',
      minTier: 1,
      latencyClass: 'fast',
      qualityTier: 'standard',
    },
    license: 'apache-2.0',
    commercialUse: true,
    releaseDate: '2024-02-28',
    huggingFaceId: 'bigcode/starcoder2-15b-instruct-v0.1',
  },
  {
    id: 'starcoder2-7b',
    family: 'starcoder',
    displayName: 'StarCoder2 7B',
    description: 'Fast and efficient code model',
    version: '2.0',
    parameterCount: '7B',
    inputModalities: ['text', 'code'],
    outputModalities: ['text', 'code'],
    capabilities: ['code', 'code_completion'],
    contextWindow: 16384,
    maxOutputTokens: 4096,
    instanceType: 'ml.g5.2xlarge',
    minVRAM: 16,
    quantization: 'bf16',
    pricing: { inputPer1M: 0.08, outputPer1M: 0.24 },
    domainStrengths: [
      { domain: 'software_engineering', strength: 'good' },
    ],
    orchestration: {
      preferredFor: ['code_completion', 'high_throughput'],
      avoidFor: ['complex_code'],
      minTier: 1,
      latencyClass: 'fast',
      qualityTier: 'economy',
    },
    license: 'apache-2.0',
    commercialUse: true,
    releaseDate: '2024-02-28',
    huggingFaceId: 'bigcode/starcoder2-7b',
  },

  // ═══════════════════════════════════════════════════════════════════════════
  // INTERNLM FAMILY (Shanghai AI Lab)
  // ═══════════════════════════════════════════════════════════════════════════
  {
    id: 'internlm2.5-20b',
    family: 'internlm',
    displayName: 'InternLM 2.5 20B',
    description: 'Shanghai AI Lab\'s flagship bilingual model',
    version: '2.5',
    parameterCount: '20B',
    inputModalities: ['text'],
    outputModalities: ['text'],
    capabilities: ['chat', 'reasoning', 'code', 'math', 'multilingual'],
    contextWindow: 32768,
    maxOutputTokens: 4096,
    instanceType: 'ml.g5.8xlarge',
    minVRAM: 40,
    quantization: 'bf16',
    tensorParallelism: 2,
    pricing: { inputPer1M: 0.18, outputPer1M: 0.54 },
    domainStrengths: [
      { domain: 'mathematics', strength: 'excellent' },
      { domain: 'multilingual', strength: 'excellent', subspecialties: ['chinese', 'english'] },
    ],
    orchestration: {
      preferredFor: ['math_problems', 'chinese_content', 'reasoning'],
      avoidFor: ['western_cultural_context'],
      fallbackTo: 'internlm2.5-7b',
      minTier: 2,
      latencyClass: 'medium',
      qualityTier: 'standard',
    },
    license: 'apache-2.0',
    commercialUse: true,
    releaseDate: '2024-07-03',
    huggingFaceId: 'internlm/internlm2_5-20b-chat',
  },
  {
    id: 'internlm2.5-7b',
    family: 'internlm',
    displayName: 'InternLM 2.5 7B',
    description: 'Efficient bilingual model',
    version: '2.5',
    parameterCount: '7B',
    inputModalities: ['text'],
    outputModalities: ['text'],
    capabilities: ['chat', 'code', 'multilingual'],
    contextWindow: 32768,
    maxOutputTokens: 4096,
    instanceType: 'ml.g5.2xlarge',
    minVRAM: 16,
    quantization: 'bf16',
    pricing: { inputPer1M: 0.08, outputPer1M: 0.24 },
    domainStrengths: [
      { domain: 'multilingual', strength: 'good', subspecialties: ['chinese', 'english'] },
    ],
    orchestration: {
      preferredFor: ['quick_chinese_tasks'],
      avoidFor: ['complex_reasoning'],
      minTier: 1,
      latencyClass: 'fast',
      qualityTier: 'economy',
    },
    license: 'apache-2.0',
    commercialUse: true,
    releaseDate: '2024-07-03',
    huggingFaceId: 'internlm/internlm2_5-7b-chat',
  },
];

// ============================================================================
// IMAGE GENERATION MODELS
// ============================================================================

export const SELF_HOSTED_IMAGE_MODELS: SelfHostedModelDefinition[] = [
  {
    id: 'flux-1-dev',
    family: 'flux',
    displayName: 'FLUX.1 Dev',
    description: 'Black Forest Labs\' flagship image generation model',
    version: '1.0',
    parameterCount: '12B',
    inputModalities: ['text'],
    outputModalities: ['image'],
    capabilities: ['image_generation', 'text_to_image'],
    contextWindow: 512,
    maxOutputTokens: 0,
    instanceType: 'ml.g5.8xlarge',
    minVRAM: 48,
    quantization: 'bf16',
    pricing: { inputPer1M: 0.50, outputPer1M: 25.00 },
    domainStrengths: [
      { domain: 'creative', strength: 'excellent', subspecialties: ['art', 'photography', 'illustration'] },
    ],
    orchestration: {
      preferredFor: ['high_quality_images', 'artistic_content', 'detailed_prompts'],
      avoidFor: ['text_tasks', 'audio_tasks'],
      pairsWellWith: ['stable-diffusion-xl'],
      fallbackTo: 'flux-1-schnell',
      minTier: 2,
      latencyClass: 'slow',
      qualityTier: 'premium',
    },
    mediaSupport: {
      imageOutput: true,
      maxImageSize: 2048,
      supportedFormats: ['png', 'jpg', 'webp'],
    },
    license: 'cc-by-nc',
    commercialUse: false,
    releaseDate: '2024-08-01',
    huggingFaceId: 'black-forest-labs/FLUX.1-dev',
  },
  {
    id: 'flux-1-schnell',
    family: 'flux',
    displayName: 'FLUX.1 Schnell',
    description: 'Fast FLUX model for quick image generation',
    version: '1.0',
    parameterCount: '12B',
    inputModalities: ['text'],
    outputModalities: ['image'],
    capabilities: ['image_generation', 'text_to_image'],
    contextWindow: 512,
    maxOutputTokens: 0,
    instanceType: 'ml.g5.4xlarge',
    minVRAM: 24,
    quantization: 'bf16',
    pricing: { inputPer1M: 0.25, outputPer1M: 12.00 },
    domainStrengths: [
      { domain: 'creative', strength: 'good' },
    ],
    orchestration: {
      preferredFor: ['quick_images', 'prototyping', 'high_volume'],
      avoidFor: ['ultra_high_quality'],
      minTier: 1,
      latencyClass: 'fast',
      qualityTier: 'standard',
    },
    mediaSupport: {
      imageOutput: true,
      maxImageSize: 1024,
      supportedFormats: ['png', 'jpg', 'webp'],
    },
    license: 'apache-2.0',
    commercialUse: true,
    releaseDate: '2024-08-01',
    huggingFaceId: 'black-forest-labs/FLUX.1-schnell',
  },
  {
    id: 'stable-diffusion-xl',
    family: 'stable_diffusion',
    displayName: 'Stable Diffusion XL',
    description: 'Stability AI\'s flagship open image model',
    version: '1.0',
    parameterCount: '6.6B',
    inputModalities: ['text', 'image'],
    outputModalities: ['image'],
    capabilities: ['image_generation', 'text_to_image', 'image_to_image', 'inpainting'],
    contextWindow: 77,
    maxOutputTokens: 0,
    instanceType: 'ml.g5.4xlarge',
    minVRAM: 24,
    quantization: 'fp16',
    pricing: { inputPer1M: 0.20, outputPer1M: 10.00 },
    domainStrengths: [
      { domain: 'creative', strength: 'excellent', subspecialties: ['art', 'design', 'photography'] },
    ],
    orchestration: {
      preferredFor: ['image_generation', 'inpainting', 'image_editing'],
      avoidFor: ['text_tasks'],
      pairsWellWith: ['flux-1-dev'],
      fallbackTo: 'stable-diffusion-3',
      minTier: 1,
      latencyClass: 'medium',
      qualityTier: 'standard',
    },
    mediaSupport: {
      imageInput: true,
      imageOutput: true,
      maxImageSize: 1024,
      supportedFormats: ['png', 'jpg', 'webp'],
    },
    license: 'apache-2.0',
    commercialUse: true,
    releaseDate: '2023-07-26',
    huggingFaceId: 'stabilityai/stable-diffusion-xl-base-1.0',
  },
  {
    id: 'stable-diffusion-3',
    family: 'stable_diffusion',
    displayName: 'Stable Diffusion 3 Medium',
    description: 'Latest Stable Diffusion with improved text rendering',
    version: '3.0',
    parameterCount: '2B',
    inputModalities: ['text'],
    outputModalities: ['image'],
    capabilities: ['image_generation', 'text_to_image'],
    contextWindow: 77,
    maxOutputTokens: 0,
    instanceType: 'ml.g5.2xlarge',
    minVRAM: 16,
    quantization: 'fp16',
    pricing: { inputPer1M: 0.15, outputPer1M: 8.00 },
    domainStrengths: [
      { domain: 'creative', strength: 'good', subspecialties: ['text_in_images', 'logos'] },
    ],
    orchestration: {
      preferredFor: ['text_in_images', 'logos', 'quick_generation'],
      avoidFor: ['complex_scenes'],
      minTier: 1,
      latencyClass: 'fast',
      qualityTier: 'standard',
    },
    mediaSupport: {
      imageOutput: true,
      maxImageSize: 1024,
      supportedFormats: ['png', 'jpg', 'webp'],
    },
    license: 'apache-2.0',
    commercialUse: true,
    releaseDate: '2024-06-12',
    huggingFaceId: 'stabilityai/stable-diffusion-3-medium',
  },
];

// ============================================================================
// AUDIO MODELS
// ============================================================================

export const SELF_HOSTED_AUDIO_MODELS: SelfHostedModelDefinition[] = [
  {
    id: 'whisper-large-v3',
    family: 'whisper',
    displayName: 'Whisper Large V3',
    description: 'OpenAI\'s speech recognition model',
    version: '3.0',
    parameterCount: '1.5B',
    inputModalities: ['audio'],
    outputModalities: ['text'],
    capabilities: ['transcription', 'translation', 'language_detection'],
    contextWindow: 448,
    maxOutputTokens: 448,
    instanceType: 'ml.g5.2xlarge',
    minVRAM: 10,
    quantization: 'fp16',
    pricing: { inputPer1M: 0.10, outputPer1M: 0.10 },
    domainStrengths: [
      { domain: 'audio_processing', strength: 'excellent', subspecialties: ['transcription', 'multilingual'] },
    ],
    orchestration: {
      preferredFor: ['transcription', 'audio_to_text', 'multilingual_audio'],
      avoidFor: ['text_only_tasks', 'image_tasks'],
      pairsWellWith: ['qwen2-audio-7b'],
      fallbackTo: 'whisper-medium',
      minTier: 1,
      latencyClass: 'fast',
      qualityTier: 'premium',
    },
    mediaSupport: {
      audioInput: true,
      maxAudioLength: 3600,
      supportedFormats: ['mp3', 'wav', 'flac', 'm4a', 'ogg', 'webm'],
    },
    license: 'mit',
    commercialUse: true,
    releaseDate: '2023-11-06',
    huggingFaceId: 'openai/whisper-large-v3',
  },
  {
    id: 'whisper-medium',
    family: 'whisper',
    displayName: 'Whisper Medium',
    description: 'Balanced Whisper model for efficient transcription',
    version: '1.0',
    parameterCount: '769M',
    inputModalities: ['audio'],
    outputModalities: ['text'],
    capabilities: ['transcription', 'translation'],
    contextWindow: 448,
    maxOutputTokens: 448,
    instanceType: 'ml.g5.xlarge',
    minVRAM: 5,
    quantization: 'fp16',
    pricing: { inputPer1M: 0.05, outputPer1M: 0.05 },
    domainStrengths: [
      { domain: 'audio_processing', strength: 'good' },
    ],
    orchestration: {
      preferredFor: ['quick_transcription', 'high_throughput'],
      avoidFor: ['complex_audio', 'noisy_audio'],
      minTier: 1,
      latencyClass: 'fast',
      qualityTier: 'standard',
    },
    mediaSupport: {
      audioInput: true,
      maxAudioLength: 3600,
      supportedFormats: ['mp3', 'wav', 'flac', 'm4a'],
    },
    license: 'mit',
    commercialUse: true,
    releaseDate: '2022-12-06',
    huggingFaceId: 'openai/whisper-medium',
  },
  {
    id: 'bark',
    family: 'bark',
    displayName: 'Bark',
    description: 'Suno\'s text-to-speech model with expressive voices',
    version: '1.0',
    parameterCount: '1B',
    inputModalities: ['text'],
    outputModalities: ['audio'],
    capabilities: ['text_to_speech', 'voice_synthesis', 'multilingual_tts'],
    contextWindow: 256,
    maxOutputTokens: 0,
    instanceType: 'ml.g5.2xlarge',
    minVRAM: 12,
    quantization: 'fp16',
    pricing: { inputPer1M: 0.15, outputPer1M: 5.00 },
    domainStrengths: [
      { domain: 'audio_processing', strength: 'excellent', subspecialties: ['tts', 'voice_cloning'] },
    ],
    orchestration: {
      preferredFor: ['text_to_speech', 'expressive_audio', 'multilingual_tts'],
      avoidFor: ['transcription', 'text_tasks'],
      pairsWellWith: ['whisper-large-v3'],
      minTier: 1,
      latencyClass: 'medium',
      qualityTier: 'premium',
    },
    mediaSupport: {
      audioOutput: true,
      maxAudioLength: 60,
      supportedFormats: ['wav', 'mp3'],
    },
    license: 'mit',
    commercialUse: true,
    releaseDate: '2023-04-14',
    huggingFaceId: 'suno/bark',
  },
  {
    id: 'musicgen-large',
    family: 'musicgen',
    displayName: 'MusicGen Large',
    description: 'Meta\'s text-to-music generation model',
    version: '1.0',
    parameterCount: '3.3B',
    inputModalities: ['text', 'audio'],
    outputModalities: ['audio'],
    capabilities: ['music_generation', 'audio_continuation'],
    contextWindow: 256,
    maxOutputTokens: 0,
    instanceType: 'ml.g5.4xlarge',
    minVRAM: 20,
    quantization: 'fp16',
    pricing: { inputPer1M: 0.25, outputPer1M: 8.00 },
    domainStrengths: [
      { domain: 'creative', strength: 'excellent', subspecialties: ['music', 'audio_art'] },
    ],
    orchestration: {
      preferredFor: ['music_generation', 'audio_creation', 'background_music'],
      avoidFor: ['text_tasks', 'speech'],
      fallbackTo: 'musicgen-medium',
      minTier: 2,
      latencyClass: 'slow',
      qualityTier: 'premium',
    },
    mediaSupport: {
      audioInput: true,
      audioOutput: true,
      maxAudioLength: 30,
      supportedFormats: ['wav', 'mp3'],
    },
    license: 'cc-by-nc',
    commercialUse: false,
    releaseDate: '2023-06-12',
    huggingFaceId: 'facebook/musicgen-large',
  },
  {
    id: 'musicgen-medium',
    family: 'musicgen',
    displayName: 'MusicGen Medium',
    description: 'Balanced music generation model',
    version: '1.0',
    parameterCount: '1.5B',
    inputModalities: ['text'],
    outputModalities: ['audio'],
    capabilities: ['music_generation'],
    contextWindow: 256,
    maxOutputTokens: 0,
    instanceType: 'ml.g5.2xlarge',
    minVRAM: 10,
    quantization: 'fp16',
    pricing: { inputPer1M: 0.15, outputPer1M: 5.00 },
    domainStrengths: [
      { domain: 'creative', strength: 'good', subspecialties: ['music'] },
    ],
    orchestration: {
      preferredFor: ['quick_music', 'prototyping'],
      avoidFor: ['high_quality_music'],
      minTier: 1,
      latencyClass: 'medium',
      qualityTier: 'standard',
    },
    mediaSupport: {
      audioOutput: true,
      maxAudioLength: 30,
      supportedFormats: ['wav', 'mp3'],
    },
    license: 'cc-by-nc',
    commercialUse: false,
    releaseDate: '2023-06-12',
    huggingFaceId: 'facebook/musicgen-medium',
  },
  {
    id: 'audiogen-medium',
    family: 'audiogen',
    displayName: 'AudioGen Medium',
    description: 'Meta\'s sound effects generation model',
    version: '1.0',
    parameterCount: '1.5B',
    inputModalities: ['text'],
    outputModalities: ['audio'],
    capabilities: ['sound_generation', 'sound_effects'],
    contextWindow: 256,
    maxOutputTokens: 0,
    instanceType: 'ml.g5.2xlarge',
    minVRAM: 10,
    quantization: 'fp16',
    pricing: { inputPer1M: 0.15, outputPer1M: 5.00 },
    domainStrengths: [
      { domain: 'creative', strength: 'good', subspecialties: ['sound_effects', 'ambient'] },
    ],
    orchestration: {
      preferredFor: ['sound_effects', 'ambient_audio', 'environmental_sounds'],
      avoidFor: ['music', 'speech'],
      pairsWellWith: ['musicgen-large'],
      minTier: 1,
      latencyClass: 'medium',
      qualityTier: 'standard',
    },
    mediaSupport: {
      audioOutput: true,
      maxAudioLength: 10,
      supportedFormats: ['wav', 'mp3'],
    },
    license: 'cc-by-nc',
    commercialUse: false,
    releaseDate: '2023-06-12',
    huggingFaceId: 'facebook/audiogen-medium',
  },
];

// ============================================================================
// 3D GENERATION MODELS
// ============================================================================

export const SELF_HOSTED_3D_MODELS: SelfHostedModelDefinition[] = [
  {
    id: 'point-e',
    family: 'point_e',
    displayName: 'Point-E',
    description: 'OpenAI\'s text-to-3D point cloud model',
    version: '1.0',
    parameterCount: '1B',
    inputModalities: ['text', 'image'],
    outputModalities: ['3d'],
    capabilities: ['3d_generation', 'text_to_3d', 'image_to_3d'],
    contextWindow: 77,
    maxOutputTokens: 0,
    instanceType: 'ml.g5.2xlarge',
    minVRAM: 12,
    quantization: 'fp16',
    pricing: { inputPer1M: 0.20, outputPer1M: 10.00 },
    domainStrengths: [
      { domain: 'creative', strength: 'moderate', subspecialties: ['3d_modeling', 'prototyping'] },
    ],
    orchestration: {
      preferredFor: ['quick_3d', '3d_prototyping', 'point_clouds'],
      avoidFor: ['high_detail_3d', 'textured_models'],
      pairsWellWith: ['shap-e'],
      minTier: 2,
      latencyClass: 'medium',
      qualityTier: 'standard',
    },
    mediaSupport: {
      imageInput: true,
      supportedFormats: ['ply', 'obj'],
    },
    license: 'mit',
    commercialUse: true,
    releaseDate: '2022-12-16',
    huggingFaceId: 'openai/point-e',
    paperUrl: 'https://arxiv.org/abs/2212.08751',
  },
  {
    id: 'shap-e',
    family: 'shap_e',
    displayName: 'Shap-E',
    description: 'OpenAI\'s text-to-3D mesh generation model',
    version: '1.0',
    parameterCount: '1B',
    inputModalities: ['text', 'image'],
    outputModalities: ['3d'],
    capabilities: ['3d_generation', 'text_to_3d', 'mesh_generation'],
    contextWindow: 77,
    maxOutputTokens: 0,
    instanceType: 'ml.g5.4xlarge',
    minVRAM: 16,
    quantization: 'fp16',
    pricing: { inputPer1M: 0.25, outputPer1M: 12.00 },
    domainStrengths: [
      { domain: 'creative', strength: 'good', subspecialties: ['3d_modeling', 'game_assets'] },
    ],
    orchestration: {
      preferredFor: ['3d_mesh_generation', 'game_assets', 'product_visualization'],
      avoidFor: ['high_poly_models', 'animated_3d'],
      pairsWellWith: ['point-e', 'stable-diffusion-xl'],
      minTier: 2,
      latencyClass: 'slow',
      qualityTier: 'standard',
    },
    mediaSupport: {
      imageInput: true,
      supportedFormats: ['glb', 'obj', 'ply'],
    },
    license: 'mit',
    commercialUse: true,
    releaseDate: '2023-05-03',
    huggingFaceId: 'openai/shap-e',
    paperUrl: 'https://arxiv.org/abs/2305.02463',
  },
];

// ============================================================================
// EMBEDDING MODELS
// ============================================================================

export const SELF_HOSTED_EMBEDDING_MODELS: SelfHostedModelDefinition[] = [
  {
    id: 'bge-m3',
    family: 'mpt',
    displayName: 'BGE-M3',
    description: 'Multi-lingual, multi-functionality embedding model',
    version: '1.0',
    parameterCount: '568M',
    inputModalities: ['text'],
    outputModalities: ['embedding'],
    capabilities: ['embedding', 'retrieval', 'multilingual'],
    contextWindow: 8192,
    maxOutputTokens: 0,
    instanceType: 'ml.g5.xlarge',
    minVRAM: 4,
    quantization: 'fp16',
    pricing: { inputPer1M: 0.02, outputPer1M: 0.02 },
    domainStrengths: [
      { domain: 'retrieval', strength: 'excellent' },
      { domain: 'multilingual', strength: 'excellent' },
    ],
    orchestration: {
      preferredFor: ['semantic_search', 'rag', 'document_retrieval'],
      avoidFor: ['generation', 'chat'],
      minTier: 1,
      latencyClass: 'fast',
      qualityTier: 'premium',
    },
    license: 'mit',
    commercialUse: true,
    releaseDate: '2024-01-30',
    huggingFaceId: 'BAAI/bge-m3',
  },
  {
    id: 'e5-mistral-7b',
    family: 'mistral',
    displayName: 'E5-Mistral-7B',
    description: 'Instruct-tuned embedding model based on Mistral',
    version: '1.0',
    parameterCount: '7B',
    inputModalities: ['text'],
    outputModalities: ['embedding'],
    capabilities: ['embedding', 'retrieval', 'instruction_embedding'],
    contextWindow: 4096,
    maxOutputTokens: 0,
    instanceType: 'ml.g5.2xlarge',
    minVRAM: 16,
    quantization: 'bf16',
    pricing: { inputPer1M: 0.05, outputPer1M: 0.05 },
    domainStrengths: [
      { domain: 'retrieval', strength: 'excellent' },
    ],
    orchestration: {
      preferredFor: ['instruction_following_retrieval', 'complex_queries'],
      avoidFor: ['generation', 'simple_search'],
      pairsWellWith: ['bge-m3'],
      minTier: 1,
      latencyClass: 'fast',
      qualityTier: 'premium',
    },
    license: 'mit',
    commercialUse: true,
    releaseDate: '2023-12-21',
    huggingFaceId: 'intfloat/e5-mistral-7b-instruct',
  },
  {
    id: 'nomic-embed-text',
    family: 'mpt',
    displayName: 'Nomic Embed Text',
    description: 'Long-context embedding model',
    version: '1.5',
    parameterCount: '137M',
    inputModalities: ['text'],
    outputModalities: ['embedding'],
    capabilities: ['embedding', 'long_context_embedding'],
    contextWindow: 8192,
    maxOutputTokens: 0,
    instanceType: 'ml.g5.xlarge',
    minVRAM: 2,
    quantization: 'fp16',
    pricing: { inputPer1M: 0.01, outputPer1M: 0.01 },
    domainStrengths: [
      { domain: 'retrieval', strength: 'good' },
    ],
    orchestration: {
      preferredFor: ['long_document_embedding', 'high_throughput'],
      avoidFor: ['generation', 'complex_queries'],
      minTier: 1,
      latencyClass: 'fast',
      qualityTier: 'economy',
    },
    license: 'apache-2.0',
    commercialUse: true,
    releaseDate: '2024-02-12',
    huggingFaceId: 'nomic-ai/nomic-embed-text-v1.5',
  },
];

// ============================================================================
// COMBINED REGISTRY
// ============================================================================

export const SELF_HOSTED_MODEL_REGISTRY: SelfHostedModelDefinition[] = [
  ...SELF_HOSTED_TEXT_MODELS,
  ...SELF_HOSTED_IMAGE_MODELS,
  ...SELF_HOSTED_AUDIO_MODELS,
  ...SELF_HOSTED_3D_MODELS,
  ...SELF_HOSTED_EMBEDDING_MODELS,
];

// Helper functions for model lookup
export const getSelfHostedModelById = (id: string): SelfHostedModelDefinition | undefined =>
  SELF_HOSTED_MODEL_REGISTRY.find(m => m.id === id);

export const getSelfHostedModelsByFamily = (family: ModelFamily): SelfHostedModelDefinition[] =>
  SELF_HOSTED_MODEL_REGISTRY.filter(m => m.family === family);

export const getSelfHostedModelsByCapability = (capability: string): SelfHostedModelDefinition[] =>
  SELF_HOSTED_MODEL_REGISTRY.filter(m => m.capabilities.includes(capability));

export const getSelfHostedModelsByModality = (
  inputModality?: ModelModality,
  outputModality?: ModelModality
): SelfHostedModelDefinition[] =>
  SELF_HOSTED_MODEL_REGISTRY.filter(m => {
    if (inputModality && !m.inputModalities.includes(inputModality)) return false;
    if (outputModality && !m.outputModalities.includes(outputModality)) return false;
    return true;
  });

export const getSelfHostedModelsByDomain = (
  domain: string,
  minStrength?: DomainStrength
): SelfHostedModelDefinition[] => {
  const strengthOrder: DomainStrength[] = ['excellent', 'good', 'moderate', 'basic'];
  const minIndex = minStrength ? strengthOrder.indexOf(minStrength) : strengthOrder.length - 1;
  
  return SELF_HOSTED_MODEL_REGISTRY.filter(m =>
    m.domainStrengths.some(ds =>
      ds.domain === domain && strengthOrder.indexOf(ds.strength) <= minIndex
    )
  );
};

export const getSelfHostedModelsForOrchestration = (
  preferredFor: string,
  tier: number,
  qualityTier?: 'premium' | 'standard' | 'economy'
): SelfHostedModelDefinition[] =>
  SELF_HOSTED_MODEL_REGISTRY.filter(m => {
    if (m.orchestration.minTier > tier) return false;
    if (qualityTier && m.orchestration.qualityTier !== qualityTier) return false;
    return m.orchestration.preferredFor.includes(preferredFor);
  });

// Model count summary
export const SELF_HOSTED_MODEL_COUNTS = {
  text: SELF_HOSTED_TEXT_MODELS.length,
  image: SELF_HOSTED_IMAGE_MODELS.length,
  audio: SELF_HOSTED_AUDIO_MODELS.length,
  threeD: SELF_HOSTED_3D_MODELS.length,
  embedding: SELF_HOSTED_EMBEDDING_MODELS.length,
  total: SELF_HOSTED_MODEL_REGISTRY.length,
};
